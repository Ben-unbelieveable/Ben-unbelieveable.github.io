<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2022%2F03%2F18%2FNGS-%E8%82%BF%E7%98%A4%E4%BD%93%E7%B3%BB%E6%A3%80%E6%B5%8B%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E8%83%9A%E7%B3%BB%E8%BF%87%E6%BB%A4%E6%96%B9%E6%A1%88%2Fdepth2Freq%2F</url>
    <content type="text"><![CDATA[Awesome-pyecharts var chart_13812cd4bbf743a3aa6832fda8950f9b = echarts.init( document.getElementById('13812cd4bbf743a3aa6832fda8950f9b'), 'white', {renderer: 'canvas'}); var option_13812cd4bbf743a3aa6832fda8950f9b = { "animation": true, "animationThreshold": 2000, "animationDuration": 1000, "animationEasing": "cubicOut", "animationDelay": 0, "animationDurationUpdate": 300, "animationEasingUpdate": "cubicOut", "animationDelayUpdate": 0, "color": [ "#c23531", "#2f4554", "#61a0a8", "#d48265", "#749f83", "#ca8622", "#bda29a", "#6e7074", "#546570", "#c4ccd3", "#f05b72", "#ef5b9c", "#f47920", "#905a3d", "#fab27b", "#2a5caa", "#444693", "#726930", "#b2d235", "#6d8346", "#ac6767", "#1d953f", "#6950a1", "#918597" ], "series": [ { "type": "line", "name": "Control Depth", "connectNulls": false, "symbolSize": 4, "showSymbol": true, "smooth": false, "clip": true, "step": false, "data": [ [ 0.005, 843.0 ], [ 0.01, 389.0 ], [ 0.015, 277.0 ], [ 0.02, 198.0 ], [ 0.025, 155.0 ], [ 0.030000000000000002, 127.0 ], [ 0.035, 108.0 ], [ 0.04, 94.0 ], [ 0.045, 83.0 ], [ 0.049999999999999996, 76.0 ], [ 0.05499999999999999, 69.0 ], [ 0.05999999999999999, 63.0 ], [ 0.06499999999999999, 59.0 ], [ 0.06999999999999999, 54.0 ], [ 0.075, 50.0 ], [ 0.08, 47.0 ], [ 0.085, 45.0 ], [ 0.09000000000000001, 42.0 ], [ 0.09500000000000001, 40.0 ] ], "hoverAnimation": true, "label": { "show": false, "position": "top", "margin": 8 }, "lineStyle": { "show": true, "width": 1, "opacity": 1, "curveness": 0, "type": "solid" }, "areaStyle": { "opacity": 0 }, "zlevel": 0, "z": 0 } ], "legend": [ { "data": [ "Control Depth" ], "selected": { "Control Depth": true }, "show": true, "padding": 5, "itemGap": 10, "itemWidth": 25, "itemHeight": 14 } ], "tooltip": { "show": true, "trigger": "item", "triggerOn": "mousemove|click", "axisPointer": { "type": "line" }, "showContent": true, "alwaysShowContent": false, "showDelay": 0, "hideDelay": 100, "textStyle": { "fontSize": 14 }, "borderWidth": 0, "padding": 5 }, "xAxis": [ { "show": true, "scale": false, "nameLocation": "end", "nameGap": 15, "gridIndex": 0, "inverse": false, "offset": 0, "splitNumber": 5, "minInterval": 0, "splitLine": { "show": false, "lineStyle": { "show": true, "width": 1, "opacity": 1, "curveness": 0, "type": "solid" } }, "data": null } ], "yAxis": [ { "show": true, "scale": false, "nameLocation": "end", "nameGap": 15, "gridIndex": 0, "inverse": false, "offset": 0, "splitNumber": 5, "minInterval": 0, "splitLine": { "show": false, "lineStyle": { "show": true, "width": 1, "opacity": 1, "curveness": 0, "type": "solid" } } } ], "title": [ { "text": "\u5b58\u5728\u663e\u8457\u6027\u9700\u8981\u7684\u6700\u4f4e\u5bf9\u7167\u6df1\u5ea6", "padding": 5, "itemGap": 10 } ] }; chart_13812cd4bbf743a3aa6832fda8950f9b.setOption(option_13812cd4bbf743a3aa6832fda8950f9b);]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2022%2F03%2F18%2FNGS-%E8%82%BF%E7%98%A4%E4%BD%93%E7%B3%BB%E6%A3%80%E6%B5%8B%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E8%83%9A%E7%B3%BB%E8%BF%87%E6%BB%A4%E6%96%B9%E6%A1%88%2FFisher2Depth%2F</url>
    <content type="text"><![CDATA[Awesome-pyecharts var chart_0e47349b1f5b4225b3f4681c0ea134d4 = echarts.init( document.getElementById('0e47349b1f5b4225b3f4681c0ea134d4'), 'white', {renderer: 'canvas'}); var option_0e47349b1f5b4225b3f4681c0ea134d4 = { "animation": true, "animationThreshold": 2000, "animationDuration": 1000, "animationEasing": "cubicOut", "animationDelay": 0, "animationDurationUpdate": 300, "animationEasingUpdate": "cubicOut", "animationDelayUpdate": 0, "color": [ "#c23531", "#2f4554", "#61a0a8", "#d48265", "#749f83", "#ca8622", "#bda29a", "#6e7074", "#546570", "#c4ccd3", "#f05b72", "#ef5b9c", "#f47920", "#905a3d", "#fab27b", "#2a5caa", "#444693", "#726930", "#b2d235", "#6d8346", "#ac6767", "#1d953f", "#6950a1", "#918597" ], "series": [ { "type": "line", "name": "Freq: 1%", "connectNulls": false, "symbolSize": 4, "showSymbol": true, "smooth": false, "clip": true, "step": false, "data": [ [ 0, "1.000" ], [ 50, "1.000" ], [ 100, "1.000" ], [ 150, "0.382" ], [ 200, "0.394" ], [ 250, "0.238" ], [ 300, "0.139" ], [ 350, "0.080" ], [ 400, "0.046" ], [ 450, "0.044" ] ], "hoverAnimation": true, "label": { "show": true, "position": "top", "margin": 8 }, "lineStyle": { "show": true, "width": 1, "opacity": 1, "curveness": 0, "type": "solid" }, "areaStyle": { "opacity": 0 }, "zlevel": 0, "z": 0 }, { "type": "line", "name": "Freq:1.5%", "connectNulls": false, "symbolSize": 4, "showSymbol": true, "smooth": false, "clip": true, "step": false, "data": [ [ 0, "1.000" ], [ 50, "1.000" ], [ 100, "0.390" ], [ 150, "0.248" ], [ 200, "0.095" ], [ 250, "0.056" ], [ 300, "0.033" ], [ 350, "0.019" ], [ 400, "0.011" ], [ 450, "0.006" ] ], "hoverAnimation": true, "label": { "show": true, "position": "top", "margin": 8 }, "lineStyle": { "show": true, "width": 1, "opacity": 1, "curveness": 0, "type": "solid" }, "areaStyle": { "opacity": 0 }, "zlevel": 0, "z": 0 }, { "type": "line", "name": "Freq: 2%", "connectNulls": false, "symbolSize": 4, "showSymbol": true, "smooth": false, "clip": true, "step": false, "data": [ [ 0, "1.000" ], [ 50, "1.000" ], [ 100, "0.250" ], [ 150, "0.100" ], [ 200, "0.039" ], [ 250, "0.024" ], [ 300, "0.008" ], [ 350, "0.005" ], [ 400, "0.001" ], [ 450, "0.001" ] ], "hoverAnimation": true, "label": { "show": true, "position": "top", "margin": 8 }, "lineStyle": { "show": true, "width": 1, "opacity": 1, "curveness": 0, "type": "solid" }, "areaStyle": { "opacity": 0 }, "zlevel": 0, "z": 0 } ], "legend": [ { "data": [ "Freq: 1%", "Freq:1.5%", "Freq: 2%" ], "selected": { "Freq: 1%": true, "Freq:1.5%": true, "Freq: 2%": true }, "show": true, "padding": 5, "itemGap": 10, "itemWidth": 25, "itemHeight": 14 } ], "tooltip": { "show": true, "trigger": "item", "triggerOn": "mousemove|click", "axisPointer": { "type": "line" }, "showContent": true, "alwaysShowContent": false, "showDelay": 0, "hideDelay": 100, "textStyle": { "fontSize": 14 }, "borderWidth": 0, "padding": 5 }, "xAxis": [ { "show": true, "scale": false, "nameLocation": "end", "nameGap": 15, "gridIndex": 0, "inverse": false, "offset": 0, "splitNumber": 5, "minInterval": 0, "splitLine": { "show": false, "lineStyle": { "show": true, "width": 1, "opacity": 1, "curveness": 0, "type": "solid" } }, "data": null } ], "yAxis": [ { "show": true, "scale": false, "nameLocation": "end", "nameGap": 15, "gridIndex": 0, "inverse": false, "offset": 0, "splitNumber": 5, "minInterval": 0, "splitLine": { "show": false, "lineStyle": { "show": true, "width": 1, "opacity": 1, "curveness": 0, "type": "solid" } } } ], "title": [ { "text": "\u663e\u8457\u6027", "padding": 5, "itemGap": 10 } ] }; chart_0e47349b1f5b4225b3f4681c0ea134d4.setOption(option_0e47349b1f5b4225b3f4681c0ea134d4);]]></content>
  </entry>
  <entry>
    <title><![CDATA[Python-包-scikit-learn]]></title>
    <url>%2F2022%2F03%2F17%2FPython-%E5%8C%85-sklearn%2F</url>
    <content type="text"><![CDATA[官方资料scikit-learnscikit-learn Git]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Use of synthetic DNA spike-in controls (sequins) for human genome sequencing]]></title>
    <url>%2F2022%2F03%2F14%2F%E6%96%87%E7%8C%AE-Use_of_synthetic_DNA_spike-in_controls_for_human_genome_sequencing%2F</url>
    <content type="text"></content>
      <categories>
        <category>NGS</category>
        <category>文献</category>
      </categories>
      <tags>
        <tag>变异检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[肿瘤临床检测中的点突变（SNV&InDel）变异检测方案调研]]></title>
    <url>%2F2022%2F03%2F14%2FNGS-%E7%82%B9%E7%AA%81%E5%8F%98%E5%8F%98%E5%BC%82%E6%A3%80%E6%B5%8B%E6%96%B9%E6%A1%88%E8%B0%83%E7%A0%94%2F</url>
    <content type="text"><![CDATA[变异检测变异过滤一些可以获取的临床变异检测资料信息中检院TMB标准化项目采用多个变异检测软件进行交叉验证，而后进行人工审核确认。 全国实体肿瘤体细胞突变 高通量测序（大 Panel）检测借助质评自身的特殊性，通过多家检测机构的结果进行较差验证，按着特定标准筛选获得标准答案集合。 基于IGV的人工审核针对如果对变异结果进行人工审核，2019年有一篇发表在GENETICS IN MEDICINE (IF 9.108)的文章，可以为我们提供一些参考。Standard operating procedure for somatic variant refinement of sequencing data with paired tumor and normal samples其中针对突变审核包含如下过程： 步骤1：把突变可视化 使用IGV观察突变；确保IGV与插件中突变选取保持一致；通过插件的“S”使突变发生reads置顶；确认IGV、插件的reads展示一致； 步骤2：确认支持突变的数量 查看突变的①链方向、总覆盖度、②位点的突变频率、③非突变频率；考虑突变受到的其他因素影响，比如原发性肿瘤 DNA、复发性DNA、肿瘤RNA等； 步骤3：确认支持突变的质量 寻找多个不匹配或者与ref高度差异性的区域；寻找 半透明或透明的reads或碱基(比对质量低的)；①对有疑问reads进一步确认比对质量、碱基质量；②看突变对应的normal检出情况； 步骤4：检查测序误差 ①切换“成对查看”确认短插入片段情况；②IGV缩小确认是否在高度差异性区域，临近区域是否有indel存在；③看参考序列是否在低复杂性区域，是否存在串列重复序列； 步骤5：给突变选择符合哪个Call标签 通过突变质量、突变数量的信息，选择合适的Call标签； 步骤6：给突变选择符合哪个Tag标签 可以对每个突变进行tag标签标记，对Call标记 不确定、失败的突变，尤其重要； 步骤7：给突变写附加的备注信息 其中提供了19中tag，作为变异过滤过程中参考判断的指标 燃石检测流程实际比较难获得泛生子内部资料，只能借助一些发布文章的method，这也往往是一个非常有效的办法。在燃石的官网查到燃石的学术发表找到其中一篇文章从题目看是和NGS检测为主的Evaluating the analytical validity of circulating tumor DNA sequencing assays for precision oncology从文章的method中，我们可以看到泛生子流程的整体检测逻辑如下： 制作模拟数据 通过wgsim (v1.9) 进行数据模拟 变异的分析流程 首先对下机数据进行Trim TrimGalore 使用anaquin 进行sequin（spike-in controls）分析, 将sequin的Reads进行分离，然后矫正到样本相同的深度，并通过Anaquin somatic 进行变异检测。详细见参考文献Use of synthetic DNA spike-in controls (sequins) for human genome sequencing bwa mem (v0.7.16) 进行数据比对，比对到Hg38 剔除捕获区间外的Reads，并用gatk MarkDuplicates (v4.0). 标记重复 VarScan (v2.4.3) 用来进行 SNVs and indels 的检测（最少支持数是3条read-fragments) 泛生子检测流程介绍在泛生子官网查找泛生子的成果,2016:The genome-wide mutational landscape of pituitary adenomas的附件中提到了分析流程 2019:Detection of early-stage hepatocellular carcinoma in asymptomatic HBsAg-seropositive individuals by liquid biopsy 详细分析方法参考文档中提及的方法材料： Sequencing reads were primarily processed with our own program to extract tags and remove sequence adapters. Residual adapters and low-quality regions were subsequently removed using Trimmomatic (v0.36). The cleaned reads were mapped to the hg19 and HBV genomes using ‘bwa(v0.7.10) mem’ with the default parameters. Candidate somatic mutations, consisting of SNP and INDEL, were identified using samtools mpileup (9) across the targeted regions of interest. To ensure accuracy, reads with the same tags, and start and end coordinates were grouped into Unique Identifier families (UID families). UID families containing at least two reads and in which at least 80% of reads were the same type were defined as Effective Unique Identifier families (EUID families). Each mutation frequency was calculated by dividing the number of alternative EUID families by the sum of alternative and reference ones. The mutations were further manually reviewed in IGV. The candidate variations were annotated with Ensembl Variant Effect Predictor (VEP) (10). HBV integrations were identified using Crest (11) , and at least 4 soft-clip reads supports were needed. 世和参考文章Tumor-derived DNA from pleural effusion supernatant as a promising alternative to tumor tissue in genomic profiling of advanced lung cancer Sequencing and data processing Target enriched libraries were sequenced on the HiSeq4000 platform (Illumina) with 2×150bp pair-end reads. Sequencing data were demultiplexed by bcl2fastq (v2.19), analyzed by Trimmomatic 24 to remove low-quality (quality&lt;15) or N bases, mapped to the reference hg19 genome (Human Genome version 19) using the Burrows-Wheeler Aligner. PCR duplicates were removed by Picard. The Genome Analysis Toolkit (GATK) was used to perform local realignments around indels and base quality reassurance. SNPs and indels were called by VarScan2 and HaplotypeCaller/UnifiedGenotyper in GATK, with the mutant allele frequency (MAF) cutoff as 0.5% for tissue samples, 0.1% for liquid biopsy samples, and a minimum of three unique mutant reads. Common variants were removed using dbSNP and the 1000 Genome project. Germline mutations were filtered out by comparing to patient’s whole blood controls. The resulting somatic variants were further filtered through an in-house list of recurrent sequencing errors that was generated from over 10,000 normal control samples on the same sequencing platform. Gene fusions were identified by FACTERA. copy number variations (CNVs) were analyzed with ADTEx . The log2 ratio cut-off for copy number gain was defined as 2.0 for tissue samples and 1.6 for liquid biopsy samples. A log2 ratio cut-off of 0.67 was used for copy number loss detection in all sample types. The thresholds were determined from previous assay validation using the absolute CNVs detected by droplet digital PCR (ddPCR). Allele-specific CNVs were analyzed by FACETS 30 with a 0.2 drift cut-off for unstable joint segments. The proportion of chromosomal instability (CIN) was calculated by dividing the size of drifted segments by the total segment size. Tumor mutational burden (TMB) in this study was defined as the number of somatic synonymous mutations per megabase in each sample, with hotspot/fusion mutations excluded. 贝瑞参考文章Genetic profiling of primary and secondary tumors from patients with lung adenocarcinoma and bone metastases reveals targeted therapy options In brief, DNA extracted from FFPE tissue biopsies was fragmented to an average size of 300 bp, molecules were then end repaired and A-tailed and finally T tailed linkers were ligated on. The added linkers were a mix of 96 different molecular barcodes giving a high probability that each molecule was marked differently at both ends and thus uniquely barcoded. Libraries were amplified by PCR and resulting amplicons captured using biotinylated probes (120 nucleotides) for the 457 genes. Following elution, molecules were re-amplified using complementary sequencing primers and then paired end (PE) sequenced (2 × 150 bp) on the NovaSeq platform (Illumina). Fastq sequencing reads were aligned to the hg19 reference genome using the Burrows Wheeler algorithm (Li and Durbin 2009). The resulting SAM files were converted to BAM file format and then sorted on genome coordinates using Samtools. To remove PCR bias (reads with the same molecular barcodes and same start and same stop positions), only the unique coded molecules were used for copy number analysis. After filtering out low mapping quality reads (MAQ &lt; 20), the average depth of coverage (DoC) for each target was calculated using the GATK Depth Of Coverage algorithm (McKenna et al. 2010). After GC correction using LOESS regression method (Alkan et al. 2009), reads were normalized using the RPKM method (Chiang et al. 2019). For these steps, the tumor and matched normal sample was processed separately. Somatic SNVs and indels were finally identified by MutLoc (Berry Genomics in-house tools, unpublished), which maps the alternative base fraction compared to the hg19 reference genome.]]></content>
      <categories>
        <category>NGS</category>
        <category>变异检测</category>
      </categories>
      <tags>
        <tag>变异检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Software-varscan-变异检测]]></title>
    <url>%2F2022%2F03%2F13%2FSoftware-varscan-%E5%8F%98%E5%BC%82%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[软件相关资源信息 软件文献 VarScan 2: Somatic mutation and copy number alteration discovery in cancer by exome sequencingDaniel Software implementation 软件获取 varscan.sourceforgevarscan.githubThe VarScan 2 core software was developed in Java; the false-positive filter was implemented in Perl. Binary executables, scripts, and source code are free for noncommercial use and available at http://varscan.sourceforge.net.The false-positive filter requires the bam-readcount utility (D. Larson et al., https://github.com/genome/bam-readcount), which is written and compiled in C. Varscan的使用安装下载Varscan的Jar包 使用samtools mpileup -f ref.fasta sample.bam |java -jar VarScan.v2.3.3.jar mpileup2indel–output-vcf 1–vcf-sample-list sample_names.list sample.varscan.vcf]]></content>
      <categories>
        <category>NGS</category>
        <category>software</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>变异检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Software-终端工具-MobaxTerm]]></title>
    <url>%2F2022%2F03%2F08%2FSoftware-%E7%BB%88%E7%AB%AF%E5%B7%A5%E5%85%B7-MobaxTerm%2F</url>
    <content type="text"><![CDATA[解决 MobaxTerm 自动断开链接使用MobaXterm工具通过SSH连接Linux服务器，如果一段时间没有操作，MobaXterm会把连接自动断开，这个设定很是不方便。通过更改下面的设置可以使SSH保持长连接，不会自动断开。分别依次选择setting 》》》 configuration 》》》 ssh SETTINGS然后再配置界面选择 keepalive， 即可保持链接不中断。]]></content>
      <categories>
        <category>software</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>软件工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Software-transvar_变异坐标转换]]></title>
    <url>%2F2022%2F03%2F07%2FSoftware-transvar-%E5%8F%98%E5%BC%82%E5%9D%90%E6%A0%87%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[坐标转换基因组学研究中经常会进行的操作是将测序检测得到的染色体侧面的变异检测结果（SNV、InDel等），注释到基因上，因为大多数功能研究和蛋白研究都是针对基因进行的，将变异注释到基因上，可以更好的帮助我们预测变异对基因表达，和蛋白合成过程中带来的影响，而这个层级的影响可以帮助我们更好的进行功能组学的相关研究。因此一些发表的论文或数据库中经常提到的变异，一般有三种格式：1）基因组坐标：2）cDNA 坐标；3）蛋白氨基酸坐标。举个例子TP53上的某个变异的基因组坐标是g.chr17:74026C&gt;A，cDNA坐标是c.1001G&gt;T，蛋白氨基酸坐标是p.G334V。当然这几种注释的写法都是有标准规范可以参考的，可以参考文章 变异检出标准化-HGVS 在数据分析的过程中经常会遇到这三种坐标相关转换的情况，例如你从文献或者某个数据库中收集到了几百个肿瘤靶向药的用药位点，而你在你样本中检测到了很多变异，想知道你的样本中包含多少收集到的已知的用药位点。但通常文献或者数据库会以第二种或者第三种形式表示变异，而我们自己检测的变异通常会以vcf格式存储，这样就无法直接匹配。当然可以对vcf格式的变异进行ANNOVAR注释，然后对cDNA或者蛋白氨基酸坐标形式的变异进行比较，但尝试过的人都表示特别痛苦：需要考虑的规则太多！尝试两次，还是放弃了：一是匹配规则不通用；二是总担心有没有考虑到过的情况。所以急需一个能完成这种坐标转换的工具。15年发表在NATURE METHODS上的题为：TransVar: a multilevel variant annotator for precision genomics的文章中推出了一款名为TransVar的软件成了解决不同层面变异坐标转换的神器。 文献下载 TransVar软件简介Transvar 是一款多种方向的突变/坐标转换工具，它支持基因组坐标、cDNA 坐标以及蛋白氨基酸坐标之间的转换。 如上图所示，该软件的功能可细分为下面3种：1）正向注释：对于基因组坐标的变异进行mRNA（cDNA）和蛋白注释，这款工具会提供所有的可能结果；2）反向注释：将mRNA（cDNA）坐标和蛋白坐标的变异转换成所有可能基因组坐标形式的变异；3）等价注释：对于某一给定的蛋白坐标的变异，搜索所有可能的与其为相同基因组坐标，但在不同转录本上的蛋白坐标变异。 软件的官方文档 ReadtheDoc 软件的使用Linux版本安装软件下载可以从github仓库获取 通过python 安装12345sudo pip install transvar ## 全局安装，需要root权限或者：pip install --user transvar ##用户安装，没有root权限的用此方法软件更新：pip install -U transvar 数据库的配置链接数据库，可通过命令行添加。最开始，不存在transvar.cfg这个文件，在第一次链接后，会创建transvar.cfg文件，并将你创建的对应关系写入文件中，transvar.cfg 存放的路径：os.path.dirname({PYTHON_PATH})/lib/python3.7/site-packages/transvar/transvar.cfg1234567891011121314151617181920212223242526272829303132# set up databasestransvar config --download_anno --refversion hg19 #默认的hg19的 dbSNP 数据库是2016年的，部分数据库如dbSNP新版数据库收录内容有很大变化（主要是数量的提升），所以建议自行重新下载# in case you don&apos;t have a referencetransvar config --download_ref --refversion hg19# in case you do have a reference to linktransvar config -k reference -v [path_to_hg19.fa] --refversion hg19transvar config -k aceview -v $PATH/hg19.aceview.gff.gz.transvardb --refversion hg19transvar config -k ccds -v $PATH/hg19.ccds.txt.transvardb --refversion hg19transvar config -k ensembl -v $PATH/hg19.ensembl.gtf.gz.transvardb --refversion hg19transvar config -k gencode -v $PATH/hg19.gencode.gtf.gz.transvardb --refversion hg19transvar config -k kg -v $PATH/transvar.download/hg19.knowngene.gz.transvardb --refversion hg19transvar config -k refseq -v $PATH/hg19.refseq.gff.gz.transvardb --refversion hg19transvar config -k ucsc -v $PATH//hg19.ucsc.txt.gz.transvardb --refversion hg19cat lib/python3.7/site-packages/transvar/transvar.cfg[DEFAULT]refversion = hg19[hg19]reference = $PATH/ucsc.hg19.fastarefseq = $PATH/hg19.refseq.gff.gz.transvardbccds = $PATH/hg19.ccds.txt.transvardbucsc = $PATH/hg19.ucsc.txt.gz.transvardbgencode = $PATH/hg19.gencode.gtf.gz.transvardbaceview = $PATH/hg19.aceview.gff.gz.transvardbensembl = $PATH/hg19.ensembl.gtf.gz.transvardbkg = $PATH/hg19.knowngene.gz.transvardb 使用这款软件即可以单点注释，也可以批量处理，下面分别介绍一下： 单点注释用 -i传入待注释位点，包括3种： 1234567891011121314# 基因组正向注释transvar ganno --ccds -i &apos;chr3:g.178936091G&gt;A&apos; # cDNA反向注释transvar canno --ccds -i &apos;PIK3CA:c.1633G&gt;A&apos;# 氨基酸反向注释transvar panno -i &apos;PIK3CA:p.E545K&apos; --ensembl # 已知 p. 进行注释，可以一次只注释一个数据库，也可以同时注释多个数据库transvar panno -i &apos;ERBB2:p.Leu755_Thr759del&apos; --aceview --ccds --ensembl --gencode --kg --refseq --ucsc# 其中--ccds、--ensembl为使用不同的数据库，如网页版，可以同时多选，\# 如 --ccds --ensembl --refseq --ucsc 来进行多选 批量注释 -l传入待注释位点 12345678910/*/software/anaconda3/bin/transvar canno -l mutiation.canno.list -m 1 -o 2 --refseq --longestcoding --gseq ###canno：指cDNA反向注释，备选包括panno（ 蛋白氨基酸反向注释）和ganno（基因组正向注释）-l：输入文件，变异与canno、panno、ganno对应。格式示例如下：![image.png](https://upload-images.jianshu.io/upload_images/22041438-ba466242c2050f60.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)-m：-l指定的输入文件可以有多列，通过-m指定哪列是待注释列，不加-m参数默认是第一列-o：同时可以通过-o来指定-l中的那一列作为输出文件的首列，不加-o，默认是第一列--refseq：使用哪个数据库的转录本进行注释，还有其他数据库可选如 ensembl/gencode/ucsc/ccds/aceview等。--longestcoding： 有多个转录本时，仅选择最长的转录本。如果不加这个参数会把涉及到的所有转录本都输出出来，这时候你就要自己制定标准进行筛选了--gseq ：在输出文件中增加类似VCF格式的变异信息，包括染色体，起始位置，终止位置，参考基因组序列，突变后的序列。 网页版Transvar Web版使用相对比较简单，界面也非常清晰]]></content>
      <categories>
        <category>NGS</category>
        <category>software</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>格式转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS_Code-提升效率的配置]]></title>
    <url>%2F2022%2F03%2F03%2FSoftware-%E7%BC%96%E7%A8%8B%E7%BB%88%E7%AB%AF-VSCode-2.%E5%B8%B8%E7%94%A8%E6%89%A9%E5%B1%95%2F</url>
    <content type="text"><![CDATA[pythonA Visual Studio Code extension with rich support for the Python language (for all actively supported versions of the language: &gt;=3.7), including features such as IntelliSense (Pylance), linting, debugging, code navigation, code formatting, refactoring, variable explorer, test explorer, and more!可以一键进行python代码的格式化。 SnippetsSnippets 是节约时间提高生产力的最好办法。这并不是单单某一个语言的扩展，而是多种语言的各种扩展。下面是一些流行的 Snippets 扩展： Angular Snippts (version 11) Python JavaScript (ES6) code snippets HTML Snippets ES7 React/Redux/GraphQL/React-Native snippets Vue 3 Snippets Markdown All in OneMarkdownAll in One可以处理所有的markdown需求，例如自动预览、快捷键、自动完成等。 从2004年发布以来，Markdown已成为最流行的标记语言之一。技术作者广泛使用Markdown转写文章、博客、文档等，因为它十分轻便、简单，而且可以在多个平台上使用。它的流行带动了许多Markdown变体的出现，如GitHub Flavored markdown、MDX等。 例如，要在Markdown中加粗字体，只需要选中文字按快捷键Ctrl+B即可，这样可以提高生产力。 Icons描述性的图标可以帮你区分不同的文件和文件夹。图标也让开发过程更有趣。 下面是两个VSCode标签页的比较。一个有图标，另一个没有。有许多图标扩展可供选择。流行的图标扩展有： vscode-icons Material Icon ThemeMaterial Theme Icons Simple icons Settings Sync使用多台机器时，该扩展将大有帮助。Settings sync让所有电脑/笔记本电脑依照visual studio的设置方式实现同步。 同时在办公室电脑和家用电脑上工作的开发人员，基本上会在不同的地点工作。手动更改两端设置极为耗时，因为需要根据正在做的项目不时更改设置以便缓解编程压力。建议使用这个扩展,以便将所有所作更改都自动同步到个人电脑和工作点。 Code Runner在编辑器里运行js代码，同时可在terminal里显示打印结果的工具，方便调试代码,支持多种语言比如 C++, Python, Java等等 guides显示代码对齐辅助线，很好用 ESLint/TSLint(未测试使用)此扩展的主要功能是自动格式化代码，以便在整个团队中实现一致的格式化。ESLint也可以配置为自动格式化代码，无论何时出现错误，它都会发出一连串的警告。]]></content>
      <categories>
        <category>software</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Software-编程终端-VSCode-1.基本配置]]></title>
    <url>%2F2022%2F03%2F03%2FSoftware-%E7%BC%96%E7%A8%8B%E7%BB%88%E7%AB%AF-VSCode-1.%E5%9F%BA%E6%9C%AC%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[创建特定类型的文件模板在进行代码开发时，每次我们都需要手动填写名称，时间，作者等一些重复的基本信息，其实非常浪费时间，而且通过使用模板，可以帮我们节省这部分时间，更多的时间用在编程本身。使用vs code开发python代码的时候，可以建立自定义的模板，大大的提高效率。File-&gt;Preferences-&gt;User Snippets（用户-&gt;首选项-&gt;用户片段）可以对应的编程语言，以python为例，选择后会打开一个python.json的文件进行编辑。把原来的内容删除，输入下面的内容：1234567891011121314151617181920212223242526272829303132333435363738&#123; &quot;HEADER&quot;:&#123; &quot;prefix&quot;: &quot;template&quot;, &quot;body&quot;: [ &quot;#!/usr/bin/python&quot;, &quot;# -*- encoding: utf-8 -*-&quot;, &quot;&apos;&apos;&apos;&quot;, &quot;@File : $TM_FILENAME&quot;, &quot;@Time : $CURRENT_YEAR/$CURRENT_MONTH/$CURRENT_DATE $CURRENT_HOUR:$CURRENT_MINUTE:$CURRENT_SECOND&quot;, &quot;@Author : Liu.Bo &quot;, &quot;@Version : 1.0&quot;, &quot;@Contact : liubo4@genomics.cn/614347533@qq.com&quot;, &quot;@WebSite : http://www.ben-air.cn/&quot;, &quot;&apos;&apos;&apos;&quot;, &quot;import logging&quot;, &quot;from logging.handlers import RotatingFileHandler&quot;, &quot;&quot;, &quot;def log_config():&quot;, &quot; LOG_FORMAT = &apos;[%(asctime)s][%(levelname)s]: %(message)s&apos;&quot;, &quot; level = logging.INFO&quot;, &quot; logging.basicConfig(level=level, format=LOG_FORMAT)&quot;, &quot; #创建RotatingFileHandler对象,满2MB为一个文件，共备份3个文件&quot;, &quot; log_file_handler = RotatingFileHandler(filename=&apos;test.log&apos;, maxBytes=2*1024*1024, backupCount=3)&quot;, &quot; # 设置日志打印格式&quot;, &quot; formatter = logging.Formatter(LOG_FORMAT)&quot;, &quot; log_file_handler.setFormatter(formatter)&quot;, &quot; logging.getLogger(&apos;&apos;).addHandler(log_file_handler)&quot;, &quot;&quot;, &quot;def main():&quot;, &quot; log_config()&quot;, &quot;&quot;, &quot;if __name__ == &apos;__main__&apos;:&quot;, &quot; main()&quot;, &quot;&quot;, &quot;$0&quot; ], &#125; &#125; 然后再次创建python脚本后，输入template（prefix 对应的内容） 就可以将编程模板填充到代码中]]></content>
      <categories>
        <category>software</category>
        <category>Windows</category>
      </categories>
      <tags>
        <tag>环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Standard operating procedure for somatic variant refinement of sequencing data with paired tumor and normal samples]]></title>
    <url>%2F2022%2F02%2F24%2FPaper-PMID-30287923%2F</url>
    <content type="text"><![CDATA[该文献对突变的人工审核方案进行了 参考材料参考文献参考附件参考PPT]]></content>
      <categories>
        <category>NGS</category>
        <category>肿瘤检测</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[常用数据库-Uniprot]]></title>
    <url>%2F2022%2F02%2F24%2FDatabase-Uniport%2F</url>
    <content type="text"><![CDATA[最近由于临床报告中需要展示一些Uniprot的相关信息字段，因此需要对Uniprot中的部分重要信息进行获取，从而后续实现数据的本地化。因此需要对Uniprot数据库的使用方法和数据查询的机制进行了一些了解，记录如下 数据库简介维护机构通用蛋白质资源(UniProt)是蛋白质序列和注释数据的综合资源。 UniProt数据库包括UniProtKB (UniProt知识库)、UniRef (UniProt Reference Clusters)和UniProt Archive (UniParc)。 UniProt是欧洲生物信息学研究所(EMBL-EBI)、SIB瑞士生物信息学研究所(SIB Swiss Institute of Bioinformatics)和蛋白质信息资源研究所(PIR)的合作项目。UniProt联盟和主办机构EMBL-EBI、SIB和PIR都致力于长期保存UniProt数据库。 EMBL-EBI和SIB共同用于生成Swiss-Prot**和TrEMBL**, PIR生成Protein Sequence Database (PIR- psd)。 这两个数据集同时存在，但蛋白质序列覆盖范围和注释优先级不同。 TrEMBL(翻译后的EMBL核苷酸序列数据库)最初创建是因为序列数据的生成速度超过了Swiss-Prot的能力。 与此同时，PIR维护了PIR- psd及相关数据库，包括蛋白质序列数据库iProClass和整理的家族库。 2002年，这三家机构决定集中他们的资源和专业知识，成立了UniProt联盟。 EBI（ European Bioinformatics Institute）：欧洲生物信息学研究所（EMBL-EBI）是欧洲生命科学旗舰实验室EMBL的一部分。位于英国剑桥欣克斯顿的惠康基因组校园内，是世界上基因组学领域最强地带之一。 SIB（the Swiss Institute of Bioinformatics）：瑞士日内瓦的SIB维护着ExPASy（专家蛋白质分析系统）服务器，这里包含有蛋白质组学工具和数据库的主要资源。 PIR（Protein Information Resource）：PIR由美国国家生物医学研究基金会（NBRF）于1984年成立，旨在协助研究人员识别和解释蛋白质序列信息。 数据库组成截至目前数据库共包含4个subDatabase The UniProt Knowledgebase (UniProtKB)UniProt知识库， 特别是UniProtKB/Swiss-Prot，被用来访问蛋白质的功能信息。 每个UniProtKB条目都包含了氨基酸序列、蛋白质名称或描述、分类数据和引文信息，除此之外，我们还添加了尽可能多的注释。 这包括广泛接受的生物本体、分类和交叉引用，以及以实验和计算数据的证据归因的形式明确标注标注质量。 UniProt Reference Clusters (UniRef)UniRef数据库提供来自UniProtKB和UniParc记录的聚类序列集，以提供多个分辨率的序列空间的完整覆盖。 UniRef90和UniRef50的数据库大小分别减少了约40%和65%，提供了显著更快的序列搜索。 UniProt Archive (UniParc)UniParc是最全面的公开可访问的非冗余蛋白质序列数据库，提供这些序列的所有潜在来源和版本的链接。 你可以立即发现一个感兴趣的序列是否已经在公共领域，如果不是，就找出它最近的亲属。 UniProt Metagenomic and Environmental Sequences (UniMES)UniMES是一个专门存储宏基因组和环境数据的数据库。 更多详细信息可以参考官方说明文档 数据库使用UniProtKB 的使用由于本次数据的获取信息，均来自于Uniport的知识库，目前主要针对知识库进行介绍。进入知识库的主页,看到的信息如下图： 最上面是 搜索框， 左侧可以进行数据的过滤，例如肿瘤数据关注点主要是人的基因信息，可以直接选择Human剔除掉一些非人源的数据信息。 中间就是整个数据库数据的展示了。 重点介绍数据内容主题框的上面两个功能 Download 和 Columns Download字面意思，进行数据的下载，可以选择多种数据格式进行数据下载，tsv、gff、xml、fasta等等，我们可以根据需要选择相关格式进行下载 Columns这个功能可以说是一个非常人性化的功能，尤其是结合Download，可以完全不适用爬虫获取该数据库的所有需要的信息，点击进入Columns后，可以筛选在汇总表格中需要展示的字段信息（具体那些字段需要，可以在详细表中进行获取，毕竟下数据了，我们首先要知道获取什么数据）。示例如下图勾选我们需要的信息后，点击下方的 save, 就可以在内容中现实特定的信息，结合Download，可以实现快速的数据获取。 获取信息后，在进行简单的格式整理，就可以直接使用了，相比那些验收、IP检测、流量限制等方案层出不确定网站，可以说是非常友好了。 BGI的下载与处理需要的信息列： Entry (Names &amp; Taxonomy) Entry name (Names &amp; Taxonomy) Gene names (Names &amp; Taxonomy) Organism (Names &amp; Taxonomy) Length (Sequences) Repeat (Family &amp; Domains) Region (Family &amp; Domains) Zinc finger (Family &amp; Domains) Domain [FT] (Family &amp; Domains) Nucleotide binding (Function) Cross-reference (GeneID) DNA binding (Function) 基于肿瘤2022.3.1的解读需求，可以参考进行下载%20[9606]%22&amp;format=tab&amp;force=true&amp;columns=id,entry%20name,genes,organism,length,feature(REPEAT),feature(REGION),feature(ZINC%20FINGER),feature(DOMAIN%20EXTENT),feature(NP%20BIND),database(GeneID)&amp;sort=score&amp;compress=yes) 下载后，流程处理脚本使用 toolkits/07.DealWithDatabase/UniprotKB_DataClean.py（GitHub仓库） 对数据进行处理。处理后的文件结果示例如下： Gene GeneID GeneLength feature_key Position_region Uniport_description BLK 640; 505 Region 1..37; “Disordered” BLK 640; 505 Domain [FT] 58..118; “SH3” BLK 640; 505 Domain [FT] 124..220; “SH2” BLK 640; 505 Domain [FT] 241..494; “Protein kinase” BLK 640; 505 Nucleotide binding 247..255; “ATP” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Repeat 823..877; “1; approximate” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Repeat 878..932; “2” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Repeat 933..987; “3” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Repeat 988..1040; “4” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Repeat 1041..1094; “5” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Repeat 1095..1148; “6” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Repeat 1149..1203; “7” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Repeat 1204..1257; “8; approximate” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Repeat 1258..1327; “9; approximate” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Region 1..299; “Interaction with ZBTB43” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Region 1..142; “Disordered” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Region 193..241; “Disordered” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Region 355..470; “Required for phosphorylation by CSNK2A1” BDP1 KIAA1241 KIAA1689 TFNR 55814; 2624 Region 379..449; “Disordered”]]></content>
      <categories>
        <category>知识沉淀</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[math-百分位数的计算说明]]></title>
    <url>%2F2022%2F02%2F20%2Fmath-%E7%99%BE%E5%88%86%E4%BD%8D%E6%95%B0%E7%9A%84%E8%AE%A1%E7%AE%97%E8%AF%B4%E6%98%8E%2F</url>
    <content type="text"><![CDATA[定义统计学术语，如果将一组数据从小到大排序，并计算相应的累计百分位，则某一百分位所对应数据的值就称为这一百分位的百分位数。可表示为：一组n个观测值按数值大小排列。如，处于p%位置的值称第p百分位数。 说明一：用99个数值或99个点，将按大小顺序排列的观测值划分为100个等分，则这99个数值或99个点就称为百分位数，分别以Pl，P2，…，P99代表第1个，第2个，…，第99个百分位数。第j个百分位数j=1,2…100。式中Lj，fj和CFj分别是第j个百分位数所在组的下限值、频数和该组以前的累积频数，Σf是观测值的数目。百分位通常用第几百分位来表示，如第五百分位，它表示在所有测量数据中，测量值的累计频次达5%。以身高为例，身高分布的第五百分位表示有5%的人的身高小于此测量值，95%的身高大于此测量值。百分位数则是对应于百分位的实际数值。= 说明二：第25百分位数又称第一个四分位数（First Quartile），用Q1表示；第50百分位数又称第二个四分位数（Second Quartile），用Q2表示，该值对应的也是中位数；第75百分位数又称第三个四分位数（Third Quartile）,用Q3表示。若求得第p百分位数为小数，可完整为整数。分位数是用于衡量数据的位置的量度，但它所衡量的，不一定是中心位置。百分位数提供了有关各数据项如何在最小值与最大值之间分布的信息。对于无大量重复的数据，第p百分位数将它分为两个部分。大约有p%的数据项的值比第p百分位数小；而大约有(100-p)%的数据项的值比第p百分位数大。对第p百分位数，严格的定义如下。第p百分位数是这样一个值，它使得至少有p%的数据项小于或等于这个值，且至少有(100-p)%的数据项大于或等于这个值。高等院校的入学考试成绩经常以百分位数的形式报告。比如，假设某个考生在入学考试中的语文部分的原始分数为54分。相对于参加同一考试的其他学生来说，他的成绩如何并不容易知道。但是如果原始分数54分恰好对应的是第70百分位数，我们就能知道大约70%的学生的考分比他低，而约30%的学生考分比他高。 计算原理下面的步骤来说明如何计算第p百分位数。 方法一第1步：以递增顺序排列原始数据（即从小到大排列）。第2步：计算指数i=n * p%第3步：l）若 i 不是整数，将 i 向上取整。大于i的毗邻整数即为第p百分位数的位置。2) 若i是整数，则第p百分位数是第i项与第(i+l)项数据的平均值。 方法二除了以上方法，再介绍另外一种方法，这种方法是SPSS所用方法，也是SAS所用方法之一。第一步：将n个变量值从小到大排列，X(j)表示此数列中第j个数。第二步：计算指数，设(n+1)P%=j+g，j为整数部分，g为小数部分。第三步：1)当g=0时：P百分位数=X(j);2)当g≠0时：P百分位数=gX(j+1)+(1-g)X(j)=X(j)+g*[X(j+1)-X(j)]。 相关代码函数pyhton123456789101112131415import numpy as np a = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])# 中位数print(np.median(a))# 25%分位数print(np.percentile(a, 25))# 75%分位数print(np.percentile(a, 75))# 输出结果：5.53.257.75]]></content>
      <categories>
        <category>知识沉淀</category>
      </categories>
      <tags>
        <tag>统计学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git.常见问题]]></title>
    <url>%2F2022%2F02%2F08%2FGit-%E5%BC%82%E5%B8%B8%E9%97%AE%E9%A2%98%E5%A4%84%E7%90%86%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[终端使用git 命令中文显示异常执行如下配置git config配置，可以正常显示中文1git config --global core.quotepath false]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>问题处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[肿瘤体系检测过程中的胚系过滤方案]]></title>
    <url>%2F2022%2F01%2F20%2FNGS-%E8%82%BF%E7%98%A4%E4%BD%93%E7%B3%BB%E6%A3%80%E6%B5%8B%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E8%83%9A%E7%B3%BB%E8%BF%87%E6%BB%A4%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[他们是怎么做的？目前已经发表的一些体系检测软件，引用了一些检测方法，为我们提供了参考。主要有3个相对比较主流的方案： 从体系检测结果中减去胚系检出结果 体细胞变异调用者使用贝叶斯方法 Fisher精确统计方法 Fisher 检验（目前产品在用）参考文献[1] Hansen N F , Gartner J J , Lan M , et al. Shimmer: detection of genetic alterations in tumors using next-generation sequence data.[J]. Bioinformatics, 2013(12):1498-1503.[2] Koboldt D C , Zhang Q , Larson D E , et al. VarScan 2: Somatic mutation and copy number alteration discovery in cancer by exome sequencing[J]. Genome Research, 2012, 22(3):568-576. 介绍以Varscan为例，基于Fisher检验是否存在显著性（Pvalue &lt; 0.1) ，及双端情况将数据划分为3类（LOH、Germline、Somatic）。 补充说明因为目前监测体系变异检测，会涉及到一些低频检测需求(1%甚至更低的频率检测需求)，在临床使用中，发现一个难以避免的问题，会存在由于对照深度不足导致的P值永远难以显著（即使对照纯阴性也无法存在显著性差异）。模拟统计计算如下：组织深度1200x； 对照纯阴性。（对照阈值300x）对于检测限 1% 的突变（组织/血浆测序深度1200x时)，对照只有达到 389x 以上时，才可能有显著性。对于一个 3% 的突变（组织/血浆测序深度1200x时)，对照只有达到 127x 以上时，才可能有显著性。对于一个 0.5% 的突变（组织/血浆测序深度1200x时)，对照只有达到 843x 以上时，才可能有显著性。 WES产品 500x；对照纯阴性。（对照阈值200x）针对检测限 3% 的突变，纯阴对照需要达到 133x 才能存在显著性。针对一个 1% 的突变，纯阴对照需要达到 506x 才能存在显著性。 做减法参考文献[1] A comparative analysis of algorithms for somatic SNV detection in cancer.[J]. Bioinformatics, 2013.[2] GATK mutect2 介绍以GATK为例 A variant allele in the case sample is not called if the site is variant in controls.We explain an exception for GATK4 Mutect2 in a bit.Historically, somatic callers have called somatic variants at the site-level. That is, if a variant site in the case is also variant in the matched control or in a population resource, e.g. dbSNP, even if the variant allele is different than the control or resource it is discounted from the somatic callset. This practice stems in part from cancer study designs where the control normal sample is sequenced at much lower depth than the case tumor sample. Because of the assumption mutations strike randomly, cancer geneticists view mutations at sites of common germline variation with skepticism. Remember for humans, common germline variant sites occur roughly on average one in a thousand reference bases. So if a commonly variant site accrues additional mutations, we must weigh the chance of it having arisen from a true somatic event or it being something else that will likely not add value to downstream analyses. For most sites and typical analyses, the latter is the case. The variant is unlikely to have arisen from a somatic event and more likely to be some artifact or germline variant, e.g. from mapping or cross-sample contamination.GATK4 Mutect2 still applies this practice in part. The tool discounts variant sites shared with the panel of normals or with a matched normal control’s unambiguously variant site. If the matched normal’s variant allele is supported by few reads, at low allele fraction, then the tool accounts for the possibility of the site not being a germline variant.When it comes to the population germline resource, GATK4 Mutect2 distinguishes between the variant alleles in the germline resource and the case sample. That is, Mutect2 will call a variant site somatic if the allele differs from that in the germline resource. [1] A comparative analysis of algorithms for somatic SNV detection in cancer.[J]. Bioinformatics, 2013.[2] GATK mutect2 体细胞变异调用者使用贝叶斯方法参考文献[1] Cibulskis K , Lawrence M S , Carter S L , et al. Sensitive detection of somatic point mutations in impure and heterogeneous cancer samples[J]. Nature Biotechnology, 2013, 31(3):213-219.[2] Christopher, T, Saunders, et al. Strelka: accurate somatic small-variant calling from sequenced tumor-normal sample pairs.[J]. Bioinformatics, 2012.[3] Yuichi S , Yusuke S , Kenichi C , et al. An empirical Bayesian framework for somatic mutation detection from cancer genome sequencing data[J]. Nucleic Acids Research, 2013(7):e89-e89.[4] SomaticSniper[J]. Bioinformatics, 2012.[5] Identification of somatic mutations in cancer through Bayesian-based analysis of sequenced genome pairs[J]. Bmc Genomics, 2013, 14.]]></content>
      <categories>
        <category>NGS</category>
        <category>标准化</category>
        <category>变异检测</category>
      </categories>
      <tags>
        <tag>变异检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGS检测相关缩略语说明表]]></title>
    <url>%2F2022%2F01%2F10%2F2022-01-10.NGS%E6%A3%80%E6%B5%8B%E7%9B%B8%E5%85%B3%E7%BC%A9%E7%95%A5%E8%AF%AD%E8%AF%B4%E6%98%8E%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[NGS检测相关实验方向 缩略语 全称 含义说明 PEC 延伸型探针捕获(Probe Extension Capture) 一种先使探针与目标区域上游结合，然后以探针为引物通过PCR延伸获取目标区域DNA序列的捕获技术。 PE测序 双端(Pair-End)测序 - 。 信息分析方向 缩略语 全称 含义说明 VAF 突变频率(Variant Allele Frequency) 基因组某个位点支持突变的reads覆盖深度占这个位点总reads覆盖深度的比例。 Dup 肿瘤检测相关 缩略语 全称 含义说明 UMI Unique molecular identifiers 对原始样本基因组打断后的每一个片段都加上一段特有的标签序列，用于区分同一样本中成千上万的不同的片段，在后续的数据分析中可以通过这些标签序列来排除由于 DNA 聚合酶和扩增以及测序过程中所引入的错误。 MSI Microsatellite Instability 与正常组织相比，肿瘤中某个微卫星位点由于重复单元的插入或缺失而出现新的微卫星等位基因的现象。 MSI的发生是由于肿瘤组织的DNA错配修复出现功能性缺陷导致。 伴随着DNA错配修复缺陷的MSI现象是临床上的一项重要的肿瘤标志物。 临床医学相关 缩略语 全称 含义说明 DLT 剂量限制性毒性 是基于系统性抗癌症治疗在第一个周期中出现严重毒性来定义的。 此类毒性是根据美国国家癌症研究所的不良事件通用术语标准（CTCAE）进行评估的，通常涵盖所有3级或更高的毒性，定义时一般会将3级非发热性中性粒细胞减少症和脱发作为例外。 MTD 最大耐受剂量 RP2D II期推荐剂量 DOR 缓解持续时间 CR 完全缓解(complete response) 所有靶病灶消失，无新病灶出现，且肿瘤标志物正常，至少维持4周。 PR 部分缓解(partial response) 靶病灶最大径之和减少≥30%，至少维持4周。 PD 疾病进展(progressive disease) 靶病灶最大径之和至少增加≥20%，或出现新病灶。 SD 疾病稳定(stable disease) 靶病灶最大径之和缩小未达PR，或增大未达PD。 OS 总生存期(overall survival) 从随机化（random assignment）开始至因任何原因引起死亡的时间（失访患者为最后一次随访时间；研究结束时仍然存活患者，为随访结束日）。 MST 中位生存期(Median Survival Time) 又称为半数生存期，表示有且只有50%的个体可以活过这个时间。评估某个癌种的中位生存期，一般从发现该肿瘤开始计算；如果是评估某项临床试验的中位生存期，一般从给药或随机开始。 DFS 无病生存期/无疾病生存时间 (Disease Free Survival) 指从随机化开始至第一次肿瘤复发/转移或由于任何原因导致受试者死亡的时间(失访患者为最后一次随访时间；研究结束时仍然存活患者，为随访结束日)。 中位DFS 中位DFS 又称半数无病生存期，表示恰好有50％的个体未出现复发/转移的时间。 TTP 疾病进展时间 (，Time To Progression) 指从随机分组开始到第一次肿瘤客观进展的时间。(TTP与PFS唯一不同在于PFS包括死亡，而TTP不包括死亡。因此PFS更能预测和反应临床受益，与OS一致性更好；而TTP在预测临床受益方面则较差，因其仅考虑抗肿瘤活性，在分析时较早时期的死亡情况被删失，导致一些重要信息的丢失。在导致死亡的非肿瘤原因多于肿瘤原因的情况下，TTP是一个合适的指标。TTP同样也需有明确的定义。) PFS 无进展生存期(Progress Free Survival) 指从随机分组开始到第一次肿瘤进展或死亡时间。通常作为晚期肿瘤疗效评价的重要指标。 ORR 客观缓解率(Objective Response Rate) 是指肿瘤缩小达到一定量并且保持一定时间的病人的比例(主要针对实体瘤)，包含完全缓解(CR，Complete Response)和部分缓解(PR，Partial Response)的病例。(客观缓解率是II期试验的主要疗效评价指标，可提供药物具有生物活性的初步证据。但一般不作为III期临床试验的主要疗效指标。) DCR 疾病控制率 (DCR，Disease Control Rate) 是指肿瘤缩小或稳定且保持一定时间的病人的比例(主要针对实体瘤)，包含完全缓解(CR，Complete Response)、部分缓解(PR，Partial Response)和稳定(SD，Stable Disease)的病例 DOR 缓解持续时间 (DOR，Duration of Response) 是指肿瘤第一次评估为CR或PR开始到第一次评估为PD(Progressive Disease)或任何原因死亡的时间。 TTF 治疗失败时间(TTF，Time To Failure) 是指从随机化开始至治疗中止/终止的时间，包括任何中止/终止原因，如疾病进展、死亡、由于不良事件退出、受试者拒绝继续进行研究或者使用了新治疗的时间。(TTF综合了有效性与毒性的评价，是一个具有综合特性的指标，不推荐作为单独支持药物批准的疗效指标。) DDC 疾病控制时间 (DDC，duration of disease control) 是指肿瘤第一次评估为CR、PR或SD开始到第一次评估为PD(Progressive Disease)或任何原因死亡的时间。 OS 总生存期（OS，overall survival） 从随机化（random assignment）开始至因任何原因引起死亡的时间（失访患者为最后一次随访时间；研究结束时仍然存活患者，为随访结束日）。 DOR 总缓解期（Duration of overall response） 从第一次出现CR或PR，到第一次诊断PD或复发的时间。 DSD 疾病稳定期（duration of stable disease） 是指从治疗开始到评价为疾病进展时的这段时间。 ORR 总缓解率 （ORR，overall response rate） 经过治疗CR+PR病人总数占对于总的可评价病例数的比例。 RR 缓解率（RR, response rate） 达到CR、PR的病人占同期病人总数的百分比。 CBR 临床获益率（CBR，clinical benefit rate） CR+PR+SD。]]></content>
      <categories>
        <category>NGS</category>
        <category>知识沉淀</category>
        <category>肿瘤检测</category>
        <category>缩略语</category>
      </categories>
      <tags>
        <tag>数据积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[肿瘤相关融合人群检出率报道]]></title>
    <url>%2F2022%2F01%2F07%2F2022-01-07.%E8%82%BF%E7%98%A4%E7%9B%B8%E5%85%B3%E8%9E%8D%E5%90%88%E4%BA%BA%E7%BE%A4%E6%A3%80%E5%87%BA%E7%8E%87%E6%8A%A5%E9%81%93%2F</url>
    <content type="text"><![CDATA[NTRK 相关融合参考文献Genomic context of NTRK1/2/3 fusion-positive tumours from a large real-world population 内容本研究旨在查询综合基因组分析数据的大型真实世界数据库，以描述NTRK基因融合的基因组景观和流行情况。NTRK融合阳性肿瘤是从超过 295,000 名癌症患者的 FoundationCORE ®数据库中确定的。我们调查了NTRK融合的患病率和伴随的基因组景观，预测了患者血统，并将 FoundationCORE 队列与 entrectinib 临床试验队列进行了比较 (ALKA-372-001 [EudraCT 2012-000148-88]; STARTRK-1 [NCT02097810-2]; [NCT02568267]）。整体NTRK在具有 88 个独特融合伴侣对的 45 种癌症中，融合阳性肿瘤的患病率为 0.30%，其中 66% 以前未报告过。在所有病例中，≥18 岁和 &lt;18 岁患者的患病率分别为 0.28% 和 1.34%；5 岁以下患者的患病率最高 (2.28%)。在唾液腺肿瘤中观察到NTRK融合的最高流行率(2.62%)。存在NTRK基因融合并没有与其他临床生物标志物可操作相关成分; 在乳腺癌或结直肠癌 (CRC) 中没有与已知的致癌驱动因素同时发生。然而，在 CRC 中，NTRK融合阳性与自发性微卫星不稳定性 (MSI) 相关；在这个 MSI CRC 子集中，与BRAF互斥观察到突变。NTRK融合阳性肿瘤类型在 FoundationCORE 和 entrectinib 临床试验中具有相似的频率。NTRK基因融合患病率因年龄、癌症类型和组织学而异。询问大型数据集有助于更好地了解癌症非常罕见的分子亚群的特征，并允许识别基因组模式和以前未报告的融合伙伴，在较小的数据集中不明显。 数据展示：]]></content>
      <categories>
        <category>NGS</category>
        <category>知识沉淀</category>
        <category>肿瘤检测</category>
        <category>数据积累</category>
      </categories>
      <tags>
        <tag>数据积累</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常见融合检测阳性率报道]]></title>
    <url>%2F2022%2F01%2F07%2F2022-01-07.maf%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[NTRK1/2/3本研究旨在查询综合基因组分析数据的大型真实世界数据库，以描述NTRK基因融合的基因组景观和流行情况。NTRK融合阳性肿瘤是从超过 295,000 名癌症患者的 FoundationCORE ®数据库中确定的。我们调查了NTRK融合的患病率和伴随的基因组景观，预测了患者血统，并将 FoundationCORE 队列与 entrectinib 临床试验队列进行了比较 (ALKA-372-001 [EudraCT 2012-000148-88]; STARTRK-1 [NCT02097810-2]; [NCT02568267]）。整体NTRK在具有 88 个独特融合伴侣对的 45 种癌症中，融合阳性肿瘤的患病率为 0.30%，其中 66% 以前未报告过。在所有病例中，≥18 岁和 &lt;18 岁患者的患病率分别为 0.28% 和 1.34%；5 岁以下患者的患病率最高 (2.28%)。在唾液腺肿瘤中观察到NTRK融合的最高流行率(2.62%)。存在NTRK基因融合并没有与其他临床生物标志物可操作相关成分; 在乳腺癌或结直肠癌 (CRC) 中没有与已知的致癌驱动因素同时发生。然而，在 CRC 中，NTRK融合阳性与自发性微卫星不稳定性 (MSI) 相关；在这个 MSI CRC 子集中，与BRAF互斥观察到突变。NTRK融合阳性肿瘤类型在 FoundationCORE 和 entrectinib 临床试验中具有相似的频率。 参考文献Genomic context of NTRK1/2/3 fusion-positive tumours from a large real-world population]]></content>
      <categories>
        <category>NGS</category>
        <category>知识沉淀</category>
        <category>文件格式</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>文件格式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[肿瘤相关融合人群检出率报道]]></title>
    <url>%2F2022%2F01%2F07%2F%E8%82%BF%E7%98%A4-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5%2F</url>
    <content type="text"><![CDATA[概念tumorTumors 更多的是指肿块，但这些肿块并非全部都是恶性的，其中存在一些是良性，所以需要记住 tumors 和 cancers 并非同义词。 cancers是tumors中的一部分（恶性部分）。 cancer是tumor中的一种，特指恶性肿瘤（malignant tumor），癌症是用来形容具有异常的失控的细胞分裂，并能侵入其他组织的疾病的一个术语。癌细胞可通过血液和淋巴系统扩散到身体的其他部位。cancer本身也不是一个单一的疾病而是100多种癌症的总称。大多数癌症以其出现的器官或细胞类型命名， 例如，始发于结肠的癌症，被称为结肠癌，始发于皮肤基底细胞的癌症称为基底细胞癌。 癌症类型可归为广义范畴。癌症的种类主要包括： Carcinomacancer that begins in the skin or in tissues that line or cover internal organs. 癌-起始于皮肤或组织，呈线条状或覆于内脏的癌症。 Sarcoma（肉瘤）cancer that begins in bone, cartilage, fat, muscle, blood vessels, or other connective or supportive tissue.起始于骨，软骨，脂肪，肌肉，血管，或其他结缔组织或支持组织的癌症。 Leukemia（白血病）cancer that starts in blood-forming tissue such as the bone marrow and causes large numbers of abnormal blood cells to be produced and enter the blood.起始于造血组织，如骨髓，可生成大量异常血细胞并进入血液的癌症。 Lymphoma and myeloma（淋巴瘤和骨髓瘤）cancers that begin in the cells of the immune system.起始于免疫系统细胞的癌症 Central nervous system cancers（中枢神经系统癌症）cancers that begin in the tissues of the brain and spinal cord.起始于大脑和脊髓组织的癌症。 癌症的起源All cancers begin in cells, the body’s basic unit of life. To understand cancer, it’s helpful to know what happens when normal cells become cancer cells. 所有的癌症起始于细胞---人体基本的生命单位。为了理解癌症，了解正常细胞何时会变为癌细胞非常有用。 The body is made up of many types of cells. These cells grow and divide in a controlled way to produce more cells as they are needed to keep the body healthy. When cells become old or damaged, they die and are replaced with new cells. 身体是由许多类型的细胞构成。因为他们需要保持身体健康，这些细胞在一个可控制的方式下生长和分化，以产生更多的细胞。当细胞衰老或损坏时，细胞死亡并被新的细胞所取代。 However, sometimes this orderly process goes wrong. The genetic material (DNA) of a cell can become damaged or changed, producing mutations that affect normal cell growth and division. When this happens, cells do not die when they should and new cells form when the body does not need them. The extra cells may form a mass of tissue called a tumor. 但是，有时这种有序的过程也会出现错误。一个细胞的遗传物质（DNA），可受损或改变，产生基因突变，从而影响正常的细胞生长和分裂。在这种情况下，细胞应该死亡但并未死亡，身体并不需要时新细胞形成。额外的细胞可能形成一个所谓的肿瘤组织肿块。 Not all tumors are cancerous; tumors can be benign or malignant. 并非所有的肿瘤都是癌症性的，肿瘤也可是良性或恶性。 Benign tumors aren’t cancerous. They can often be removed, and, in most cases, they do not come back. Cells in benign tumors do not spread to other parts of the body. 良性肿瘤不是癌性的。它们通常可以切除，并且，在大多数情况下，不会复发。良性肿瘤的细胞不会扩散到身体的其他部位。 Malignant tumors are cancerous. Cells in these tumors can invade nearby tissues and spread to other parts of the body. The spread of cancer from one part of the body to another is called metastasis. 恶性肿瘤是癌性的。这些肿瘤细胞可侵入附近组织并扩散到身体的其他部位。癌症从身体的一部分扩散至另一部分称为转移。 Some cancers do not form tumors. For example, leukemia is a cancer of the bone marrow and blood. 有些癌症不形成肿瘤。例如，白血病是骨髓和血液的一种癌症。 理解癌症Cancer begins in cells, the building blocks that form tissues. Tissues make up the organs of the body. 癌症细胞起始于细胞，并形成肿块。 Normally, cells grow and divide to form new cells as the body needs them. When cells grow old, they die, and new cells take their place. 通常情况下，细胞生长、分裂，形成新的细胞，这是人体所需要的。当细胞衰老时，细胞死亡，新细胞取代其位置。 Sometimes, this orderly process goes wrong. New cells form when the body does not need them, and old cells do not die when they should. These extra cells can form a mass of tissue called a growth or tumor. 有时，这种有序的过程中出现错误。当身体并不需要时，新细胞形成，衰老的细胞应该死亡但并未死亡。这些额外的细胞可以形成一个组织团块称为增生或肿瘤。 Tumors can be benign or malignant: 肿瘤可以是良性或恶性： Benign tumors are not cancer: 良性肿瘤不是癌性的： Benign tumors are rarely life-threatening. 良性肿瘤很少危及生命。 Generally, benign tumors can be removed, and they usually do not grow back. 一般来说，良性肿瘤可以切除，而他们通常不会复发。 Cells from benign tumors do not invade the tissues around them. 良性肿瘤细胞不侵入周围组织。 Cells from benign tumors do not spread to other parts of the body. 良性肿瘤细胞不会扩散到身体的其他部位。 Malignant tumors are cancer: 恶性肿瘤是癌性的： Malignant tumors are generally more serious than benign tumors. They may be life-threatening. 恶性肿瘤一般都比良性肿瘤严重。他们可能会危及生命。 Malignant tumors often can be removed, but sometimes they grow back. 恶性肿瘤往往可以切除，但有时它们重新生长出来（复发）。 Cells from malignant tumors can invade and damage nearby tissues and organs. 恶性肿瘤细胞可侵入和破坏邻近组织和器官。 Cells from malignant tumors can spread (metastasize) to other parts of the body. Cancer cells spread by breaking away from the original (primary) tumor and entering the bloodstream orlymphatic system. The cells can invade other organs, forming new tumors that damage these organs. The spread of cancer is called metastasis. 恶性肿瘤细胞可以扩散（转移）到身体的其他部位。癌细胞经脱离原（主）肿瘤并进入血液系统或淋巴系统发生扩散。细胞可以侵入其他器官，形成新的肿瘤并损害这些器官。癌症的扩散称为转移。 Most cancers are named for where they start. For example, lung cancer starts in the lung, and breast cancer starts in the breast. Lymphoma is cancer that starts in the lymphatic system. And leukemia is cancer that starts in white blood cells (leukocytes). 大多数癌症以其起始部位命名。例如，肺癌起始于肺，乳腺癌起始于乳腺。淋巴瘤是起始于淋巴系统的癌症。白血病是起始于白细胞的癌症。 When cancer spreads and forms a new tumor in another part of the body, the new tumor has the same kind of abnormal cells and the same name as the primary tumor. For example, if prostate cancer spreads to the bones, the cancer cells in the bones are actually prostate cancer cells. The disease is metastatic prostate cancer, not bone cancer. For that reason, it is treated as prostate cancer, not bone cancer. Doctors sometimes call the new tumor “distant” or metastatic disease. 当癌细胞扩散，并在身体的其他部位形成一种新的肿瘤时，新的肿瘤具有同一种异常细胞，名称与原发肿瘤相同。例如，如果前列腺癌扩散到骨，骨头的癌细胞其实是前列腺癌细胞。这种疾病是转移性前列腺癌，而不是骨癌。出于这个原因，被视为前列腺癌进行治疗，而不是骨癌。医生有时称之为“远部”新肿瘤或转移性疾病。 参考tumor，cancer，carcinoma…你弄清楚了吗？]]></content>
      <categories>
        <category>NGS</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>基础概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Fish验证简介]]></title>
    <url>%2F2022%2F01%2F05%2F2022-01-05-Fish%E9%AA%8C%E8%AF%81%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[By 赵东晓 NGS检测过程中经常遇到需要第三方验证的需求，不管是为了证明检测结果准确性，还是前期方法学检测的需求，都不可避免的需要面对各种第三方验证。而Fish检验就是一个常用的用来检验融合的方法。最近同事对Fish进行了一些调研，简单梳理以备后用。 Fish调研NGS报告融合推药逻辑 1类融合多见，为常见伴侣融合，是指南里面提到的，且有功能证据证明激活的融合亚型； 针对1类融合，相同基因，不同断点和亚型，现在药物推荐还没有区分差别。 2类融合少见，是指那些没有指南支持，仅有少量文献证据的罕见融合； 3类融合不推药； 通过FISH（荧光原位杂交）检测融合，目前有2种方法： 第1种（应用较广）：可以设计已知融合基因的探针，比如针对ALK的，用红色和黄色覆盖ALK基因的上下游区域，正常就是红黄在一起，融合就是ALK发生了断裂就是红黄分开了。此方法检出的融合，不能确定是何种融合亚型，推药只能按照广义层面上的融合大类来推荐用药。 第2种（不经济实用）：可以设计已知融合基因和伴侣基因的探针，比如针对ALK和EML4的，ALK全部用红色探针覆盖，EML4用黄色探针覆盖，正常就是红黄分开，融合就是红黄在一起。此方法检出的融合，为常见伴侣基因的融合，为1类融合，推药逻辑没有差异。 以ALK探针为例：Vysis ALK break-apart probe (Abbott Molecular)美国食品药品监督管理局(FDA)已批准的FISH分离探针试剂盒(Vysis ALK Break Apart FISH Probe Kit; Abbott Molecular, Inc.)可用于检测ALK融合基因的表达。该试剂盒设计的两种探针分别标记ALK基因第20号外显子断裂点的两端，在5 ‘(着丝粒)侧有一个约442 kb的绿色探针，在3 ‘(端粒)侧有一个约300 kb的橙色探针，橙色区域包括了ALK激酶活性区。 ALK基因：chr2:29,415,640-30,144,452 (GRCh37/hg19 by Entrez Gene)，Size:728,813 bases. 结果判读阴性信号： 一个癌细胞核内至少有一个橙色和一个绿色信号，橙色信号与绿色信号相互邻近或叠加，其问距小于两个信号直径。 一个癌细胞核内至少有一个橙色和一个绿色信号，有单独的绿色信号，但无相应的橙色信号。 阳性信号： 一个癌细胞核内至少有一个橙色和一个绿色信号，橙色和绿色信号的间距大于两个信号直径。 一个癌细胞核内至少有一个橙色和一个绿色信号，有单独的橙色信号，但无相应的绿色信 阳性判定： 计数50个肿痛细胞，若阳性肿指细胞数多于25个，该样本为阳性； 若阳性肿指细胞数小于5个，该样本为阴性； 阳性肿指细胞数介于5-25个，为可疑阳性。需要另计数50个肿指细胞，将前后两次的合计100个肿瘤细胞的信号状况汇总。 若阳性肿痛细胞比例少于1598(15/100),该样本为阴性。 着阳性肿痛细胞比例多于159(15/100,该样本为阳性。 该方法只能判断ALK基因是否断裂，可以检测所有的融合型，但不能区分与其发生融合的基因是什么。阳性细胞为存在橙绿信号分离或单独橙色信号的细胞。 ALK基因的检测方法ALK基因的检测方法有荧光原位杂交（FISH）、显色原位杂交（CISH）、免疫组化（IHC）、基于PCR的各种方法、NGS二代测序等。 检测ALK融合的各种技术的特点总结参考：中国间变性淋巴瘤激酶(ALK)阳性非小细胞肺癌诊断专家共识(2013版) 参考：Int J Mol Sci. 2019 Aug 13;20(16):3939. doi: 10.3390/ijms20163939. 总结ALK基因融合的检测要尽可能采用两种以上的方法相互印证，以免出现漏检或假阴性结果，使得部分病友失去从靶向药中获益的机会。检测实验室应该根据组织标本类型选择合适的检测技术。当怀疑一种技术的可靠性时（如FISH的肿瘤细胞融合率接近15％时），可以考虑采用另一种技术加以验证。]]></content>
      <categories>
        <category>NGS</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>肿瘤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jbrowse部署安装]]></title>
    <url>%2F2021%2F12%2F25%2FSoftware-Jbrowse%E9%83%A8%E7%BD%B2%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[腾讯云服务如果服务不存在，登陆腾讯云服务器执行如下命令12cd /var/www/html/jbrowsenohup npx serve . &amp; 前言JBrowse 是今天要介绍的主角。它是GMOD( Generic Model Organism Database) 开源项目的一部分,这个项目收集了非常多的开源软件工具，用来管理、可视化、存储、展示基因组学数据。 the Generic Model Organism Database project, a collection of open source software tools for managing, visualising, storing, and disseminating genetic and genomic data. ---GMOD官网在GMOD的众多项目中最出名的应该是Galaxy，而JBrowse则是GMOD之前一款基因浏览器JGBrowse的继任者。 JBrowse资料JBrowse官网GMOD-JBrowse WIkiJBrowse2 Github项目 JBrowse 部署安装镜像调整设置yum镜像123456789cd /etc/yum.repos.d/mkdir centos.backmv *.repo centos.back# 获取新镜像wget http://mirrors.aliyun.com/repo/Centos-7.repo 阿里的源wget http://mirrors.163.com/.help/CentOS7-Base-163.repo 163的源yum clean all # 清空缓存yum makecache # 生成缓存 设置npm镜像123456789# 设置npm源为淘宝NPM镜像npm config set registry https://registry.npm.taobao.org# 查看是否设置成功npm config get registry# 直接使用cnpm命令行工具代替默认的npmnpm install -g cnpm --registry=https://registry.npm.taobao.org# 设置回默认的官方源npm config set registry https://registry.npmjs.org/ 环境需求Node version must be &gt;=12.0.0 to use this CLI需要安装 redhat-lsb1yum -y install redhat-lsb 升级Node版本安装npm的n模块(专门用来管理nodejs的版本)12npm install -g n # 安装n模块n stable # 升级到最新的稳定版本 安装jbrowse123### operate under a normal user so this guide does not use thisnpm install -g @jbrowse/clijbrowse create /var/www/html/jbrowse2 也可以直接下载软件包： 下载最新版JBrowse2软件包 选择其中的Web版本(jbrowse-web-v1.5.3.zip)，解压后进入目录,运行npm服务即可 123456789101112131415unzip jbrowse-web-v1.5.3.zipcd jbrowsenpx serve .弹出如下信息，则证明服务已经成功启动。 ┌──────────────────────────────────────────────────┐ │ │ │ Serving! │ │ │ │ - Local: http://localhost:39963 │ │ - On Your Network: http://172.21.0.8:39963 │ │ │ │ This port was picked because 3000 is in use. │ │ │ └──────────────────────────────────────────────────┘ 配置jbrowse完成了jbrowse以后，下一步就是Jbrowse的配置，有两种方案可以进行配置 命令行的方法 图形界面 使用命令行添加数据添加基因组12# 添加Hg19的基因组，由于添加过程会在执行目录更新config.json文件，因此记得在jbrowse目录下执行！！jbrowse add-assembly /root/Database/hg19.fa --load copy --displayName Hg19 添加 bam 文件123jbrowse add-track /data/volvox.bam --load copy# 如果bam缺少索引文件，需要建立索引。samtools index volvox.bam 添加 BigWig/BigBed 文件因为jbrowse添加的bed文件必须是BigBed文件(二进制的bed文件)，因此bed文件添加前要先通过bedToBigBed 进行处理12345sort -k1,1 -k2,2n unsorted.bed &gt; input.bed #bed文件必须先排序bedToBigBed input.bed chrom.sizes myBigBed.bb## Download bigwig or bigbed filejbrowse add-track volvox-sorted.bam.coverage.bw --load copy 除了bed文件外，jbrowse还支持 BigWig有多种方式可以生成BigWig文件以下介绍的方式有基于wiggle (wig) 格式的文件，通过 软件：wigToBigWig 生成）， BigWig(.bw)的生成需要准备一个BedGraph文件格式如下： 123456#Chr Start End Value(可以自行定义)chr1 10270744 10270745 0.278208333333333chr1 10270745 10270746 0.275666666666667chr1 10270746 10270747 0.276833333333333chr1 10270747 10270748 0.27675chr1 10270748 10270749 0.279083333333333 排序后，通过bedGraphToBigWig工具，将BedGraph文件转换成.bw文件，直接加载12sort -k1,1 -k2,2n $file.bedGraph &gt; $file.sorted.bedGraph bedGraphToBigWig $file.sorted.bedGraph hg19.fa.fai $file.bw Adding a variant track12345678#首先对vcf进行排序bcftools sort file.vcf &gt; file.sorted.vcf#vcf需要进行压缩和建立索引bgzip yourfile.vcftabix yourfile.vcf.gzjbrowse add-track /data/yourfile.vcf.gz --load copy Adding a GFF3 file with GFF3Tabix1234gt gff3 -sortlines -tidy -retainids yourfile.gff &gt; yourfile.sorted.gffbgzip yourfile.sorted.gfftabix yourfile.sorted.gff.gzjbrowse add-track yourfile.sorted.gff.gz --load copy]]></content>
      <categories>
        <category>software</category>
        <category>Linux</category>
        <category>可视化</category>
      </categories>
      <tags>
        <tag>可视化</tag>
        <tag>Jbrowse</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGS检测中的数据模拟]]></title>
    <url>%2F2021%2F12%2F23%2F2021-12-23-NGS%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A8%A1%E6%8B%9F%2F</url>
    <content type="text"></content>
      <categories>
        <category>NGS</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>NGS</tag>
        <tag>肿瘤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[芯片设计(Panel-Design)]]></title>
    <url>%2F2021%2F12%2F12%2F2021-12-12-Panel-Design%2F</url>
    <content type="text"><![CDATA[前言目前探针的靶向捕获测序，已经发展临床检测应用的常规技术手段。因此在进行靶向捕获测序时，我们需要面临和解决的第一个问题，就是我们应该如何设计芯片探针。2014年，发表的一篇文章An ultrasensitive method for quantitating circulating tumor DNA with broad patient coverage为我们进行靶向捕获区域设计提供了一个可参考的方案CAPP-Seq Selector。 名词概念 RI值 ：Recurrence Index (RI), is defined as the number of unique patients (i.e., tumors) with somatic mutations per kilobase of a given genomic unit (here, exon)。RI =（n×1000）÷L，其中n为所述外显子区间的患者数目，L为外显子区间的序列长度（bp）。 方法介绍 本方法是针对NSCLC设计的，但是也可以推广应用到其他高频突变已经明确的癌种。 首先，我们挑选出一些重要的外显子，这些外显子包含了COSMIC和其他来源（Somatic mutations affect key pathways in lung adenocarcinoma.[PubMed: 18948947]；Identifying cancer driver genes in tumor genome sequencing studies. [PubMed: 21169372]）的潜在驱动基因中反复出现的突变。 然后使用TCGA数据库，获取NSCLC的407例样本的WES测序数据。 最后应用了一种迭代算法来最大化每个患者的错义突变数量，同时最小化整个芯片大小。 Most human cancers are relatively heterogeneous for somatic mutations in individual genes. Specifically, in most human tumors, recurrent somatic alterations of single genes account for a minority of patients, and only a minority of tumor types can be defined using a small number of recurrent mutations (&lt;5-10) at predefined positions. Therefore, the design of the selector is vital to the CAPP-Seq method because (1) it dictates which mutations can be detected with high probability for a patient with a given cancer, and (2) the selector size (in kb) directly impacts the cost and depth of sequence coverage. For example, the hybrid selection libraries available in current whole exome capture kits range from 51-71 Mb, providing ~40-60 fold maximum theoretical enrichment versus whole genome sequencing. The degree of potential enrichment is inversely proportional to the selector size such that for a ~100 kb selector, &gt;10,000 fold enrichment should be achievable. We employed a six-phase design strategy to identify and prioritize genomic regions for the CAPP-Seq NSCLC selector as detailed below. Three phases were used to incorporate known and suspected NSCLC driver genes, as well as genomic regions known to participate in clinically actionable fusions (phases 1, 5, 6), while another three phases employed an algorithmic approach to maximize both the number of patients covered and SNVs per patient (phases 2–4). The latter relied upon a metric that we termed “Recurrence Index” (RI), defined as the number of NSCLC patients with SNVs that occur within a given kilobase of exonic sequence (i.e., No. of patients with mutations / exon length in kb). RI thus serves to measure patient-level recurrence frequency at the exon level, while simultaneously normalizing for gene or exon size. As a source of somatic mutation data uniformly genotyped across a large cohort of patients, in phases 2–4, we analyzed non-silent SNVs identified in TCGA whole exome sequencing data from 178 patients in the Lung Squamous Cell Carcinoma dataset (SCC)10 and from 229 patients in the Lung Adenocarcinoma (LUAD) datasets (TCGA query date was March 13, 2012). Thresholds for each metric (i.e. RI and patients per exon) were selected to statistically enrich for known/suspected drivers in SCC and LUAD data (Supplementary Fig. 1). RefSeq exon coordinates (hg19) were obtained via the UCSC Table Browser (query date was April 11, 2012) The following algorithm was used to design the CAPP-Seq selector (parenthetical descriptions match design phases noted in Fig. 1b). Phase 1 (Known drivers) Initial seed genes were chosen based on their frequency of mutation in NSCLCs. Analysis of COSMIC (v57) identified known driver genes that are recurrently mutated in ≥9% of NSCLC (denominator ≥500 cases). Specific exons from these genes were selected based on the pattern of SNVs previously identified in NSCLC. The seed list also included single exons from genes with recurrent mutations that occurred at low frequency but had strong evidence for being driver mutations, such as BRAF exon 15, which harbors V600E mutations in &lt;2% of NSCLC. Phase 2 (Max. coverage) For each exon with SNVs covering ≥5 patients in LUAD and SCC, we selected the exon withhighest RI that identified at least 1 new patient when compared to the prior phase. Amongexons with equally high RI, we added the exon with minimum overlap among patients alreadycaptured by the selector. This was repeated until no further exons met these criteria. Phase 3 (RI ≥ 30) For each remaining exon with an RI ≥ 30 and with SNVs covering ≥3 patients in LUAD andSCC, we identified the exon that would result in the largest reduction in patients with only 1SNV. To break ties among equally best exons, the exon with highest RI was chosen. This wasrepeated until no additional exons satisfied these criteria. Phase 4 (RI ≥ 20) Same procedure as phase 3, but using RI ≥ 20. Phase 5 (Predicted drivers) We included all exons from additional genes previously predicted to harbor driver mutations inNSCLC12,13. Phase 6 (Add fusions) For recurrent rearrangements in NSCLC involving the receptor tyrosine kinases ALK, ROS1,and RET, the introns most frequently implicated in the fusion event and the flanking exons wereincluded. All exons included in the selector, along with their corresponding HUGO gene symbols andgenomic coordinates, as well as patient statistics for NSCLC and a variety of other cancers, areprovided in Supplementary Table 1, organized by selector design phase. 参考资料文献An ultrasensitive method for quantitating circulating tumor DNA with broad patient coverage $\color{red}{ed}$]]></content>
      <categories>
        <category>NGS</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>芯片设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-pyechart画web版图片]]></title>
    <url>%2F2021%2F12%2F10%2FPython-%E5%8C%85-pyechart%E7%94%BBweb%E7%89%88%E5%9B%BE%E7%89%87%2F</url>
    <content type="text"><![CDATA[pyechart quickstart 12345678from pyecharts.charts import Barbar = Bar()bar.add_xaxis([&quot;衬衫&quot;, &quot;羊毛衫&quot;, &quot;雪纺衫&quot;, &quot;裤子&quot;, &quot;高跟鞋&quot;, &quot;袜子&quot;])bar.add_yaxis(&quot;商家A&quot;, [5, 20, 36, 10, 75, 90])# render 会生成本地 HTML 文件，默认会在当前目录生成 render.html 文件# 也可以传入路径参数，如 bar.render(&quot;mycharts.html&quot;)bar.render()]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[本地构建control集合进行过滤]]></title>
    <url>%2F2021%2F12%2F08%2F2021-12-08.Local_control%2F</url>
    <content type="text"><![CDATA[各个流程的处理过程大同小异 GATK PONA Panel of Normal or PON is a type of resource used in somatic variant analysis. Depending on the type of variant you’re looking for, the PON will be generated differently. What all PONs have in common is that : they are made from normal samples (in this context, $\color{red}{“normal”}$ means derived from healthy tissue that is believed to not have any somatic alterations) their main purpose is to capture recurrent technical artifacts in order to improve the results of the variant calling analysis. As a result, the most important selection criteria for choosing normals to include in any PON are the technical properties of how the data was generated. It’s very important to use normals that are as technically similar as possible to the tumor (same exome or genome preparation methods, sequencing technology and so on). Additionally, the samples should come from subjects that were young and healthy to minimize the chance of using as normal a sample from someone who has an undiagnosed tumor. Normals are typically derived from blood samples. There is no definitive rule for how many samples should be used to make a PON (even a small PON is better than no PON) but in practice we recommend aiming for a minimum of 40. At the Broad Institute, we typically make a standard PON for a given version of the pipeline (corresponding to the combination of all protocols used in production to generate the sequence data, starting from sample preparation and including the analysis software) and use it to process all tumor samples that go through that version of the pipeline. Because we process many samples in the same way, we are able to make PONs composed of hundreds of samples. MSKFiltering for high confidence mutations: Raw SNV and indel calls are subjected to a series of filtering steps to ensure only high-confidence calls are admitted to the final step of manual review. These parameters include (1) evidence of it being a somatic mutation (i.e., ratio between mutation frequencies in the tumor and normal samples to be ≥ 5.0); (2) whether the mutation is a known hotspot mutation (refer to Appendix 1a for details); (3) reference on in house ‘standard normal’ based on common artifacts; (4) technical characteristics that use coverage depth (DP), number of mutant reads (AD), mutation frequency (VF). The filtering scheme and threshold are shown in Figure 1 below. The threshold values for the filtering criteria were established based on paired-sample mutation analysis on replicates of normal FFPE samples, and optimized to reject all false positive SNVs and almost all false positive indel calls from the reference dataset. BGI 目前策略Control集合构建SOP reference GATK:PON EVALUATION OF AUTOMATIC CLASS III DESIGNATION FOR MSK-IMPACT]]></content>
      <categories>
        <category>NGS</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>NGS</tag>
        <tag>肿瘤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DNA-Damage]]></title>
    <url>%2F2021%2F12%2F07%2F2021-12-07.DNA-Damage%2F</url>
    <content type="text"><![CDATA[背景概念生物学真实损伤和实验引入损伤间的差异。DNA易受多种损伤，其中之一就是氧化损伤。随着时间的推移，这种类型的损害会逐渐累积，破坏修复系统，导致健康问题，最终导致疾病。 在生理环境下，一旦某一个碱基发生改变如果没有被错配修复蛋白处理掉，这种错配可以传递给子代，形成突变，一个真实的突变正模板链和对应负模板链应同时被替换。 如果碱基改变是发生在实验阶段，那么其对应链不会发生改变，正链发生G&gt;8-oxoG的改变时，由于其可与A配对，易被测序仪读成T，但对应的负链C碱基，仍会被读为C，而不是A 正负链 真实突变 假突变 正链：5’-3’ 5’- ATC$\color{red}{G}$ATCG-3 5’- ATC$\color{red}{G}$ATCG-3 负链：3’-5’ 3’- TAG$\color{red}{A}$TAGC-5 3’- TAG$\color{red}{C}$TAGC-5 NGS识别氧化损伤的技术基础NGS检测原理-实验 数据表现参考资料文献 Characterization of background noise in capture-based targeted sequencing data FIREVAT: finding reliable variants without artifacts in human cancer samples using etiologically relevant mutational signatures Sequence Neighborhoods Enable Reliable Prediction of Pathogenic Mutations in Cancer Genomes Needlestack: an ultra-sensitive variant caller for multi-sample next generation sequencing data Location analysis of 8-oxo-7,8-dihydroguanine in DNA by polymerase-mediated differential coding Targeted Single Primer Enrichment Sequencing with Single End Duplex-UMI Analysis of error profiles in deep next-generation sequencing data The use of technical replication for detection of low-level somatic mutations in next-generation sequencing Allele balance bias identifies systematic genotyping errors and false disease associations Overview of Next-Generation Sequencing Technologies Detecting Somatic Mutations in Normal Cells Detecting Rare Mutations and DNA Damage with Sequencing-Based Methods IMPUTOR: Phylogenetically Aware Software for Imputation of Errors in Next-Generation Sequencing UDiTaS™, a genome editing detection method for indels and genome rearrangements Reference standards for next-generation sequencing 网站 Science Direct: Oxidative Damage exploredna: DNA and Oxidative Damage Oxidative DNA damage: mechanisms, mutation, and disease The genomics of oxidative DNA damage, repair, and resulting mutagenesis]]></content>
      <categories>
        <category>NGS</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>NGS</tag>
        <tag>肿瘤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGS检测原理-实验]]></title>
    <url>%2F2021%2F12%2F07%2F2021-12-07.NGS%E6%A3%80%E6%B5%8B%E5%8E%9F%E7%90%86-%E5%AE%9E%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[NGS在数据下机前需要对数据进行一些列的实验处理后才能进行上级测序，因此了解实验原理才能更好的从根源了解数据处理过程，及各个环节的不同处理方案可能带来的优劣影响。在下游数据处理过程中，更有针对性的对数据处理过程进行优化提升。 DNA的提取细胞裂解预处理加入保护液（如TE buffer）来溶解DNA并防止其降解；在破胞前加入去垢剂来去除杂质并破坏细胞（如SDS是一种表面活性剂，能破坏细胞膜上的脂质，并在低温下使其沉淀） 主要方法机械破碎法（振荡珠磨、液氮研磨、反复冻融等）和酶解法（如溶菌酶溶解细菌细胞壁） 去除杂质杂质如细胞碎片、蛋白质、RNA、腐殖酸等 方法化学法（加入抑制因子沉淀杂质、使用氯仿等有机溶剂溶解杂质）、酶解法（例如蛋白酶K、RNA酶降解蛋白质、RNA） 回收DNA主要方法 醇沉淀法：DNA不溶解于异丙醇、乙醇等 过柱收集法：DNA在高盐环境下可以吸附在硅胶滤膜上，这是大部分试剂盒采用的方法 磁珠吸附法：DNA分子通过氢键吸附到具有磁性的磁珠上，然后在磁场中分离磁珠，常见于自动提取仪 清洗溶解DNA方法 对沉淀的DNA、收集柱DNA以及磁珠吸附的DNA使用70%乙醇清洗； 待乙醇挥发后使用无菌水溶解DNA。 DNA提取原则 保证核酸一级结构的完整性； 核酸样品中不应存在对酶有抑制作用的有机溶剂和过高浓度的金属离子； 其他生物大分子如蛋白质、多糖和脂类分子的污染应降低到最低程度； 其他核酸分子，如RNA，也应尽量去除。 文库制备末端修饰 使用Taq聚合酶补齐不平的末端； 并在两个末端添加突出的碱基A，从而产生粘性末端（若使用Taq酶扩增，则无需末端修饰）； 产生粘性末端的片段可以添加接头（Adaptor）。 添加接头 经过末端修饰后的PCR片段末端具有突出的A尾，而接头具有突出的T尾，可以使用连接酶将接头添加到DNA片段两端。 NEB的接头为特殊的碱基U连接的环状结构（可以增强稳定性），因此连接接头后，还需要将碱基U删除从而形成“Y”形接头。 上一步添加的接头主要是为了后续PCR中作为引物扩增继续添加文库index和与测序平台互补的寡核苷酸序列（此外还作为测序引物Rd1 SP/Rd2 SP）。 之所以为“Y”型开叉结构，是因为每一端接头是两条不互补的序列（每一端都是Rd1 SP与Rd2 SP交错），连接酶没有选择性，每个接头都是只靠突出的T来与DNA连接，“Y”接头保证了每条单序列两端均为不同的测序引物，从而在后续PCR中可以连接不同的寡核苷酸序列（P5/P7）。 过程示意图如下： 磁珠纯化目的添加接头后的文库体系中含有聚合酶、连接酶等各种酶以及辅助物质，接头的添加也是过量的，而且由于末端的不稳定性，容易形成自连片段，鸟枪法打断的片段中也可能有大片段存在，所以需要特殊磁珠（AMPure XP Beads）纯化来去除大片段以及各种杂质，从而获得成功添加接头的文库片段。 原理磁珠可以通过氢键等作用力来吸附DNA片段，磁珠本身不具有片段大小选择的能力，但其储存的buffer里面含有20%的PEG 8000，PEG浓度越大则可以吸附的DNA片段越小。 注意事项磁珠纯化的时候要根据文库片段不同严格控制磁珠添加量（其实是PEG添加量）来实现片段选择。 PCR扩增 添加了接头的DNA片段，可以使用与接头互补的引物来扩增。 此外，片段还需要添加用于区分不同文库的特异性index，以及与测序仪芯片互补的两种寡核苷酸序列（P5/P7）。 第二次磁珠纯化 PCR后需要将产物DNA片段与聚合酶等杂质分离，因此再次进行磁珠纯化。 之后进行质量检测，包括DNA浓度检测、琼脂糖凝胶电泳和片段长度检测，完成建库。 NGS测序仪上机待补充 参考来源 https://mp.weixin.qq.com/s/zNFvod8B-VhX7Kq7OgoRMA ClarkeA C, Prost S, Stanton J a L, et al. From cheek swabs to consensus sequences: anA to Z protocol for high-throughput DNA sequencing of complete humanmitochondrial genomes[J]. Bmc Genomics, 2014, 15(1): 1-12. BowmanS K, Simon M D, Deaton A M, et al. Multiplexed Illumina sequencing librariesfrom picogram quantities of DNA[J]. Bmc Genomics, 2013, 14(1): 135-143. MardisE R. Next-Generation DNA Sequencing Methods[J]. Annual Review of Genomics &amp;Human Genetics, 2008, 9(9): 387-402]]></content>
      <categories>
        <category>NGS</category>
        <category>标准化</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>NGS</tag>
        <tag>肿瘤</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TMB简介及华大相关进展]]></title>
    <url>%2F2021%2F11%2F30%2F2021-11-29-TMB%2F</url>
    <content type="text"><![CDATA[TMB的出现及发展TMB 基本现状定义 WES： TMB是指肿瘤基因组内存在的体细胞突变位点数量，可以间接反映肿瘤产生新生抗原的能力。由于早期研究多基于WES检测，因此TMB通常是指单位基因组外显子编码区域（外显子组，exome）的突变数量（mutations, muts），单位为muts/exome。 Panel： 虽然WES是检测TMB的金标准，但WES时间成本和分析成本较高。经过多项大样本研究验证后，TMB检测从WES扩展到了更切合临床实际的靶向二代测序（next-generation sequencingpanel, NGS panel）。靶向测序的基因检测位点比外显子组少，由于不同平台检测方法和测序覆盖的外显子区域长度不同，TMB也被定义为肿瘤基因组区域中每兆碱基（megabase, Mb）发生的碱基替换突变和插入缺失突变的数量总和，单位为muts/Mb。 纳入计算的突变范围 WES TMB被定义为通过WES测序肿瘤组织样本中体细胞非同义突变数量的总和。 Panel 在NGSpanel检测TMB的研究中，纳入TMB计算的是体细胞编码区中碱基替换突变和插入缺失突变，部分NGS panel计算TMB也同时纳入了同义突变，而胚系变异、核苷酸多态性位点、明确的抑癌基因及驱动基因热点突变则不计算在内.(Analysis of 100,000 human cancer genomes reveals the landscape of tumor mutational burden、The COSMIC (Catalogue of Somatic Mutations in Cancer) database and website、ExAC:Analysis of protein-coding genetic variation in 60,706 humans ) Panel大小有一些证据[23,24]发现检测的基因数越多，TMB的检测结果与WES的一致性越高，NGS大panel可能更适合评估TMB。对于TMB较高的样本，不同大小的NGS panel检测结果差异可能不显著；而对于TMB较低的样本，检测结果的不一致性显著增加。目前一般认为NGS panel ≥0.8 Mb可以较好地评估肿瘤组织TMB水平(Implementing TMB measurement in clinical practice: considerations on assay requirements)。 参考材料：来源：历史中检院宣讲PPT材料 Transl Lung Cancer Res 2018;7(6):703-715Genes Chromosomes Cancer. 2019;58:578–588. 影响因素样本收集阶段、DNA处理阶段、测序阶段、生物信息分析阶段和报告生成阶段均会影响TMB检测的可靠性。样本收集阶段主要包括样本类型、肿瘤类型、肿瘤异质性和克隆进化等影响因素；DNA处理阶段包括DNA质量和数量、文库构建等影响因素；测序阶段包括DNA捕获区域、测序深度、覆盖读长、测序平台等影响因素；生物信息分析阶段包括突变类型、胚系突变过滤、等位基因突变频率等影响因素；报告生成阶段包括瘤种分类、患者人群、患者数量、TMB排序标准等影响因素。除了考虑技术因素，流程监管、样本收集和处理质控以及样本运送时长等因素可能也会影响样本质量，从而影响检测结果。 关联指标在一定程度上，TMB 水平反映的是肿瘤细胞内DNA 的修复损伤情况，与产生肿瘤新抗原能力密切相关。DNA错配修复基因（mismatch repair genes，MMR）负责修正DNA 复制错误，若MMR 存在突变往往会导致微卫星不稳定（microsatellite instability，MSI），因此高微卫星不稳定（MSI high，MSI鄄H）常作为MMR 功能缺陷（mismatch repair deficient，dMMR）的替代指标［6］。 此外，DNA 聚合酶着（DNA polymerase 着，POLE）和DNA 聚合酶啄1（polymerase delta 1,POLD1）对DNA复制的校对和保真至关重要，POLE/POLD1 基因突变（特别是外切酶活性域突变）也会导致肿瘤的高突变或超突变（TMB&gt;100 个突变/Mb）(Tumor and Microenvironment Evolution during Immunotherapy with Nivolumab) TMB发展重要节点历程TMB概念起源于2013年Nature发表的一项研究(Signatures of mutational processes in human cancer)。在30个癌种7,000多个标本中，研究者通过全基因组测序（whole genome sequencing,WGS）和全外显子测序（whole exome sequencing, WES）技术分析了突变图谱，描述了不同癌种样本中每百万碱基（megabase, Mb）的突变数量。 2014年的一项黑色素瘤研究（Genetic Basis for Clinical Response to CTLA-4 Blockade in Melanoma）发现，免疫治疗的响应率与肿瘤突变数目有一定的相关性，通过WES检出错义突变数量大于100的患者接受免疫治疗后具有更长的总生存期（overall survival, OS），这是首个验证TMB和免疫治疗疗效相关性的研究。 2015年，首个TMB与NSCLC免疫治疗疗效的研究（Mutational landscape determines sensitivity to PD-1 blockade in non–small cell lung cancer）发表于Science，该研究发现高于中位TMB的NSCLC患者具有更长的无进展生存期（progression-free survival, PFS）。 此后，CheckMate-026、CheckMate-227等多项大型研究证实了TMB对NSCLC免疫治疗疗效的预测作用。 2017年，Genome Medicine发表的一项10万例实体瘤患者研究(Analysis of 100,000 human cancer genomes reveals the landscape of tumor mutational burden)，探索了靶向捕获测序panel与WES检测TMB的相关性，证实了panel检测TMB的可行性与可靠性。 2019年中国临床肿瘤学会（Chinese Society of Clinical Oncology, CSCO）指南和美国国家综合癌症网络（National Comprehensive Cancer Network, NCCN）指南均将TMB纳入晚期肺癌的分子病理检测范围。 2020年，美国食品药品监督管理局（Food and Drug Administration, FDA）批准Pembrolizumab单药用于治疗高TMB且既往接受治疗后病情进展的不可手术或转移性实体瘤患者。Pembrolizumab成为全球首个以TMB作为标志物而获批的抗肿瘤药物。但临床实践中TMB的检测和评估缺乏统一的标准，这极大限制了其临床应用。虽然《肿瘤突变负荷检测及临床应用中国专家共识（2020年版）》已发布，但TMB在肺癌免疫治疗临床应用中的相关规范仍有待统一。 2021年，为促进TMB在肺癌免疫治疗中应用的规范化，协作组组织国内肺癌领域权威专家，综合国内外高质量文献，形成《肿瘤突变负荷应用于肺癌免疫治疗的专家共识》，对TMB的定义、临床意义和临床应用给出指导性建议。 TMB 重要资讯TMB是肿瘤NGS检测 TMB相关文章指南共识信息 发布时间 简介 机构 文章材料 2019.10.17 肿瘤突变负荷检测国家参考品说明书公示 中检院 肿瘤突变负荷检测国家参考品说明书公示 2020.06 肿瘤突变负荷检测国家参考品 中检院 肿瘤突变负荷检测国家参考品 2020.10 肿瘤突变负荷检测及临床应用中国专家共识（2020 年版） 中国癌症防治杂志 肿瘤突变负荷检测及临床应用中国专家共识（2020年版） 2021.11 TMB国内共识 - 面向肺癌 中国临床肿瘤学会 肿瘤突变负荷应用于肺癌免疫治疗的专家共识 TMB阈值确定方法标准化的阈值，应该使用临床疗效数据进行阈值的判断！ 目前部分文章是使用的人群比例占比进行的TMB High/Low的划分。 阈值确定参考素材 index TMB-High TMB-intermedia TMB-L 参考文献 1 Top 10% Top 10%-20% else https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7210182/ 2 Top 10% Top 10%-50% else https://mct.aacrjournals.org/content/molcanther/16/11/2598.full.pdf 免疫治疗响应疗效报道 BGI的TMB工作TMB计算方式SNV（含同义突变和InDel的总突变数目除以芯片大小(2.79M) TMB标准化项目整体时间规划 第一阶段结果基于华大数据进行Panel和WES的相关性拟合基于TCGA公共数据，进行拟合，获取各公司Panel计算TMB值和原WES水平TMB的回归拟合公式。y=1.371599x-0.935414 （x：Panel检测的TMB值； y：经过矫正后，对应WES水平的TMB值。） 使用该公式，对PanCancer（688芯片）检测临床样本获得的TMB值进行校正，并利用校正后的数据和WES检测TMB结果进行相关性比较，结果如下： 第一阶段总结TMB标准化第一阶段发布会-内容存档 华大数据基于三分段确定的阈值BGI历史数据阈值（三分段）基于该标准（index1）和华大历史样本确定的整体阈值（数据截止2020.8） 癌症类型 TMB high TMB median TMB low 组织泛癌种 ≥8.6Mut/Mb ＞5.02Mut/Mb且＜8.6Mut/Mb ≤5.02Mut/Mb 基于该标准（index1）和华大历史样本确定的各个癌种阈值（数据截止2021.9） 癌症类型 TMB high TMB median TMB low 胆管癌 Cholangiocarcinoma ≥5.73Mut/Mb ＞3.94Mut/Mb且＜5.73Mut/Mb ≤3.94Mut/Mb 胆囊癌 Carcinoma of Gallbladder ≥8.6Mut/Mb ＞4.66Mut/Mb且＜8.6Mut/Mb ≤4.66Mut/Mb 非小细胞肺癌 Non-Small Cell Lung Cancer ≥9.68Mut/Mb ＞6.09Mut/Mb且＜9.68Mut/Mb ≤6.09Mut/Mb 肝细胞癌 Hepatocellular Carcinoma ≥7.89Mut/Mb ＞5.38Mut/Mb且＜7.89Mut/Mb ≤5.38Mut/Mb 宫颈癌 Cervical Cancer ≥16.49Mut/Mb ＞8.96Mut/Mb且＜16.49Mut/Mb ≤8.96Mut/Mb 黑色素瘤 Melanoma ≥8.24Mut/Mb ＞3.94Mut/Mb且＜8.24Mut/Mb ≤3.94Mut/Mb 结直肠癌 Colorectal Cancer ≥27.24Mut/Mb ＞6.45Mut/Mb且＜27.24Mut/Mb ≤6.45Mut/Mb 卵巢癌 Ovarian Cancer ≥5.73Mut/Mb ＞3.94Mut/Mb且＜5.73Mut/Mb ≤3.94Mut/Mb 膀胱癌 Bladder Cancer ≥20.07Mut/Mb ＞10.75Mut/Mb且＜20.07Mut/Mb ≤10.75Mut/Mb 前列腺癌 Prostate Cancer ≥8.6Mut/Mb ＞6.09Mut/Mb且＜8.6Mut/Mb ≤6.09Mut/Mb 乳腺癌 Breast Cancer ≥6.81Mut/Mb ＞5.38Mut/Mb且＜6.81Mut/Mb ≤5.38Mut/Mb 软组织肉瘤 Soft Tissue Sarcoma ≥4.66Mut/Mb ＞2.87Mut/Mb且＜4.66Mut/Mb ≤2.87Mut/Mb 肾癌 Kidney Cancer ≥6.45Mut/Mb ＞3.94Mut/Mb且＜6.45Mut/Mb ≤3.94Mut/Mb 头颈癌 Head and Neck Cancer ≥8.6Mut/Mb ＞5.73Mut/Mb且＜8.6Mut/Mb ≤5.73Mut/Mb 胃癌 Gastric Cancer ≥12.19Mut/Mb ＞7.17Mut/Mb且＜12.19Mut/Mb ≤7.17Mut/Mb 胰腺癌 Pancreatic Adenocarcinoma ≥3.94Mut/Mb ＞2.51Mut/Mb且＜3.94Mut/Mb ≤2.51Mut/Mb 子宫肿瘤 Uterine Neoplasms ≥26.88Mut/Mb ＞17.92Mut/Mb且＜26.88Mut/Mb ≤17.92Mut/Mb]]></content>
      <categories>
        <category>NGS</category>
        <category>标准化</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>Standards and guidelines</tag>
        <tag>Biomarker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算技术及性能优化]]></title>
    <url>%2F2021%2F11%2F17%2F2021-11-17.%E4%BA%91%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E5%8F%8A%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[写在前面，最近一些业务工作，涉及到整体的云计算业务平台开发。之前虽然都有一些零散的涉猎和了解，但是知识框架不成体系，零散的认知在紧迫的业务面前捉襟见肘。所以趁着双十一，买了一些教材构建一个针对云计算的系统认知。各种博客、课程、教材看的再多，可能都不如自己亲自体验经历一遍，因此也会借此机会在系列课程的学习过程中，利用一些现有条件进行实践。 - 纸上得来终觉浅，绝知此事要躬行。 云图 – 云计算图志 云计算的产生与发展1.1 云计算的产生20世纪60年代，John McCarthy提到“计算迟早有一天会变成一种公用基础设施”。 2007年10月，IBM和GOogle宣布在云计算领域的合作，云计算开始吸引了众多的关注迅速发展。 21世纪初，Web2.0 的流程让网络迎来了新的发展高峰。 技术上，分布式计算(Distributed Computing)技术的日益成熟和应用，特别是网络计算的发展通过Internet把分散在各处的硬件、软件、信息资源链接成为一个巨大的整体，是的人们能够利用地理上分散的资源，完成大规模、复杂的计算和数据处理任务。 数据存储的快速增长产生了以谷歌文件系统(Google File System, GFS)、存储域网络(Storage Area Network, SAN)为代表的的高性能存储技术。另外服务器整合需求推动了虚拟化技术的进步，这些技术的发展未构建更强大的计算能力和服务平台提供了可能。云计算应运而生。 1.2 云计算发展历程1.2.1 计算模式演进云计算是在并行计算(Parallel Computing)、分布式计算、网格计算(Grid Computing)和效用计算(Utility Computing)的基础上发展起来的，经过持续烟花和融合改进逐步形成目前留下的云计算模型，云计算的演化过程如下所述： 1. 并行计算包括空间并行、基于流水线技术的时间并行，以及基于优化算法的数据并行和任务并行等。是对穿行计算的单指令流单数据流做出优化，以及通过采用多指令流多数据流的并行计算的大幅度提升系统的处理能力。 2. 分布式计算分布式计算模式是在处理庞大的计算请求时，将需要解决的问题分解成细小的组成部分，然后将这些组成部分分散给众多的计算机进行处理，处理完成后将结果进行汇总，形成最终结果。 3. 网格计算网格计算是一种无缝、集成的计算和协作环境。安装网格提供的功能，网格可分为两类：计算网格和存储网格。计算网格可以提供虚拟的、无限制的计算和分布数据资源，存储网格则提供一个合作环境。 4. 效用计算效用计算的具体目标是结合分散各地的服务器、存储系统及应用程序来立即提供需求数据的技术。效用这个词是指为客户提供个性化的服务，并且可以满足不断变化的客户需求，可以基于实际占用的资源进行收费。 5. 云计算云计算强调所有资源均以服务的形态出现，包括基础设施即服务、平台即服务、软件即服务、数据即服务、知识即服务、存储即服务、安全即服务等。 1.2.2 云计算发展大事记 1959年6月，Christopher Strachey发表虚拟化论文，虚拟化是今天云计算基础架构的基石。 1961年，John McCarthy提出计算力和通过公用事业销售计算机应用的思想。 1962年，J.C.R. Licklider提出“星际计算机网络”设想。 1965年 美国电话公司Western Union一位高管提出建立信息公用事业的设想。 1984年，Sun公司的联合创始人John Gage说出了“网络就是计算机”的名言，用于描述分布式计算技术带来的新世界，今天的云计算正在将这一理念变成现实。 1996年，网格计算Globus开源网格平台起步。 1997年，南加州大学教授Ramnath K. Chellappa提出云计算的第一个学术定义”，认为计算的边界可以不是技术局限，而是经济合理性。 1998年，VMware(威睿公司)成立并首次引入X86的虚拟技术。 1999年，Marc Andreessen创建LoudCloud，是第一个商业化的IaaS平台。 1999年，salesforce.com公司成立，宣布“软件终结”革命开始。 2000年，SaaS兴起。 2004年，Web 2.0会议举行，Web 2.0成为技术流行词，互联网发展进入新阶段。 2004年，Google发布MapReduce论文。Hadoop就是Google集群系统的一个开源项目总称，主要由HDFS、MapReduce和Hbase组成，其中HDFS是Google File System(GFS)的开源实现;MapReduce是Google MapReduce的开源实现;HBase是Google BigTable的开源实现。 2004年，Doug Cutting 和 Mike Cafarella实现了Hadoop分布式文件系统(HDFS)和Map-Reduce，Hadoop并成为了非常优秀的分布式系统基础架构。 2005年，Amazon宣布Amazon Web Services云计算平台。 2006年，Amazon相继推出在线存储服务S3和弹性计算云EC2等云服务。 2006年，Sun推出基于云计算理论的“BlackBox”计划。 2007年，Google与IBM在大学开设云计算课程。 2007年3月，戴尔成立数据中心解决方案部门，先后为全球5大云计算平台中的三个(包括Windows Azure、Facebook和Ask.com)提供云基础架构。 2007年7月，亚马逊公司推出了简单队列服务(Simple Queue Service，SQS)，这项服务使托管主机可以存储计算机之间发送的消息。 2007年11月，IBM首次发布云计算商业解决方案，推出“蓝云”(Blue Cloud)计划。 2008年1月，Salesforce.com推出了随需应变平台DevForce,Force.com平台是世界上第一个平台即服务的应用。 2008年2月，EMC中国研发集团云架构和服务部正式成立，该部门结合云基础架构部、Mozy和Pi两家公司共同形成EMC云战略体系。 2008年2月，IBM宣布在中国无锡太湖新城科教产业园为中国的软件公司建立第一个云计算中心。 2008年4月，Google App Engine发布。 2008年中，Gartner发布报告，认为云计算代表了计算的方向。 2008年5月，Sun在2008JavaOne开发者大会上宣布推出“Hydrazine”计划。 2008年6月，EMC公司中国研发中心启动“道里”可信基础架构联合研究项目。 2008年6月，IBM宣布成立IBM大中华区云计算中心。 2008年7月，HP、Intel和Yahoo联合创建云计算试验台Open Cirrus。 2008年8月3日，美国专利商标局(以下简称“SPTO”)网站信息显示，戴尔正在申请“云计算”(Cloud Computing)商标，此举旨在加强对这一未来可能重塑技术架构的术语的控制权。戴尔在申请文件中称，云计算是“在数据中心和巨型规模的计算环境中，为他人提供计算机硬件定制制造”。 2008年9月 Google公司推出Google Chrome浏览器，将浏览器彻底融入云计算时代。 2008年9月，甲骨文和亚马逊AWS合作，用户可在云中部署甲骨文软件、在云中备份甲骨文数据库。 2008年9月，思杰公布云计算战略，并发布新的思杰云中心(Citrix Cloud Center，C3)产品系列。 2008年10月，微软发布其公共云计算平台——Windows Azure Platform，由此拉开了微软的云计算大幕。 2008年12月，Gartner披露十大数据中心突破性技术，虚拟化和云计算上榜。 2008年，亚马逊、Google和Flexiscale的云服务相继发生宕机故障，引发业界对云计算安全的讨论。 2009年，思科先后发布统一计算系统(UCS)、云计算服务平台，并与EMC、Vmware建立虚拟计算环境联盟。 2009年1月，阿里软件在江苏南京建立首个“电子商务云计算中心”。 2009年4月，VMware推出业界首款云操作系统VMware vSphere 4。 2009年7月 Google宣布将推出Chrome OS操作系统。 2009年7月，中国首个企业云计算平台诞生(中化企业云计算平台)。 2009年9月，VMware启动vCloud计划 构建全新云服务。 2009年11月，中国移动云计算平台“大云”计划启动。 2010年1月，HP和微软联合提供完整的云计算解决方案。 2010年1月，IBM与松下达成迄今为止全球最大的云计算交易。 2010年1月，Microsoft正式发布Microsoft Azure云平台服务。 2010年4月，英特尔在IDF上提出互联计算，图谋用X86架构统一嵌入式、物联网和云计算领域。 2010年，微软宣布其90%员工将从事云计算及相关工作。 2010年4月，戴尔推出源于DCS部门设计的PowerEdgeC系列云计算服务器及相关服务。]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>流程开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算-基础概念-私有云公有云混合云]]></title>
    <url>%2F2021%2F11%2F11%2F%E4%BA%91%E8%AE%A1%E7%AE%97-%E5%9F%BA%E7%A1%80%E6%A6%82%E5%BF%B5-%E7%A7%81%E6%9C%89%E4%BA%91%E5%85%AC%E6%9C%89%E4%BA%91%E6%B7%B7%E5%90%88%E4%BA%91%2F</url>
    <content type="text"><![CDATA[公有云概念公有云是部署云计算最常见的方式。公有云资源（如服务器和存储空间）由第三方云服务提供商拥有和运营，这些资源通过 Internet 提供。在公有云中，所有硬件、软件和其他支持性基础结构均为云提供商所拥有和管理。在公有云中，你与其他组织或云“租户”共享相同的硬件、存储和网络设备。你可以使用 Web 浏览器访问服务和管理帐户。公有云部署通常用于提供基于 Web 的电子邮件、网上办公应用、存储以及测试和开发环境。 优势 成本更低 — 无需购买硬件或软件，仅对使用的服务付费。 无需维护 — 维护由服务提供商提供。 近乎无限制的缩放性 — 提供按需资源，可满足业务需求。 高可靠性 — 具备众多服务器，确保免受故障影响。 但是同时，很多人担心公有云的安全性、私密性等问题。于是就有了私有云。 私有云概念私有云是云计算的另一种形式。它为一个企业或组织提供专用的云环境。私有云可以由企业或组织内部的IT团队在该组织的防火墙后面进行内部操作，因此组织可以更好地控制其计算资源。私有云主要由企业使用，因此它也被视为一种企业云。私有云可在物理上位于组织的现场数据中心，也可由第三方服务提供商托管。私有云中，服务和基础结构始终在私有网络上进行维护，硬件和软件专供组织使用。私有云可使组织更加方便地自定义资源，从而满足特定的 IT 需求。私有云的使用对象通常为政府机构、金融机构以及其他具备业务关键性运营且希望对环境拥有更大控制权的中型到大型组织。 优势 灵活性更高 — 组织可自定义云环境以满足特定业务需求。 安全性更高 — 资源不与其他组织共享，从而可实现更高控制性和安全性级别。 缩放性更高 — 私有云仍然具有公有云的缩放性和效率。 但是私有云的费用相对较高， 并且维护成本也不低。于是有的厂商结合了公有云和私有云推出了混合云。 混合云概念混合云是一种云计算模型，它通过安全连接（如V**连接或租用线路）组合一个或多个公有云和私有云环境，从而允许在不同云环境之间共享数据和应用程序。当在私有云上运行的应用程序遇到使用高峰时，它们可以自动“突发”到公有云环境以获得额外的按需容量。这被称为“云爆发”。由于额外的需求将在公有云上，因此无需担心提前配置硬件以满足高峰需求。连接公有云和私有云有两种方法：V**和点对点专用连接。混合云通常被认为是“两全其美”，它将本地基础架构或私有云与公有云相结合，组织可利用这两者的优势。在混合云中，数据和应用程序可在私有云和公有云之间移动，从而可提供更大灵活性和更多部署选项。 优势 控制性 — 组织可针对敏感资产维持私有基础结构。 灵活性 — 需要时可利用公有云中的其他资源。 成本效益 — 具备扩展至公有云的能力，因此可仅在需要时支付额外的计算能力。 容易轻松 — 无需费时费力即可转换至云，因为可根据时间按工作负荷逐步迁移。 混合云整合了公有云和公有云的优势。它提供高可扩展性，几乎无限的存储空间，灵活的支付模式，并且与公有云一样具有成本效益。混合云也非常安全；它为您提供了更多的灵活性和对云资源的控制。 社群云社群云，也称社区云，是由几个组织共享的云端基础设施，它们支持特定的社群，有共同的关切事项，例如使命任务、安全需求、策略与法规遵循考量等。管理者可能是组织本身，也能是第三方；管理位置可能在组织内部，也可能在组织外部。 社群云在模式和机制、可靠性、安全、组织管理等方面面临挑战，有待进一步解决。社群云与私有云、公有云相比模式上复杂一些，由多个组织共同构建和共享云设施。 这四种云的主要区别就是使用的人群和使用的方式不一样： 公有云由公众开放使用 私有云由单一组织独占使用 混合云则是前述的两种以上模式的混合 社群云是由一个特定社区独占使用，该社区由具有共同关切 (如使命、安全要求、政策等) 的多个组织组成 参考资料microsoftalibabacloud]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>基础概念</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WDL - 入门简介]]></title>
    <url>%2F2021%2F11%2F09%2F2021-11-09.WDL-%E5%85%A5%E9%97%A8%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[WDL 是 Workflow Description Language的缩写，有时也写作 Workflow Definition Language，是美国 Broad Institute 推出的工作流描述语言。从开发者及开发者赋予的名字中，我们就能看出WDL是一个面向生物信息/基因组学领域的专业的工具。 经过几年的发展，WDL 已经是生信行业广泛接受的一种工作流标准，具有下面的优势： Human-readable WDL 作为一种为工作流领域定制的语言，和 Shell、Python 等通用的脚本语言相比，没有过多复杂的概念，对使用者的计算机技能要求不高，对于生信用户容易上手。 Portable Workflow WDL 可以在多个平台执行，比如本地服务器、SGE 集群，云计算平台等，可以做到一次编写多处执行。 Standard 作为GA4GH支持的工作流描述语言之一，已经得到了众多大厂和行业协会的支持，形成了比较完善的生态。 在GATK4的best practice中，不再像以前那样给出每个步骤对应的代码，而是直接给出了官方使用的pipeline。这些pipeline采用WDL进行编写。 参考文档WDL参考文档 Broad WDL 官方论坛 WDL项目仓库 标准流程描述语言 WDL 阿里云最佳实践 在学习编写 WDL 的过程中，可以参考 Broad 官方的一些 GATK工作流 借鉴和学习 WDL 的用法。 流程结构组成WDL是一种流程编写语言，没有太多复杂的逻辑和语法，入门简单。首先看一个hello world的例子 1234567891011workflow myWorkflow &#123; call myTask&#125;task myTask &#123; command &#123; echo &quot;hello world&quot; &#125; output &#123; String out = read_string(stdout()) &#125;&#125; 对于一个WDL脚本而言，有以下5个重要的核心结构 workflow：工作流定义 task：工作流包含的任务定义 call：调用或触发工作流里面的 task 执行 command：task在计算节点上要执行的命令行 runtime：task在计算节点上的运行时参数，包括 CPU、内存、docker 镜像等 output：task 或 workflow 的输出定义 1. workflow &amp; call 每个脚本包含1个workflow，定义了一个可执行的流程，由多个task构成。 在workflow中，通过call调用对应的task。每个task在workflow代码块之外单独定义。 task可以是一个模块化的一系列命令，（这个特性非常重要，特别是在容器化环境下，有机会详细说），它可以复用。由call 语句调用在workflow block里面，task本身定义在外围，它可以import,强烈建议这样书写增加可维护性，这里先不展开说了。task调用的顺序及书写顺序不决定流程执行task的顺序，但撰写过程应该尽可能保持整个流程的可读性。 2. task &amp; command &amp; output task代表任务，读取输入文件，执行相应命令，然后输出。command中对应的就是执行的命令，比如一条具体的gatk的命令，output 指定task的输出值。可以将task理解为编程语言中的函数，每个函数读取输入的参数，执行代码，然后返回，command对应执行的具体代码，output对应返回值。 3. globglob 是指对 workflow 或 task 的输出，支持通配符匹配。123output &#123; Array[File] output_bams = glob(&quot;*.bam&quot;)&#125; 使用场景:输出文件有多个，且文件名不确定 使用方法:采用 glob 表达式，用 array 方式存储多个输出文件 价值:输出结果支持通配符匹配，简化 WDL 编写，采用数组方式，方便并发处理 4. Call cachingCall caching 是 Cromwell 的一个很有用的高级特性，通过 task 的复用，帮助客户节省时间，节省成本。 适用场景: 输入和运行环境不变的情况下，复用之前 task 的运行结果 命中条件: 输入 + 运行时参数相同 价值: 复用之前的执行结果，节省时间，节省成本 5.批量计算 runtime用于配置任务运行时的相关参数。使用批量计算作为后端时，主要的 runtime 参数有：1234567891011121314151617181920212223242526cluster: 计算集群环境 支持serverless 模式和固定集群模式mounts: 挂载设置 支持 OSS 和 NASdocker: 容器镜像地址 支持容器镜像服务simg: 容器镜像文件 支持singularity 镜像systemDisk: 系统盘设置 包括磁盘类型和磁盘大小dataDisk: 数据盘设置 包括磁盘类型、磁盘大小和挂载点memory: 所需的任务内存cpu: 所需的计算核心数目timeout: 作业超时时间maxRetries: 指令允许定义在发生故障时可以重新提交流程实例的最大次数。 具体的参数解释及填写方法，请参考 Cromwell 官方文档 除此之外，还有一些其他的概念 runtime parameter_meta meta从官方版本45开始，Cromwell 使用批量计算作为后端，支持 glob 和 Call caching 两个高级特性。 变量的定义对应WDL的结构，变量也分为两层，task层和workflow层。最基本的变量有两个，一种是File，对应文件，一种是String对应的是字符。task层的变量可以引用workflow层的变量，也可以直接传参。下面我举个例子来说明一下： 变量的类型，主要有以下几种： String Int Float File Boolean Array[T] Map[K, V] Pair[X, Y] Object关于每一种变量的使用，以及 WDL 的更多使用技巧，请参考官方规范文档。 示例1234567891011121314151617181920212223242526272829workflow helloHaplotypeCaller &#123; File Ref String Sample call haplotypeCaller&#123; input: RefFasta=Ref, sampleName=Sample &#125;&#125;task haplotypeCaller &#123; File GATK File RefFasta File RefIndex File RefDict String sampleName File inputBAM File bamIndex command &#123; java -jar $&#123;GATK&#125; \ -T HaplotypeCaller \ -R $&#123;RefFasta&#125; \ -I $&#123;inputBAM&#125; \ -o $&#123;sampleName&#125;.raw.indels.snps.vcf &#125; output &#123; File rawVCF = &quot;$&#123;sampleName&#125;.raw.indels.snps.vcf&quot; &#125;&#125; 在workflow层，我们定义了两个变量，Ref和Sample，在call haplotypeCaller的过程中，我们用input语句将它们传给了task层的RefFasta和sampleName，这样的话，提升了传参的复用——只用给Ref和Sample两个变量传参，多个task都可以引用它们。而其它的变量则可以由输入文件一起传入。 以上就是关于WDL的基本架构与变量的内容，一个最基本的WDL文件就可以完成了，接来就要准备对应的输入与执行了，我们会继续介绍。 流程组成task 如何组装成 workflow一个 workflow 里面包含多个 task，task 之前的串行或并行关系如何表达呢？主要有下面三种情况： Linear Chaining Multi-input / Multi-output第二种是多输入多输出的场景，一个 task 可以定义多个输入和输出，比如上面的例子，task B 有两个输出，作为 taskC 的输入。 Scatter-Gather Parallelism 第三种场景是用于 task 的并发执行。如果一个 task 有多个样本需要并发处理，可以使用数组的方式将样本传入，然后使用 scatter 并发的处理每个样本，每个执行的单元称为一个 shard。所有的 shard 执行完成，则当前 task 执行完成，所有 shard 的输出，又作为一个数组，可以传递到下一个 task 处理。 输入参数如何传入配置文件生成与填写workflow 的输入，比如基因样本的存储位置、计算软件的命令行参数、计算节点的资源配置等，可以通过 json 文件的形式来指定。使用 wdltools 工具可以根据 WDL 文件来生成输入模板：1java -jar wdltools.jar inputs myWorkflow.wdl &gt; myWorkflow_inputs.json 模板格式如下：123&#123; &quot;&lt;workflow name&gt;.&lt;task name&gt;.&lt;variable name&gt;&quot;:&quot;&lt;variable type&gt;&quot;&#125; 当然，如果工作流不是很复杂，也可以按照上面的格式手写 input 文件。下面是一个 GATK 工作流的 input 文件的片段： 示例 task定义：UnmappedBamToAlignedBam 工作流解析 整个 Workflow 由5个 task 组成 Task 之间通过 Linear Chaining 的方式组合 每个 Task 是子 Workflow，由多个 Task 组合而成。也就是说 WDL - 支持嵌套，workflow 里面的任务，既可以是一个 task，也可以是一个完整的 workflow，这个 workflow 被称为sub workflow。更多关于嵌套的用法请参考官方规范文档。 WDL 怎么运行执行引擎 CromwellCromwell 是 Broad Institute 开发的工作流管理引擎。具有如下的优势： 支持 WDL 和 CWL 两种工作流描述语言 多平台支持，包括本地服务器、SGE集群、云计算平台等 阿里云批量计算是官方支持的云平台之一 丰富的元数据，展示工作流执行过程 支持多种高级特性，优化 workflow 的执行 语法检查工具WDL 编写完成后，在真正执行之前，我们可以使用官方工具进行语法检查：1java -jar wdltool.jar validate myWorkflow.wdl 使用 Cromwell 运行 WDL使用 Cromwell 运行 WDL 有两种模式 Run 模式用来执行单个 WDL，适用于调试初期，快速执行一个WDL。 1$ java -jar cromwell.jar run echo.wdl --inputs input.json Server 模式用下面的命令启动一个 HTTP server 1$ java -Dconfig.file=application.conf -jar cromwell.jar server 再使用 RESTful API 提交工作流到 server 执行：1$ java -jar cromwell.jar submit -t wdl -i input.json -o option.json -h http://localhost:8000 相比 Run 模式，Server 模式有以下优势： 可以并行处理多个 workflow，适用于生产环境 有 Call caching 等高级特性（下文会讲到），优化 workflow 的执行 提供丰富的 workflow metadata，来展示 workflow 的执行过程 注意：不管是使用Run 模式还是 Server模式，要使用批量计算作为后端运行 WDL，都需要对应的配置文件支持，配置文件详解请参考批量计算官方文档或Cromwell 官方文档。]]></content>
      <categories>
        <category>云计算</category>
        <category>任务调度</category>
      </categories>
      <tags>
        <tag>流程开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[注释软件的转录本选择]]></title>
    <url>%2F2021%2F11%2F07%2F2021-11-07.%E8%BD%AC%E5%BD%95%E6%9C%AC%E7%9A%84%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[简介临床检测过程中，面对的一个比较复杂的问题，就是转录本的选择。 转录本的选择转录本的选择需要结合相关预期临床用途。目前华大相关产品的转录本选择方案参考文档： 肿瘤产品转录本选择管理规程文档仍在准备受控阶段，后续确定终板需要进行更新。 转录本切换评估方案构建结构注释bed文件首先基于新的转录本，构建一个描述基因结构的bed文件。该文件应该包含所关注的转录本结构区域。 在NCBI上下载对应版本的基因结构注释结果文件*gff格式。 使用 /jdfstj1/B2C_COM_P1/Research_and_Development/Database/Transtript_choose/5.1.1NCBI/gff2bed.pl 脚本将将gff格式的结构文件转化为bed文件（NCBI.gff2bed.bed)。 使用bedtools对产品检测范围进行结构注释。需要基于捕获区间分别对新旧转录本获取该文件。 1234567891011# 对原始bed进行排序bedtools sort -i BedPrePare/Pancancer_v2.bed &gt; BedPrePare/Pancancer_v2.sort.bed# 对原始bed区域进行合并bedtools merge -i BedPrePare/Pancancer_v2.sort.bed &gt; BedPrePare/Pancancer_v2.merge.bed# 基于结构文件对原始bed区域进行注释bedtools intersect -a BedPrePare/Pancancer_v2.merge.bed -b NCBI.gff2bed.bed -wb | cut -f1-3,7-10 &gt; BedPrePare/Pancancer_v2.anno.bed# 评估相关基因的覆盖情况bedtools intersect -b BedPrePare/Pancancer_v2.merge.bed -a NCBI.gff2bed.bed -wao &gt; BedPrePare/Pancancer_v2.covercheck.bed 对现有产品的新旧转录本文件进行比较。确定差异检测范围 获得两套转录本区域（该区域指和检测范围区间交集为基础）之间的交集 1bedtools intersect -a Pancancer_v2.anno.Oldtrans.bed -b Pancancer_v2.anno.Newtrans.bed &gt; old_new.overlap.bed 获得切换转录本后减少的区域 1bedtools subtract -a Pancancer_v2.anno.Oldtrans.bed -b Pancancer_v2.anno.Newtrans.bed &gt; old.subtract.new.bed 切换转录本后增加的区域 1bedtools subtract -a Pancancer_v2.anno.Newtrans.bed -b Pancancer_v2.anno.Oldtrans.bed &gt; new.subtract.old.bed 接受替换的标准 针对就转录本进行替换时，需要额外补充如下评估内容 更换转录本后，由于转录本涵盖区间发生改变，需要将更换后，不会提报的范围反馈解读。基于临床历史检测结果的变异进行汇总统计。确认是否会影响致病变异位点的输出。 核查新旧转录本特异性区域，对应的公共数据库交集区域，确定更换转录本对公共数据库变异范围产生的影响。 针对肿瘤检测相关产品可参考数据库如下： ClinVar Cosmic 备注由于部分原始下载文件中，染色体编号常规命名和常规使用命名方式可能会存在出入； 因此在下游处理过程中需要对染色体编号进行转换，转换关系如下： NCBI获取染色体编号和NC编码之间的对应关系|Molecule name | GenBank sequence | |RefSeq sequence|Unlocalized sequences count||-|-|-|-|-||Chromosome 1|CM000663.1|=|NC_000001.10|2||Chromosome 2|CM000664.1|=|NC_000002.11|0||Chromosome 3|CM000665.1|=|NC_000003.11|0||Chromosome 4|CM000666.1|=|NC_000004.11|2||Chromosome 5|CM000667.1|=|NC_000005.9|0||Chromosome 6|CM000668.1|=|NC_000006.11|0||Chromosome 7|CM000669.1|=|NC_000007.13|1||Chromosome 8|CM000670.1|=|NC_000008.10|2||Chromosome 9|CM000671.1|=|NC_000009.11|4||Chromosome 10|CM000672.1|=|NC_000010.10|0||Chromosome 11|CM000673.1|=|NC_000011.9|1||Chromosome 12|CM000674.1|=|NC_000012.11|0||Chromosome 13|CM000675.1|=|NC_000013.10|0||Chromosome 14|CM000676.1|=|NC_000014.8|0||Chromosome 15|CM000677.1|=|NC_000015.9|0||Chromosome 16|CM000678.1|=|NC_000016.9|0||Chromosome 17|CM000679.1|=|NC_000017.10|4||Chromosome 18|CM000680.1|=|NC_000018.9|1||Chromosome 19|CM000681.1|=|NC_000019.9|2||Chromosome 20|CM000682.1|=|NC_000020.10|0||Chromosome 21|CM000683.1|=|NC_000021.8|1||Chromosome 22|CM000684.1|=|NC_000022.10|0||Chromosome X|CM000685.1|=|NC_000023.10|0||Chromosome Y|CM000686.1|=|NC_000024.9|0| 竞品公司的转录本信息世和燃石基因转录本-part1燃石基因转录本-part2]]></content>
      <categories>
        <category>NGS</category>
        <category>数据</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>Annotation</tag>
        <tag>BGI work</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基因注释软件-VEP]]></title>
    <url>%2F2021%2F11%2F03%2F2021-11-03.%E5%9F%BA%E5%9B%A0%E6%B3%A8%E9%87%8A%E8%BD%AF%E4%BB%B6-Vep%2F</url>
    <content type="text"><![CDATA[简介在TCGA等大型项目中，也推荐使用了VEP作为注释软件，同时，TCGA项目提供了由VEP向MAF转换的工具 vcf2maf，该工具由MSK长期跟进及维护。VEP 是Ensemble旗下开发的软件，有众多的专业人员进行着更新维护，同时他也符合 CLIA Variant Effect Predictor（VEP）是功能强大的注释、分析工具。它可以对二代测试产生的不同类型变异进行注释，包含SNPs, insertions, deletions, copy number variants和structural variants。也可以依据各种数据库的内容，根据需要，对变异进行过滤和排序。 安装VEP的安装可以直接参考官方说明 #]]></content>
      <categories>
        <category>NGS</category>
        <category>software</category>
      </categories>
      <tags>
        <tag>Annotation</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[肿瘤NGS检测开发过程中的方法学]]></title>
    <url>%2F2021%2F10%2F29%2F2021-10-29.%E8%82%BF%E7%98%A4NGS%E6%A3%80%E6%B5%8B%E5%BC%80%E5%8F%91%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E6%96%B9%E6%B3%95%E5%AD%A6%2F</url>
    <content type="text"><![CDATA[肿瘤NGS检测开发过程中的方法学 李金明，高通量测序技术[M]. 李金明，个体化医疗中的临床分子诊断[M]. Rehm H L, et al. ACMG clinical laboratory standards for next-generation sequencing[J] 2013. Aziz N, et al. College of American Pathologists’ laboratory standards for next-generation sequencing clinical tests[J] 2015. Matthijs G, et al. Guidelines for diagnostic next-generation sequencing[J] 2016. Jennings L J, et al. Guidelines for validation of next-generation sequencing–based oncology panels[J] 2017. Li M M, et al. Standards and guidelines for the interpretation and reporting of sequence variants in cancer[J] 2017. Roy S, et al. Standards and guidelines for validating next-generation sequencing bioinformatics pipelines[J] 2018. 产品开发过程中的深度确定测序深度或覆盖深度被定义为覆盖给定核苷酸位置的reads的数量，生物信息学工具极其依赖于足够的覆盖深度，以便灵敏和特异地检测变异。覆盖深度与稳定检测样本的变异之间的关系很简单，因为更高数量的高质量测序数据为特定位置的碱基检测供了信心，无论来自测序样本的碱基调用是否是与参考碱基相同（未识别出变异）或者是非参考碱基（识别出变异）。 然而，许多因素会影响所需的深度，包括测序平台，目标区域的序列复杂性（与基因组的多个区域具有同源性的区域、重复序列元件或假基因的存在以及GC富集区域）。此外，用于目标富集的文库制备和需要评估的变异类型也是重要的考虑因素。因此，必须在检测开发和验证过程中系统地评估每个 NGS 测试的覆盖模型。 这些性能参数可以并且应该在开发阶段进行评估，以帮助定义验证的接受标准。例如，对于给定比例的突变等位基因，可以使用二项分布方程来确定检测到最小数量等位基因的概率： 而在一个确定的检测体系下，我们可以知道一个体系的错误率（LOB），和预期的检测限。这时我们可以根据所需的检测下限、读取质量和假阳性或假阴性结果的容忍度来估计所需的覆盖深度(可以游有效区分真阳性和真阴性的最低深度)。123456789101112131415161718192021222324252627282930313233343536373839404142library("ggplot2")Totaldepth=5000 # 预期深度，控制评估的深度上限ErrorRate=0.004 # 基于产品首批高深度产品，评估获得LOBLoDRate = 0.01 # 产品预期的检测性能，后期LOD需要单独进行评估补充。CI = 0.9 # 对性能结果要求的置信区间。depthlist = c(1:Totaldepth)ErrorReadNumlist = depthlistSupportReadNumlist = depthlistfor (depth in 1:Totaldepth) &#123; ErrorReadNum = round(depth * ErrorRate) # 考虑错误率统计过程中本身已经是错误率的最高值，所以不再进行二项分布扩展。 #ErrorReadNum = qbinom(CI,depth,ErrorRate) # 错误率考虑上95置信区间。 SupportReadNum = qbinom(1-CI,depth,LoDRate) ErrorReadNumlist[depth] = ErrorReadNum SupportReadNumlist[depth] = SupportReadNum&#125;Difference= SupportReadNumlist - ErrorReadNumlisttype=c(rep(paste('Error:',ErrorRate),times=Totaldepth),rep(paste('Detect:',LoDRate),times=Totaldepth),rep('Difference',times=Totaldepth))depth=c(depthlist,depthlist,depthlist)read_num=c(ErrorReadNumlist,SupportReadNumlist, Difference)data=data.frame(type, depth,read_num)# ggplot(data,aes(x=depth,y=read_num,cluster=type,color=type))+geom_line()+geom_hline(yintercept = 2)## 确定目标深度Target_depth="Not Find "for(i in Totaldepth:1)&#123; if(Difference[i]&lt;2)&#123; Target_depth = i+1 break &#125;&#125;## 绘图ggplot(data,aes(x=depth,y=read_num,cluster=type,color=type)) + geom_line() + geom_hline(yintercept = 2) + annotate(geom = 'text', x= 2000, y = 30, label = paste("Totaldepth=5000\nLOBRate=0.0013\nLODRate=0.01\nCI=0.99\nDepth=",Target_depth )) 内部共享PPT]]></content>
      <categories>
        <category>NGS</category>
        <category>标准化</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>Standards and guidelines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker - 入门简介]]></title>
    <url>%2F2021%2F10%2F29%2Fdocker-%E5%85%A5%E9%97%A8%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[基本概念 镜像（Image）：Docker 镜像就相当于是一个静态的root文件系统。就类似一个模板，根据这个模板可以创建多个容器。 容器（Container）：镜像和容器的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等。 仓库（Repository）：用来保存镜像的地方。有共有仓库和私有仓库之分。 培训材料大IT一体机培训PPT 初始配置镜像配置1234#配置阿里云镜像sudo yum-config-manager \ --add-repo \ http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo 镜像加速器 镜像加速器地址 Docker 中国官方镜像 https://registry.docker-cn.com DaoCloud 镜像站 http://f1361db2.m.daocloud.io Azure 中国镜像 https://dockerhub.azk8s.cn 科大镜像站 https://docker.mirrors.ustc.edu.cn 阿里云 https://&lt;your_code&gt;.mirror.aliyuncs.com 七牛云 https://reg-mirror.qiniu.com 网易云 https://hub-mirror.c.163.com 腾讯云 https://mirror.ccs.tencentyun.com 启动服务12345#启动dockersudo systemctl start docker#重启dockersystemctl restart docker.service 容器使用获取镜像 docker pull1$ docker pull ubuntu 启动容器 docker run1234docker run -it -v /share:/share 6015a1bc5eb51fb /bin/bash ；启动镜像# 交互式启动容器docker run -it ubuntu:15.10 /bin/bash 参数 含义简介 -t 在新容器内指定一个伪终端或终端。 -i 允许你对容器内的标准输入 (STDIN) 进行交互。 -d 在后台启动一个容器，所有后台容器都有一个唯一的容器ID 查看运行容器 docker ps123456docker ps #查看运行中的容器CONTAINER ID IMAGE COMMAND ... 5917eac21c36 ubuntu:15.10 &quot;/bin/sh -c &apos;while t…&quot; ...docker -H :4000 ps -a 查看所有任务；docker -H :4000 logs 92293811f94f ；查看特定任务的日志文件 Title 含义 CONTAINER ID 容器 ID。 IMAGE 使用的镜像。 COMMAND 启动容器时运行的命令。 CREATED 容器的创建时间。 STATUS 容器状态。 PORTS 容器的端口信息和使用的连接类型（tcp\udp）。 NAMES 自动分配的容器名称。 查看容器标准输出 docker logs在宿主主机内使用 docker logs 命令，查看容器内的标准输出：1docker logs 2b1b7a428627 进入容器 docker attach/exec12345#attach 进入容器后，如果退出容器会导致容器停止docker attach 1e560fca3906 # exec 进入容器后，如果退出，容器不会停止docker exec -it 243c32535da7 /bin/bash 退出容器 exit1234#交互状态中镜像中运行exit 或者使用 CTRL+D 退出容器root@0123ce188bd8:/# exitexitroot@runoob:~# 停止容器 docker stop重启容器 docker restart导出容器 docker export12#将一个镜像导出一个快照文件docker export 1e560fca3906 &gt; ubuntu.tar 导入容器 docker import12#可以使用 docker import 从容器快照文件中再导入为镜像，以下实例将快照文件 ubuntu.tar 导入到镜像 test/ubuntu:v1:cat docker/ubuntu.tar | docker import - test/ubuntu:v1 删除容器 docker rm12345#删除指定容器docker rm -f 1e560fca3906#下面的命令可以清理掉所有处于终止状态的容器。docker container prune 提交镜像 docker commitdocker commit 92293811f94f ；制作docker镜像；]]></content>
      <categories>
        <category>云计算</category>
        <category>镜像</category>
      </categories>
      <tags>
        <tag>流程开发</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MAF文件格式]]></title>
    <url>%2F2021%2F10%2F20%2F2021-10-20.maf%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[规范化参考来源TCGA 是其定义了一个相对标准的变异描述格式MAF 其中文件定义了，提升流程的规范性]]></content>
      <categories>
        <category>NGS</category>
        <category>知识沉淀</category>
        <category>文件格式</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>文件格式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Standards and guidelines for the interpretation of sequence variants]]></title>
    <url>%2F2021%2F02%2F19%2F2021-02-19.Standards-and-guidelines-for-the-interpretation-of-sequence-variants%2F</url>
    <content type="text"><![CDATA[参考文献Standards and guidelines for the interpretation of sequence variants: a joint consensus recommendation of the American College of Medical Genetics and Genomics and the Association for Molecular Pathology 遗传变异分类标准与指南 遗传变异分类标准与指南整理PPT材料 工作组 ACMG、 分子病理协会(the Association for Molecular Pathology, AMP) 美国病理学家协会(the College of American Pathologists, CAP)应用范围基因分型、单基因、基因包、外显子组和基因组. 使用特定标准属于来描述孟德尔疾病相关的基因变异: ACMG Standards and Guidelines 遗传变异分类标准与指南 pathogenic 致病的 likely pathogenic 可能致病的 uncertain significance 意义不明确的 likely benign 可能良性的 benign 良性的 建议临床分子基因检测应在符合临床实验室改进修正案(CLIA)认证的实验室中进行, 其检测结果应由通过职业认证的临床分子遗传学家或分子遗传病理学家或相同职能的专业人员解读. 术语突变： 是指核苷酸序列的永久性改变 多态性：指频率超过1%的变异。 命名标准的基因变异命名由人类基因组变异协会(the Human Genome Variation Society,HGVS)维护和版本化(https://www.hgvs.org/mutnomen), 除非另有说明, 一般推荐该命名法作为确定变异命名的首要准。 当描述变异时，可利用这些工具提供正确的HGVS命名(http://mutalyzer.nl)。 编码命名应该使用翻译起始密码子ATG中的A作为位置编号1来描述。 协会支持的参考转录本通常可以通过LRG数据库(http://www.lrg-sequence.org)、CDS 共识数据库(https://www.ncbi.nlm.nih.gov/CCDS/CcdsBrowse.cgi) 、人类基因突变数据库(http://www.hgmd.cf.ac.uk) 、ClinVar(http://www.ncbi.nlm.nih.gov/clinvar)或特异基因座数据库来确定 文献及数据库使用在使用人群数据库时,须明确数据库收录的是健康群体的信息还是患病群体的信息; (如能确认)数据库是否收录了同一家庭多名成员的信息以及数据库收录的受试者的年龄范围. 当使用数据库时, 临床实验室应做到: 确定数据库的更新频率, 确定数据库收录相关数据时是否进行了校勘, 以及采用什么方法进行数据校勘; 确认采用HGVS 命名体系, 并确定􁧿述变异的基因组版本和转录本参考序列; 确定数据分析准确度的验证程度(如变异是源自于低覆盖的新一代测序,还是通过了Sanger 测序验证), 并分析用于评估数据准确度的各种指标, 要获得这些信息可能需要阅读相关的文献; 确定收录对象的来源及其唯一性. 生物信息学计算预测程序各种公共和商业化计算机工具可以辅助解读序列变异. 每种工具使用的算法可能有差异, 但都会包含序列变异在核苷酸及氨基酸水平上作用影响的判断, 包括变异对主要转录本, 可变转录本, 其他基因组元件影响作用的确认. 主要分为两类: 一类可以预测错义变异是否会破坏蛋白质的功能或结构; 另一种可以预测是否影响剪接 多数算法预测已知致病的错义突变的准确率能达65%~80%[12]. 但是大多数工具的特异性较低, 导致有些错义改变被过度预测为有害突变, 而且对于影响较小的错义变异的预测也不可靠[14]. 目前临床实验室常用的错义变异解读工具有PolyPhen 2[15],SIFT[16]和MutationTaster[17]. 序列变异解读的拟定标准以下评估变异证据的方法是用了解释在临床诊断实验室中具有疑似遗传(主要指孟德尔遗传)疾病患者的变异. 并不适用于解读体细胞变异、药物基因组(PGx)变异、或者是多基因非孟德尔复杂疾病相关的基因变异. 在外显子组或基因组研究中, 对候选基因(意义不明确的基因(GUS))应用这些准则时应当谨慎(见下面注意事项), 因为本指南目的不是满足鉴定新致病基因的研究需求.本指南提供了两套标准: 一是用于对致病或可能致病的变异进行分类(表3), 另一是用于对良性或可能良性的变异进行分类(表4). 致病变异标准可分为非常强(very strong, PVS1), 强(strong, PS1~4); 中等(moderate, PM1~6), 或辅助证据(supporting,PP1~5). 良性变异证据可分为独立(stand-alone, BA1), PVS1 极强致病性变异从业人员需谨慎考虑以下原则: 当将该类变异归类为致病性时, 需确认无功能变异(null variants)是已知的致病机理, 且与该疾病的遗传模式相一致. 例如, 有些基因(如许多肥厚性心肌病基因)只有杂合错义突变时才致病, 而杂合无功能变异却是良性的. 仅基于这一项证据来看, 对显性肥厚性心肌病来说, MYH7 基因上出现一个新的杂合无义突变不一定是致病的, 而CFTR 基因上出现一个新的杂合无义突变则有可能是一个隐性致病变异. 当文献中将3′远端下游截短变异注释成致病突变时, 要特别小心. 特别是当所预测的终止密码子出现在最后一个外显子, 或者出现在倒数第二个外显子的最后50 个碱基对时, 这种无义突变介导的转录降解[22]可能不会发生, 这个蛋白很可能会表达.据此所预测的截短蛋白的长度也是致病性评估的因素, 但这些变异未经功能分析是无法进行判定的. 就剪接位点变异而言, 因外显子剪切位点的供体/受体位点改变或产生了新的剪切位点, 从而可能导致外显子丢失、缩短, 也可能会使内含子序列变成外显子部分. 虽然剪切位点变异可能被预测为无功能变异, 然而该变异类型造成的影响需要通过RNA 或蛋白质功能分析确认. 还必须考虑可读框内缺失/插入的可能性, 其长度变化较小(PM4), 可以保留蛋白质的关键结构域, 因此导致轻微或中性效应,或功能获得效应. 基因会有不同的转录本, 哪一种转录本与生物学功能相关, 在哪些组织会表达哪些转录本, 这些都是需要进行重点考虑的. 如果一个截短变异只限于一个或并非所有转录本, 则必须谨慎考虑到可能存在其他同功型蛋白质, 防止过度解释. 如果发现一个无功能变异位于某个外显子上, 而该外显子先前无致病变异报道, 那么该外显子可能被选择性剪切了, 此时需要谨慎考虑该变异的致病性. 当预测的截短变异是偶然发现时(与检测指征无关)则应特别小心, 在这种情况下该位点致病的可能性非常低. PS1 极强致病性变异多数情况下, 尤其是当致病机制是蛋白质功能发生改变时, 如已确定某一错义变异是致病变异, 应考虑到与其位于同一变异位点的不同形式的碱基改变也可能产生相同的错义突变结果——氨基酸改变相同(如c.34G&gt;C(p.Val12Leu)和c.34G&gt;T(p. Val12Leu)), 那么, 这些变异也应是致病突变. 需要重点注意:变异可能不是通过改变氨基酸的水平, 而是通过改变DNA 的序列来发挥作用, 例如, 破坏剪接位点(可通过软件分析确定), PS2 PM6 新发变异当将一个新发变异(父母样本检测结果阴性)归类为强的致病证据时, 需要满足以下条件: (i) 身份检验表明患者的父母是其生物学父母. 注意如果父母的身份是假定的而没有被证实, 则判定为PM6; (ii)患者的家族史符合新发变异特征. 例如, 显性遗传病患者的父母均未患病. 在存在生殖细胞嵌合现象时也可能有1 个以上同胞患病; (iii) 患者的表型与变异基因异常引起的表型相吻合. 例如患者具有特殊面容、多毛和上肢缺陷(即Cornelia de Lange 综合征), 检测到NIPBL 基因的新生突变即为强致病证据, 而患者仅表现为非特异性的发育迟缓, 通过外显子组测序发现的该基因的新发变异, 则判断此变异致病性的证据较弱. PS3 BS3 功能研究功能实验研究是一种研究变异致病性的非常强大的工具, 然而并非所有的功能研究都能有效地预测基因或蛋白的功能. 重点注意功能实验的有效性、重复性和稳定性应重点考虑, 这些参数用来评估功能实验的分析性能以及判定样本诊断信息的完整性, 该完整性容易受标本采集的方法及时间、存储及运输的影响. 评估变异在剪接位点、编码序列、非翻译区以及更深的内含子区域的影响时, 对变异在信使RNA 水平(如信使RNA 的稳定性、加工或翻译)进行评估, 可以提供丰富的信息. 相关的技术方法包括对RNA 和/或互补DNA 衍生物进行直接分析, 以及体外微小基因剪接分析 PS4 PM2 BA1 BS1 BS2 变异频率及对照人群的使用通过搜索公共人群数据库(如千人基因组数据库, NHLBI 外显子测序数据库, EXAC 数据库; 表1),并利用已发表文献中相同种族的对照数据进行基因变异频率分析(译者注: 此条款在指南更新时会有修改), 通过分析变异基因在对照人群或普通人群中的携带频率, 有助于评估该变异的潜在致病性. NHLBI外显子测序数据库来源于白种人和非裔美国人群,根据其数据覆盖量能够识别是否存在基因变异. 尽管千人基因组数据库缺乏评估基因变异能力, 但它囊括了更多的种族人群, 因此其数据具有更广泛代表性的. EXAC 数据库近期发布了一组来源于不同人群的6 万多个外显子组的等位基因频率数据, 包括了大约三分之二的NHLBI 外显子测序数据. 一般情况下, 某一等位基因在对照人群的频率大于疾病预期人群(表7)时, 可认为是罕见孟德尔疾病良性变异的强证据(BS1), 如果频率超过5%时, 则可认为是良性变异的独立证据(BA1). 此外, 如果疾病发生在早期,且变异在健康成人中以隐性(纯合子)、显性(杂合子)或X-连锁(半合子)的状态存在, 那么这就是良性变异的强证据(BS2). 如果数据库中未能检出变异的存在,应该确认建立该数据库采用的测序读长深度是否足以检测出该位点上的变异. 如果在一个大样本的普通人群或队列数据的对照人群(&gt;1000 人)中变异不存在(或隐性遗传的突变频率是低频), 并且携带此变异的患者与对照人群为同一种族, 那么可以认为该变异是致病性的中等证据(PM2). 许多良性变异是“个体化的”(即个人或家系独有的), 因此即使在相同种族的人群中缺乏也不能作为致病性的充足甚至强的证据 PM1 热点突变和/或关键的、得到确认的功能域某些蛋白结构域对蛋白质的功能起到了关键作用, 如果在这些结构域上发现的所有错义突变均已被证实为致病突变, 且这些结构域中一定没有已知的良性突变, 那么这就能作为致病的中等证据. 此外, 基因中某些功能尚未确定的区域已被证实存在许多突变热点, 若突变发生在基因突变热点上, 且一个或多个邻近残基中存在较高频率的已知致病突变,那么这也能作为致病的中等证据. PM3 BP2 顺式/反式检测检测双亲样本以确定变异在基因上以顺式(incis)(位于基因的同一拷贝)或是反式(in trans)(位于基因的不同拷贝)方式排列, 这对评估变异的致病性非常重要. 例如, 当两个杂合变异发生在隐性遗传病的致病基因上时, 如果已知其中一个变异为致病变异,那么当另一个待分类变异与其呈反式排列时, 这可以作为待分类变异的中等致病证据(PM3). 另外, 若待分类变异与多个已知致病变异均呈反式排列, 则该证据可升级为强致病证据. 但是, 若待分类变异在普通人群中存在, 则需要用统计学方法判断该现象是否为随机共发生事件. 相反, 当已知致病变异与另一个待分类变异呈顺式排列时, 这可以作为待分类变异的良性支持证据(BP2). 如果发生在隐性遗传病致病基因上的两个杂合变异的致病性均未知, 那么确定它们以顺式或是反式排列, 并不能为判断其中任一变异的致病性􁨀供更多信息. 但是, 如果两者以顺式排列, 则该基因两个拷贝均受影响的可能性将会降低.对于显性遗传病而言, 若待分类变异与致病变异呈反式排列, 则可作为该变异的良性支持证据(BP2); 对于特定研究成熟的疾病模型, 甚至可以考虑将其作为独立良性证据(如CFTR 相关变异的评估) PM4 BP3 由于框内缺失/插入和终止密码子丧失导致的蛋白长度改变相较于单一的错义突变所导致的蛋白质长度变化, 一个或多个氨基酸的缺失或插入、以及由终止密码子变为翻译氨基酸的密码子(如终止密码子丢失)而导致的蛋白质延长更可能破坏蛋白质功能. 因此,框内缺失/插入以及终止密码子丢失可作为中等致病证据. 缺失、插入或延伸范围越大, 缺失区域的氨基酸越保守, 则支持致病的证据越强. 相反, 在重复区域或在进化中不是很保守的区域中小的框内缺失/插入致病的可能性较小 PM5 同一位置新的错义变异如果一个新发错义突变发生在一已知致病突变导致相同氨基酸改变的位置上( 如Trp38Ser 和Trp38Leu), 那么可作为中等致病证据(但不能假定一定是致病的), 尤其当新的突变比已知致病错义突变更保守时. 此外, 不同的氨基酸变化可能导致不同的表型. 例如, FGFR3 基因编码的Lys650 残基的不同变化与不同的临床表型相关: p.Lys650Gln 或p.Lys650Asn 会导致轻度软骨发育不良; p.Lys650Met会导致严重的软骨发育不全伴发育迟缓和黑棘皮病;p.Lys650Glu 会导致2 型发育异常及致命的骨骼发育不良. PP1 BS4 共分离分析在使用家系中变异的共分离现象作为致病性证据时需谨慎. 事实上, 一个与某种表型相关的特定变异在某一家系中的共分离现象是位点与疾病连锁的证据, 而不是变异本身致病性的证据. 一个已经发表的统计方法显示, 在某个家系中鉴定的变异可能与真正的致病变异是连锁不平衡的. 统计模型考虑到了年龄相关的外显率和拟表型率, 一些新的方法也将生物信息分析预测以及与已知致病突变共存作为致病性的单独定量指标. 将远亲纳入统计之中是很重要的, 因为与核心家系成员相比, 他们不太可能同时有该疾病和变异. 对整个基因进行测序(包括整个内含子和5′和3′非编码区)可排查其他致病变异或另一个可能致病的变异的存在. 除非仔细评估基因位点, 否则非致病变异可能被错误地认为是致病变异.当目标基因的特定变异在多个患病的家系成员中以及不同种族背景的多个家系中与表型或疾病共分离时, 则其作为致病的证据不太会受到连锁不平衡和确认偏倚的影响. 在这种情况下, 该标准可以作为中等或强致病证据而不是支持性证据, 其强度取决于共分离的程å度.另一方面, 一个变异与表型并不共分离时, 为其非致病的强证据. 需要进行仔细的临床评估来排除正常个体的轻度症状和可能的拟表型(患者表型由非遗传或不同的遗传原因引起). 此外, 需确认生物学家庭关系来排除收养、非生父、精子和卵子捐献以及其他非生物学关系. 同时, 外显率下降和年龄依赖性的外显率也必须考虑, 以确保无症状家系成员是真正的无症状.在临床实验室进行共分离的统计评估可能并不容易, 当鉴定了合适的家系时, 为了确保建模合适,并避免得出变异与疾病相关性的错误结论, 鼓励临床实验室与统计或群体遗传学专家合作. PP2 BP1 变异谱许多基因具有明确的致病变异和良性变异谱.在某些基因中, 错义突变是导致疾病的常见原因, 且该基因上的良性突变非常少, 那么这种基因上的新发错义突变可作为致病变异的支持证据(PP2). 相反,有些基因致病的唯一已知变异是截短突变, 该基因上的新发错义突变可作为良性的支持证据(BP1). 例如, ASPM 基因的截短变异是该基因引起常染色体隐性遗传小头畸形的主要致病变异类型, 且该基因发生错义多态性突变的频率高, 因此ASPM 基因上的错义变异可认为是良性影响的支持证据. PP3 BP4 生物信息分析数据不能过分相信生物信息分析所得到的结果, 特别是不同的生物信息算法依赖于相同或相近的数据进行预测, 并且大多数生物信息算法未被已知致病变异验证过. 此外, 相同算法对不同的基因的预测结果可能完全不同. 如果不同种类算法的分析预测结果一致, 那么生物信息分析结果可以作为支持的证据. 如果绝大多数算法的预测结果不一致, 则这些预测的结果不能用于对变异进行分类. 若某一变异引起的氨基酸改变, 在多个非人哺乳动物物种不太保守的区域中出现, 说明该变异可能不会损害功能, 可以作为良性解读的强的证据. 然而, 如果某基因已在人类中发生进化(如参与免疫功能的基因), 那么在判定该基因在非保守区域中发生的变异为良性时必须小心. PP4 表型支持考虑到几乎所有接受疾病针对性测试的患者都有某种表型, 通常, 不将患者表型与某个基因临床特征谱匹配作为判断致病的证据. 但是, 如果满足以下条件, 患者的表型可作为支持证据: (i) 临床检测的灵敏度高, 大多数带有该基因致病突变的患者都被检测为阳性; (ii) 患者有某种明确的综合征的症状,与其他临床表现几乎无重叠(如戈尔林综合征包括基底细胞癌、掌跖坑和牙源性角化); (iii) 该基因通常不存在太多的良性变异(可通过外显子组等人群测序确定的良性变异); (iv) 家族史与疾病遗传方式一致. PP5 BP6 可靠的来源现在有越来越多可靠来源(如长期专注于某一疾病领域的临床实验室)的致病性分类信息被分享在数据库中, 但分类判断所依据的证据往往并未􁨀供或者很难获取. 在这种情况下, 如果分类信息是近期􁨀交的, 那它就可以作为一个单独的支持证据. 然而,还是鼓励实验室共享分类的判断依据, 并与􁨀交者进行沟通以评估和创建分类证据. 如果能获得证据,则不应使用这一条款, 而是应该使用相关的证据. BP5 对共发变异的观察一般情况下, 当某一变异是在一个有明确的遗传病因的疾病患者中被观察到时, 可作为将该变异解读为良性的证据. 不过, 也有例外. 某一个体可以是某一不相关隐性遗传疾病致病变异的携带者, 因此本证据与隐性遗传性疾病相比, 更支持显性遗传性疾病基因良性变异的分类. 此外, 有些疾病当具有多个变异可以导致更严重的疾病. 例如, 在一个具有严重表型的显性遗传患者中鉴定了两个变异, 一个是致病的, 一个是新的变异, 父母中的一个也有轻微的疾病, 这种情况下, 必须考虑新的变异致病的可能性, 且新的变异使先证者表型加重. 在这种临床情况下, 观察到的第二个新的变异不应分类为良性变异,(尽管在无进一步证据的前􁨀下也不认为该变异是致病的). 最后, 有些疾病已知为多基因遗传模式, 如Bardet-Beidel 综合征, 在第二个基因座位上的额外变异也有可能是致病的, 但应谨慎进行报告. BP7 同义变异人们逐渐认识到经典的剪接序列以外的剪接错误是一类重要的致病机制, 特别是对那些功能丧失为其常见致病机制的基因. 因此, 在假设同义核苷酸改变没有影响时应持谨慎态度. 然而如果核苷酸位置进化不保守, 且剪接评估算法预测其对剪接一致序列没有影响, 也不会产生新的经典剪接序列, 那么剪接影响的可能性就比较小. 因此, 如果生物信息分析证据支持(BP4), 可将新发同义变异分类为可能良性. 然而, 如果生物信息分析证据表明剪接可能有影响或怀疑有影响(例如, 发生在隐性遗传病致病基因上, 且与已知致病突变呈反式排列的变异), 那么在有功能评估可以􁨀供更确切的对影响的评估, 或者得到其他可排除该变异致病作用的证据之前, 该类变异应该归类为意义不明确. 序列变异报告报告应该使用清晰的语言书写, 避免使用医学遗传学术语, 当必须要使用时需指明所用术语的定义。 报告应包含所有的检测基本要素:, 结构化的结果 解释 参考文献 检测方法 适当的免责声明. 结果应根据HGVS 命名规则(见命名部分)列出变异.基本内容包括： 核苷酸(基因组和cDNA)和蛋白质水平的命名 基因名称 疾病 遗传模式 外显子 合子性 变异的分类. 若亲本来源明确, 也可包括在内. 当报告外显子组或全基因组测序结果, 或偶尔报告包含基因数目较多的疾病基因包检测结果时, 将变异按“与表型明确相关的疾病基因的变异”、“与表型可能相关的疾病基因的变异”及(在适当情况下)“附带(次要)发现”进行分类可能有益。 解读解读应包含对变异检测结果进行分类的证据,包括编码蛋白的功能影响预测, 以及检测所发现的变异是否可能全部或部分地解释患者的临床表型.报告也应包括对临床医生的建议, 这些建议包括一些需补充的临床检测, 如对患者进行细胞酶学/功能的检测, 以及对患者家系其他成员进行的变异检测,以便为进一步解读变异检测结果􁨀供支持. 解读应当包括检测结果部分􁧿述的全部变异, 以及其他附加信息. 对于各个变异需要注明是否已经在先前的文献、疾病病例或对照数据库中有过报道. 在报告结尾处需要列出对变异检测结果分类时所引用的全部参考文献和信息. 方法学报告中应说明使用的实验方法、检测所涉及的变异类型、检测过程的难点, 以及检测变异所使用的方法的局限性. 需要说明的实验方法应包括核酸的获取方法(如聚合酶链式反应、捕获、全基因组扩增等)以及核酸的检测方法(如双向Sanger 测序、下一代测序、染色体基因芯片、基因分型技术等), 这些信息可以为医务工作者􁨀供必要的信息, 以帮助其决定是否需要追加实验来跟进这些检测结果. 方法部分还应包括人类基因组组织基因命名委员会批准的正式基因名称、转录本的RefSeq 登录号和所参考的基因组版本. 对于大的基因包, 基因水平的信息可以通过引用URL 来加以说明. 实验室还可以选择增加对检测过程中常见问题(如样本质量问题、样品混合污染等)的免责声明. 患者维权团体、临床实验和研究的获取尽管不提倡在实验室报告中对患者􁨀供具体临床指导, 但是在报告中􁨀供对于检测结果分类的总体信息(如全部阳性检测结果)是恰当且有益的. 大量病人群体和临床试验现在可用于多种疾病的支持和治疗. 实验室可以选择将此信息添加到报告的正文或附加信息, 并且与报告一起发送给医务工作者. 在遵守医疗保险便携性和责任法案(HIPAA)保护患者隐私的前􁨀下, 当某一变异检测结果被归为意义不明确时, 实验室可尝试帮助医务工作者和特定的疾病研究小组建立联系. 变异再分析随着新的变异证据增加, 现有的分类标准需要修订. 例如, 当大样本的有效的人群变异频率被报道后, 许多原本意义不明确的变异, 可以因为明确意义而进行重新分类, 而检测家系中其他成员的结果也可以导致重新分类.随着检测变异数量的增加及检测范围的扩大,无论是全外显子检测还是全基因组测序, 都可以得到数以百万的变异信息量. 如果实验室缺乏有效的分析方法和足够的文献数据库支撑, 将无法进行变异再分析. 为了满足医务人员和患者的实际需求, 实验室应该开展基因检测数据再分析, 并明确再分析是否产生额外费用. 应该鼓励实验室为帮助医务人员和患者而不断开发更新信息的新途径[31,32].当报告中有针对主要指征的基因中存在临床意义不明的变异, 在实验室又无法及时􁨀供更新的数据时, 建议医务人员定期查询其不明意义的变异结果是否被更改. 另一方面, 鼓励实验室在对变异的分类有重要变化时(如致病性或良性的变异被修改)必须主动及时地更新报告. 关于医生对病人报告更新方面的责任, 可详见ACMG 有关指南. 验证对于孟德尔疾病的致病或可能致病变异需进行正交法验证. 具体方法包括但不限于以下几种: 重新取样和检测、检测父母的变异情况、限制性内切酶消化、对于目标区域重新测序或使用另一种基因分型技术。 特殊考虑]]></content>
      <categories>
        <category>NGS</category>
        <category>标准化</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>Standards and guidelines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Standards and Guidelines for the Interpretation and Reporting of Sequence Variants in Cancer]]></title>
    <url>%2F2021%2F02%2F19%2F2021-02-19.Standards-and-Guidelines-for-the-Interpretation-and-Reporting-of-Sequence-Variants-in-Cancer%2F</url>
    <content type="text"><![CDATA[参考文献Standards and Guidelines for the Interpretation and Reporting of Sequence Variants in Cancer 整理汇总PPT材料 摘要下一代基于测序的癌症测试的临床实验室的广泛实施突出了标准化实验室间分子结果的解释和报告的重要性和潜在的好处。分子病理学协会召集了一个多学科工作组，负责评估基于下一代测序技术的癌症检测的现状，并建立体细胞序列变异的标准化共识分类，注释，解释和报告惯例，并由美国医学遗传学和基因组学学院联络代表，美国临床肿瘤学会和美国病理学家学院。根据专业调查，文献综述和工作组主题专家共识的结果，提出了一种基于体细胞序列变异的临床意义进行分类的四级系统：一级，具有很强临床意义的变异； II级，具有潜在临床意义的变体； III级，临床意义未知的变体；和第四级，变体被视为良性或可能良性。癌症基因组学是一个快速发展的领域。因此，应不断评估治疗，诊断或预后中任何变异的临床意义。报告基因组变异应遵循标准命名法，并明确描述测试方法和限制。临床建议应简明扼要，并与组织学和临床发现相关联。 分类 tier I, variants with strong clinical significance; tier II, variants with potential clinical significance; tier III, variants of unknown clinical significance; tier IV, variants deemed benign or likely benign. 导读基于二代测序技术的肿瘤检测已越来越多的应用于临床实验室中，但目前在不同实验室间存在检测方法、报告内容等方面的差异，这对遗传检测的解读以及普及应用造成了一定的影响。因此，在不同实验室间建立统一的分子检测结果的解读和报告标准，及建立行业标准，显得尤为迫切。 在2015年春天，在美国专门成立了一个以临床实验室为核心的工作组，其组成包含了分子病理协会（AMP）、美国医学遗传学与基因组学协会（ACMGG）、美国临床肿瘤学会(ASCO）与美国病理学家协会（CAP)的一线专家，该工作组的主要工作为对肿瘤及疑似肿瘤相关的序列变异检测建立检测标准并在行业达成共识。 该工作组首先对北美地区超过40家的临床检测实验室进行了问卷调查，结果显示不同实验室在检测组织类型、检测基因数量、是否检测肿瘤组织全外显子组或全基因组、以及其他细节方面都存在较大差别，此外在不同单位的检测报告的报告内容方面也存在较多差异。该工作组认为，为医疗机构提供分类的遗传变异报告对病人及整个医疗行业都极为重要，包括：提供精确的肿瘤对靶向治疗反应性信息；建立国家级别的医疗指南；以及与临床试验合作，对建立不同实验室间的通用标准提供支持。基于以上这些考量，工作组专家们根据已有数据、文献报道和专业知识，给出以下指南建议. 对多个公司的报告情况调研结果如下 图1 AMP对NGS技术及NGS结果解读的调研 A: MAF阈值. B: 变异分类数目 C:报告中是否包含治疗性建议 . D: 报告中是否包含潜在的生殖细胞突变. E: 报告是否包含变异等位频率Variant allele frequency (VAF) F: 报告是否包含基因组坐标 G: 报告是否包含转录本ID(Transcript accession) H: 报告是否包含不符合质控的基因/区间 数据库 Genomic Databases随着越来越多的针对各种肿瘤类型的大规模基因组测序项目的发布，全球正在产生大量的基因组信息并将其整合到许多公共数据库中（表1）。例如，美国国家癌症研究所（National Cancer Institute）的基因组数据共享（Genome Data Commons）包含美国国家癌症研究所（National Institutes Institutes）从一些最大和最全面的癌症基因组数据集中生成的数据.包括 ： The Cancer Genome Atlas, Therapeutically Applicable Research to Generate Effective Therapies, and the Cancer Genome Characterization Initiative (https://gdc.cancer.gov, last accessed September 25, 2016). Another public somatic variant database is the Catalog of Somatic Mutations in Cancer (http://cancer.sanger.ac.uk/cosmic, last accessed September 30, 2016). 其中包含数百万种跨多种肿瘤类型的体细胞变异。体细胞变异分析中经常使用的其他几个数据库，例如参考序列信息，种群数据库和种系变异数据库也在不断增加和改进。基因组数据库提供了准确注释和确定体变异优先级所必需的信息。 在使用这些数据库是，整体上应该遵循乳癌规则： 了解数据库的内容以及如何汇总数据。临床实验室应查看与给定数据库有关的文档或公开文献，以确定数据库的来源，类型和意图 特别注意每个数据库的限制，以避免对注释结果的过度解释。 确认人类基因组装配的版本以及mRNA转录本参考，以确保适当的人类基因组变异学会（HGVS）注释。 尽可能使用基因组坐标而不是HGVS命名法来明确查询基因组数据库。 根据出版物或其他数据库的来源，单个或多个特定条目的数量，研究的深度，使用适当的对照，确认变异的体细胞来源，评估提供的基因组数据的质量以及功能和潜在药物反应研究。 验证所提供病理诊断的数据质量（例如，地点，诊断和子类型 Reference Sequence Databases参考序列数据库提供有关人类基因组装配版本的信息以及相关信息，例如基因组坐标，以明确表示序列变异。附加信息，例如mRNA转录本的登录和版本（例如，BRAF NM_004333.4）和外显子边界定义，对于产生变异的正确HGVS命名法至关重要。可以从这些数据库中计算基因的变异位置图谱（编码，非编码，非翻译区和剪接位点）和链表述（阳性与阴性）。这也允许在没有基因组坐标信息的情况下明确表示变异。一些常用资源包括： RefSeq（国家生物技术信息中心参考序列数据库，https：//www.ncbi.nlm.nih.gov/refseq，上次访问时间为2016年1月2日） Ensembl（http://www.Ensembl.org）。 ensembl.org/index.html，最后访问时间为2016年1月2日） Locus Reference Genomic （https://www.lrg-sequence.org，最近访问时间为2016年2月2日）。 Population Databases这些数据库提供了有关大量特定人群中给定基因座上替代（次要）等位基因频率的全面信息。这些数据库通常用于根据次要等位基因频率（MAF）的任意临界值筛选出被认为是多态/良性的变异。目前尚无用于去除多态或良性变异的MAF的标准临界值。在没有正常组织配对的情况下，工作组建议使用1％（0.01）作为主要阈值，这在许多临床实验室中也很普遍。尽管总体MAF最常用，但临床实验室可能会考虑使用种族-根据患者的种族背景确定特定的MAF。在解释体细胞变异时，必须谨慎使用这些数据库，因为在参与研究时，假定参与这些测序研究的个体是健康的或没有亚临床疾病。确实，一些众所周知的经典癌症相关的和可靶向的体细胞改变已作为种群数据库的种系变异包括在内。例如，变异NM_004972.3（JAK2）：c.1849G&gt; T（c.V617F）通常被看作是叶绿体增生的体细胞变异体肿瘤，可以用FDA批准的Janus激酶（JAK）抑制剂靶向。它也包含在多个人群数据库中，例如 The Database of Short Genetic Variation (the National Center for Biotechnology Information database of genetic variation), Exome Variant Server, and Exome Aggregation Consortium（表格1）。在评估可能的血液系统恶性肿瘤时应格外小心，因为白血病和骨髓增生异常综合症中的许多常见突变基因也可能在其他健康个体的血液中发生体细胞突变，因此可能被错误地注释为多态性。 Cancer-Specific Databases这些数据库提供了有关不同癌症和亚型谱中序列变异的发生率和普遍性的信息，对其他基因组数据库的交叉引用以及对已发表或未进行系统综述的文献的引用，细胞途径，靶向疗法，临床试验 以及结果数据。 从这些数据库中提取的不同癌症中的序列变异体的普遍性和分布，应谨慎解释，因为病理诊断标准的代表性较差，缺乏临床级别的文献管理以及提交变异体的来源控制不严（例如，探索性或 发现研究）。 例如，这些数据库中包括一些常见的种系良性变异，例如 the Catalog of Somatic Mutations in Cancer database 中的NM_000222.2（KIT）：c.1621A&gt; C（p.M541L）。 表1列出了常用的体细胞变异数据库。 Constitutional Variant Databases常见的是，在有或没有匹配的正常组织的情况下进行肿瘤测序可能会揭示出种系起源的变异，例如与癌症易感综合症相关的基因中的致病变异。种系突变数据库，例如人类基因突变数据库和其他疾病或基因座特异性突变数据库，是评估这些变异的有用资源。这些数据库也可用于评估在这些数据库中报道了经过充分研究的种系对应物的体细胞变异（例如，TP53和PTEN基因中的某些变异）。另一个常用的数据库是ClinVar（http://www.ncbi.nlm.nih.gov/clinvar）。 ClinVar处理所有种类的稀有种系变异，例如病原体和良性，并在可用时提供相关的临床和实验证据。专家小组对ClinVar中的某些变异进行了有关其致病性的审查。目前，该数据库仅宿主种系变异，并有望在不久的将来纳入体细胞变异。 Internal (Laboratory-Generated) Databases需要强调的是，临床实验室应该建立一个标注良好的内部数据库，以跟踪实验室中识别出的变异并提供一致的变异注释。这样的数据库可用于识别可能由测序比对伪像引起的潜在假阳性呼叫，以及确定实验室通常遇到的癌症类型的突变频率。我们强烈鼓励体细胞变异数据共享，并敦促临床实验室将精心挑选的变异体贡献到公共变异数据库中，以促进对体细胞变异体的准确解释。但是，此类提交过程应标准化并符合联邦隐私法规，即《健康保险可移植性和责任法案》以及《经济和临床健康信息技术法案》（原文 the Health Insurance Portability and Accountability Act andthe Health Information Technology for Economic and ClinicalHealth Act.）。 正在努力建立临床级基因组数据库 In Silico (Computational) Prediction Algorithms 在计算机模拟中，预测算法是预测基因中核苷酸变化是否会改变蛋白质结构和功能的常用工具（表2）。起初，开发了早期常用算法并验证了用于胚系变异的算法。随后，外推它们的用途以解释体细胞变异。尽管各个算法的核心风险预测方法可能有所不同，但是它们可以分为两类：错义变异对蛋白质功能的影响的预测和序列变异对剪接的影响。考虑到氨基酸或核苷酸残基的进化保守程度，特定理化特性的氨基酸取代的生物化学影响以及变异在翻译蛋白质中的位置，是不同算法用来预测功能的一些主要标准错义变异的影响。拼接位点预测算法使用各种统计方法，例如马尔可夫模型，机器学习（神经网络）和最大熵原理，来预测变异是否会对拼接产生任何影响。通常，错义和剪接位点预测工具具有中等的特异性（大约60％至80％），并且倾向于过度预测有害影响。在癌症基因功能的背景下，对这些预测的解释通常并不直接了当，特别是对于激活突变。例如，当通过多种计算机模拟算法进行分析时，经典的BRAF V600E致癌突变结果会具有冲突甚至良性的作用。这是临床实验室在进行体细胞变异解释时应该意识到的几种情况之一，同时在解释计算机分析的评分结果时应谨慎行事。建议不要将这些预测算法的结果用作变异分类或临床决策的唯一依据。 Variant Identification and Annotation变异检测是变异解释的关键起点。 有许多变异检测软件工具(Supplemental Table S2).可以满足一种特定的检测，例如SNV，插入缺失，结构变异和CNV (Supplemental Table S1): Variant caller Location (URL) MuTect v1.1.555 https://www.broadinstitute.org/cancer/cga/mutect Genome Analysis Toolkit (GATK) – MuTect v2s https://www.broadinstitute.org/gatk/guide/tooldocs/org_broadinstitute_gatk_tools_walkers_cancer_m2_MuTect2.php VarScan 256 http://dkoboldt.github.io/varscan/ VarDict57 https://github.com/AstraZeneca-NGS/VarDict Sterlka58 https://sites.google.com/site/strelkasomaticvariantcaller/ FreeBayes59 https://github.com/ekg/freebayes Scalpel60 http://scalpel.sourceforge.net/ Pindel61 http://gmt.genome.wustl.edu/packages/pindel/ SAMtools62 http://samtools.sourceforge.net/ Torrent Suite Variant Caller https://github.com/iontorrent/TS SomaticSniper63 http://gmt.genome.wustl.edu/packages/somatic-sniper/ 对于临床实验室来说，了解这些变异检测工具的局限性很重要。 对生物信息学流程（包括商业购买的生物信息学软件包）进行适当的实验室验证对于确保结果的质量至关重要。 某些称为变异的指标对于变异解释至关重要，例如 supporting reads (depth of coverage) and variant allele frequency (VAF)，应纳入变异体评估中； 后者对于在没有配对正常的情况下的体细胞变异解释和评估肿瘤克隆多样性特别重要。 变异检测结果一般使用一些标准格式进行输出展示，例如clinical variant call format(VCF), genomic VCF 和 general feature format (alias gene-finding format or generic feature format). The VCF is the most widely used schema in the clinical laboratories as of 2016 to represent detected variants (Clinical Variant Call Format, http://vcfclin.org, last accessed September 28, 2016). Required VCF fields include genomic coordinates, reference nucleotide(s), and variant nucleotide( s). However, complex, multinucleotide, and large structural variants are difficult to represent in the current specification of VCF file format version 4.2, despite the ongoing efforts for standardizing variant representation. For further clinical interpretation, additional metadata that add meaningful and readily identifiable information to variants should be included (eg, gene symbol, variant location, variant type, HGVS nomenclature for cDNA sequence changes, and predicted protein sequence alterations). Additional resources, such as cross-references to external databases (cancerspecific and general genomic databases) (Table 1) and precomputed in silico algorithm-based predictions (Table 2), can also be beneficial. This process is formally referred to as variant annotation, and may be automated by software tools(Supplemental Table S2). (Supplemental Table S2): Software Location (URL) Annovar64 http://annovar.openbioinformatics.org/en/latest/ snpEff65 http://snpeff.sourceforge.net/ SeattleSeq http://snp.gs.washington.edu/SeattleSeqAnnotation138/ AnnTools66 http://anntools.sourceforge.net/ NGS-SNP67 https://www.ualberta.ca/~stothard/downloads/NGS-SNP/ VEP (Variant Effect Predictor)15 http://useast.ensembl.org/info/docs/tools/vep/index.html 变异注释对于准确解释体细胞序列变异至关重要。这些对变异注释得到的多元数据构成了变异评估和解析的初始内容。变异注释面对的一个重要挑战就是将基因组坐标（即染色体和位置）转换为相应的cDNA /氨基酸坐标系统（分别为c.和p.syntax）以进行解读。 这个问题针对indel变异由于对齐排列导致变异表述不一致的问题上，表现尤其突出。尽管HGVS系统建议使用右对齐表示法（将变异的开始位置向右移动，直到不再可能这样做），但VCF规范要求使用左对齐表示法。当前可用的注释解决方案仅部分解决了该问题。缺乏左/右对齐的标准化可能会严重影响变异定位，从而导致变异命名错误。根据HGVS命名法，当存在多个替代转录本时，必须使用正确的mRNA转录本编号和版本信息，以确保变异描述的准确和一致。临床实验室在内部数据库中使用变异的基因组位置来存储变异信息也非常重要，以确保数据存储的明确和可回查。 Proposed Guideline for Evidence-Based Categorization of Somatic Variants体细胞变异包括SNV，插入缺失，基因组重排产生的融合基因和CNV。与胚系变异的解释（侧重于特定疾病的变异性或疾病因果关系）不同，体细胞变异的解释应着重于其对临床的影响。如果变异预测对特定疗法的敏感性，耐药性或毒性，改变基因的功能（可以被批准的或研究用的药物靶向），则该变异可以视为影响临床护理的生物标志物，可以作为临床试验的纳入标准，影响疾病的预后，帮助确定癌症的诊断或保证实施监视措施以早期发现癌症。因此，临床影响应包括治疗，预后，诊断和预防措施。给定变异的临床影响应根据当前可获得的证据确定。基于变异分类的证据在临床决策中的重要性，可以对其进行不同的权衡。在文献综述和工作组共识的基础上，我们建议将临床和实验证据分为四个级别 Level A, biomarkers that predict response or resistance toUS FDA-approved therapies for a specific type of tumoror have been included in professional guidelines astherapeutic, diagnostic, and/or prognostic biomarkers forspecific types of tumors; Level B, biomarkers that predict response or resistance toa therapy based on well-powered studies with consensusfrom experts in the field, or have diagnostic and/orprognostic significance of certain diseases based on wellpoweredstudies with expert consensus; Level C, biomarkers that predict response or resistance totherapies approved by FDA or professional societies for adifferent tumor type (ie, off-label use of a drug), serve asinclusion criteria for clinical trials, or have diagnosticand/or prognostic significance based on the results ofmultiple small studies; Level D, biomarkers that show plausible therapeuticsignificance based on preclinical studies, or may assistdisease diagnosis and/or prognosis themselves or alongwith other biomarkers based on small studies or multiplecase reports with no consensus. 可以将这些证据水平分配给基因组变异体，以确定其临床影响的重要性。 我们建议根据体细胞疾病的临床影响将其序列变体分为四类： tier I，具有强烈临床意义的变体（A和B级证据）； tier II，具有潜在临床意义的变体（C或D级证据）； tier III，临床意义未知的变体； tier IV，良性或可能良性的变体 各类别判断依据Tier I Variants: Variants with Strong Clinical Significance (Level A and B Evidence) Tier II Variants: Variants with Potential Clinical Significance (Level C and D Evidence) Tier III Variants: Variants of Unknown Significance Tier IV Variants: Benign or Likely Benign Germline Variants Identified during Cancer Testing在体细胞致癌突变的临床实验室研究中，重要的是将获得的体细胞变异体与遗传的胚系变异体区分开。大多数胚系变异体都是遗传变异，这些变异可以代代相传，并且通常在100％的细胞中具有变异，导致等位基因分数为0.5或1.0。体细胞变异是在出生后获得的，通常是由于DNA复制或修复错误或环境侵害引起的。由于存在污染正常组织的情况，因此即使在表面上纯净的肿瘤样本中，体细胞变异的等位基因分数通常&lt;0.5。实验室必须正确识别可能与诊断，预后，治疗干预和/或临床试验选择有关的体细胞突变，并且不得将高频体细胞突变错误识别为胚系变异，因为这可能具有重大的临床意义。同样，实验室必须认识到可能导致癌症易感综合症的胚系变异，这将对患者和其他家庭成员产生医疗保健影响。 为了帮助对变异进行分类，一些实验室在对正常的，匹配的对照DNA样品进行测序的同时，对肿瘤DNA进行了平行测试。当正常，匹配的对照组织与肿瘤一起测序时，胚系变异通常很明显。 In this case, the laboratory must have policies that address detection, disclosure/nondisclosure, and interpretation/reporting of germline variants (see section below). 当分析中未包括匹配的对照时，实验室应具有可用于推断变体是体细胞或胚系的标准。指定胚系的主要标准是VAF，对于杂合变体，应为约50％，对于纯合变体，应为100％。某些种系变体（例如大插入缺失）可能会导致正常等位基因的优先扩增（在基于扩增子的测试中）或捕获（在基于捕获的测试中），因为这些等位基因的序列同源性丧失，导致&lt;50％用于种系变体的VAF。当在已知的癌症易感综合征基因（例如TP53或BRCA1）中检测到明显的胚系变异时，有关疾病发作年龄的临床信息（年轻人与致癌基因中遗传的种系突变的较高风险相关） ，肿瘤的侧面性（更可能遗传双侧肿瘤）以及癌症的家族或个人病史可以帮助确定癌症易感性的可能性。文献综述和数据库查询还可以帮助确定该变异体先前是否已被报告为易感综合征患者的复发种系变异体。构成突变的有用数据库包括： Online Mendelian Inheritance in Man (National Center for Biotechnology Information, http://www.ncbi.nlm.nih.gov/ omim, last accessed March 6, 2016), Human Gene Mutation Database (http://www.hgmd.cf.ac.uk/ac/index.php, last accessed March 6, 2016), ClinVar locus-specific databases 实验室应制定一项政策，对恶性肿瘤中发现的遗传变异进行测试，以在收到患者的适当同意或根据临床医生的要求后，使用经过临床验证的生殖测试来确认变异的生殖或体细胞来源。 ACMG建议在胚系测试中显示阳性结果，以显示53个基因的阳性结果，其中大约一半与可能在体细胞检测面板上的癌症易感性基因有关。即使在仅将该胚系作为一部分进行评估的情况下，也建议进行公开 肿瘤/正常研究。 通过推断，在仅肿瘤的体细胞突变研究中也考虑种系致病变异的可能性似乎是谨慎的。 在单样本无法判断变异是体系还是胚系变异是，添加局限性说明When paired germline samples are not used, NGS analysisdoes not distinguish germline and somatic variants, andsequencing results may contain both findings. In this case,findings can be reported with a disclaimer that the NGS testused does not allow definitive differentiation betweengermline and somatic variants. In certain settings, a germlinevariant may be suspected (eg, MAF 40% to 60%). However,this interpretation should be made with caution and correlatedwith tumor cellularity. If a germline variant is suspected,testing of a patient germline sample (eg, blood in patientswith solid tumors) can be suggested if clinically indicatedafter an appropriate patient consent. The reports shouldinclude a statement addressing the manner in which thedistinction between somatic and germline alterations is made,and indications of remaining uncertainty, where appropriate. “ Interpretation and ReportingNomenclature所有检测到的遗传变异均应按照HUGO基因命名委员会的指定进行注释和报告: 基因名参考 ：HGNC :http://www.genenames.org 变异写法参考：HGVS，http：//www.hgvs.org SNV和插入缺失应使用p.和c. 符号进行报告（例如，BRAFp.V600E，c.1799T&gt; A）。 SV，列出两个融合的基因伴侣之间用斜杠分隔（例如，EML4 / ALK fusion）。 CNV应以表格形式报告为拷贝数GAIN或LOSS。 如果适用，可以包括基因/基因组基因座的基因组坐标。可以在适当的时候报告数字拷贝数的变化[例如，EGFR拷贝数GAIN（拷贝数比25）； CDKN2A拷贝数LOSS]。 使用标准术语不会超过与临床团队进行清晰明确沟通的需要。 根据需要，除了标准术语外，还应包括口语命名法，以便医生阅读报告并使用它们来确定治疗时向医生清晰地传达含义。例如，TERT启动子变体的报告可以为1-124C&gt; T（ HGVS命名法，然后是括号中的口语命名法（TERTC228T）。使用HGVS命名法报告基因组变体以明确将变体重新映射到参考基因组，而口语命名法则向临床团队传达了明确的信息。 Other Reporting Elements除了检测到的变体之外，报告还应包含其他一些元素，这些元素可能与更深入的结果分析或与随时间推移从该患者获得的其他结果进行比较有关，例如基因组座标，基因组构建和转录参考序列（ 例如NM_004333.4），前提是此信息不会损害患者和临床提供者解释该报告中与之直接相关的基本要素的能力。 本节或对结果进行扩展说明的另一节中，远离顶部结果。应评估等位基因分数（VAF）和覆盖率，并在适当时包括在报告中。该报告应包括所用NGS测定的测序覆盖率临界值。在报告中应声明所有未满足最低要求的测序覆盖率标准的基因和/或热点均已失败。 报告不应仅限于肯定的发现。 I类药物/癌症组合应包括相关的阴性结果（例如，肺癌患者中明确缺乏EGFR突变或黑色素瘤患者中明确缺乏BRAF突变）。如果存在不确定性， 必须在报告中进行沟通；这包括序列质量，样品充分性，肿瘤含量和生物医学知识的问题。 Reporting of Germline Variants希望对配对的胚系样品进行并发分析，因为这可以澄清解释。但是，这并不总是实用的，因此也不是必需的。当有成对的胚系样品可用时，测序管线可允许从体细胞获得性变体中分离出胚系发现。通常，仅解释和报告体细胞变异。如果患者或临床医生要求对胚系发现进行进一步分析，则可以在以后重新查看胚系NGS数据，并在获得患者适当同意后进行报告。成对的胚系测试可能需要获得同意并提供相关文件，以符合当地法律和政策。如果NGS小组的某些基因中未报告胚系变体，则初始报告应特别说明这一事实。当不使用成对的胚系样品时，NGS分析不能区分胚系和体细胞变体，测序结果可能包含这两个发现。在这种情况下，可以用免责声明报告使用的NGS测试不能明确区分胚系和体细胞变体。在某些情况下，可能会怀疑胚系变异（例如MAF 40％至60％）。然而，这种解释应谨慎进行，并与肿瘤细胞数量有关。如果怀疑胚系变异，如果在适当的患者同意后临床上有指示，可以建议对患者胚系样本（例如，实体瘤患者的血液）进行测试。报告中应包含一份声明，说明在体细胞和胚系变化之间进行区分的方式，并在适当情况下指示仍存在不确定性。首先测试癌症样品和稍后再配对的胚系样品的实验室可以选择进行以下操作： 将包含胚系样品发现的结果发布到癌症报告的附录中， 在胚系报告中单独发表一份关于胚系变体的报告，并附上唯一的解释性声明，并在初始癌症报告中添加一份附录。 作为单独的胚系报告和另外的单独报告发布，该报告整合了癌症和胚系样品的结果。 生殖细胞变体应按照ACMG / AMP指南进行报告。如果订购了针对癌症易感基因的生殖细胞测试，则生殖细胞变异的报告应遵循ACMG / AMP指南。应提供遗传咨询和转诊给临床医学遗传学家。实验室应制定政策，以报告重要性不明的变体并披露次要发现，包括在何种情况下将报告或不报告此类发现 Reporting the Clinical Significance of DetectedVariants对检测到的遗传变异提供解释性注释是很有用的，该变异将这种变异置于临床病理背景下可为管理决策提供依据。这对于I级和II级突变至关重要。必须对III级变体的详细分析与目标，使报告中最关键的信息保持简洁，清晰并突出显示的目的相平衡。这些评论可能包括该变体对于特定肿瘤类型，对生化途径的影响以及相关癌症的患病率的功能，预后或预测意义。但是，建议应该简短明了，并应谨慎措辞，并应理解治疗或其他患者管理决定是基于除遗传改变以外的许多医学信息，其中许多信息对于分子专业报告是不可用的。重要的是要认识到，治疗的适用性是基于许多因素，而不是根据测试申请书上写的诊断和通过测试发现的基因型。这些因素通常是分子专业报告结果所未知的（即，存在混杂的医学状况，例如葡萄糖耐量不足，自身免疫性疾病或心力衰竭），并且在推荐特定疗法时未考虑这些其他因素会导致混淆，患者与肿瘤科团队之间的冲突以及焦虑。 NGS实验室报告中的治疗建议应以证据为依据，应与患者的癌症诊断相关，并应使用某种语言来明确指出该报告包含结合实验室可用数据点的广义治疗建议（例如，diag-疾病和基因型），但需要将其他因素纳入为每个个体制定治疗计划的过程中。尽管可以接受有关相关试验的一般性陈述或已发表试验的引用结果，但不应针对具体临床试验提出建议。]]></content>
      <categories>
        <category>NGS</category>
        <category>标准化</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>Standards and guidelines</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-包-python-pptx生成PPT]]></title>
    <url>%2F2021%2F02%2F10%2FPython-%E5%8C%85-python-pptx%E7%94%9F%E6%88%90PPT%2F</url>
    <content type="text"><![CDATA[简介处于某些上下游对接需求，所以需要频繁的将生信的分析结果整理成PPT文件，以便进行结果的展示。所以基于该模块可以更方便的在集群上自动化生成相关的文档示例，用于进行后续的处理。 使用python操作PPT，需要使用的模块就是python-pptx，下面来对该模块做一个简单的介绍。这里提前做一个说明：python操作PPT，最好是我们提前设计好自己的一套样式，然后利用进行python进行内容的获取和填充（最主要的功能！），最好是不用使用python代码操作PPT的格式，格式的修改肯定不如我们直接在PPT中修改方便。可以创建、修改PPT（.pptx）文件。 环境准备模块的安装需要单独安装，不包含在Python标准模块里1234# &quot;Windows用户命令行下输入&quot;pip install python-pptx# &quot;Mac用户命令行下输入&quot;pip3 install python-pptx 模块的导入1import pptx 模块的使用python读取PPT文档中的内容在使用python操作PPT之前，首先应该清楚PPT的结构，这个对于之后代码的编写很有帮助。 获取Slide12345from pptx import Presentationprs = Presentation(&quot;统计学习方法PPT.pptx&quot;)for slide in prs.slides:print(slide) 获取Shape形状12345678910import pptxfrom pptx import Presentationprs = Presentation(&quot;统计学习方法PPT.pptx&quot;)for slide in prs.slides:for shape in slide.shapes:print(shape)&quot;&quot;&quot;注意：这里得到的Shape对象，并不能看出什么，接着往下看。&quot;&quot;&quot; 判断每个Shape中是否存在文字 shape.has_text_frame ：是否有文字 shape.text_frame ：获取文字框123456789import pptxfrom pptx import Presentationprs = Presentation(&quot;统计学习方法PPT.pptx&quot;)for slide in prs.slides:for shape in slide.shapes:if shape.has_text_frame:text_frame = shape.text_frameprint(text_frame.text) 获取某一页Slide中的内容1234567891011import pptxfrom pptx import Presentationprs = Presentation(&quot;统计学习方法PPT.pptx&quot;)for i,slide in enumerate(prs.slides):if i == 5:for shape in slide.shapes:if shape.has_text_frame:text_frame = shape.text_frameprint(text_frame.text) 获取Shape中的某个Paragraph1234567891011121314151617import pptxfrom pptx import Presentationprs = Presentation(&quot;统计学习方法PPT.pptx&quot;)for i,slide in enumerate(prs.slides):if i == 5:for shape in slide.shapes:if shape.has_text_frame:text_frame = shape.text_framefor paragraph in text_frame.paragraphs:print(paragraph.text)&quot;&quot;&quot;注意：该方法和上述4)中的方法一摸一样。上述方法是直接获取Shpae中的文字内容；下面这个更灵活，先获取每个Shape，然后在获取每个Shape中的paragraph；下面方式更好：因为我们可以针对paragraph，写一个判断条件，只获取第几个paragraph；&quot;&quot;&quot; 参考readthedocs知乎CSDN]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Office处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[snakemake介绍]]></title>
    <url>%2F2020%2F05%2F02%2F2020-05-02.snakemake%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[snakemake分享pptSnakemake介绍官方文档 shell投递常用参数： –jobs设置并行的最大任务数目。 –config向snakemake传递参数（字典形式） –configfile指定配置文件路径（可以支持多个） –cores设置任务最多使用的核数 –resources设置任务最多使用的内存 –forceall强制执行某条Rule及它的依赖。 –list展示smk脚本中所能获得的所有Rule –dag 123456生成流程逻辑框架图：snakemake xxxx(流程本身的参数) --dag | dot -Tsvg &gt; dag.svg #如果snakemake流程本身会打印输出内容，则需要单独处理如下：snakemake xxxx(流程本身的参数) --dag &gt;tmp.txt # 删除tmp.txt文档中流程自身打印的内容，然后生成图片dot -Tsvg tmp.txt &gt; dag.svg –touch更新文件的时间戳（不会重新跑） –force, -f 重新运行第一条或指定的某条Rule –forcerun, -R 强制执行snakefile，更新rule时，使用此命令。会同步更新后续的所有结果 –dry-run, 生成相关分析路径的shell脚本，但是不进行实际的执行。 –keep-going, 在某个任务失败后，继续运行其他的独立任务； –cluster 针对集群投递到计算节点的参数设置； 12345 --cluster &quot;qsub -clear -cwd -P P18Z11900N0299 -l num_proc=&#123;threads&#125; -l vf=&#123;params.resources&#125; -binding linear:&#123;threads&#125;&quot; ``` - --restart-times 任务失败后，重投的次数 –restart-times 5 123456789101112131415161718- --rerun-incomplete, 针对结果不完整的数据，重跑所有的rules；- --unlock 解锁被异常锁定的目录 - --stats 记录任务的执行状态，输出到指定文件 - --nocolor 不输出彩色的结果 - --drmaa-log-dir 仅限使用 -drmaa 进行任务调度时有效。 指定shell的log（.e 和 .o）输出目录. ### rule内的函数- protected 在文件生成后，将文件权限改为 只读文件。 `]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
        <category>任务调度</category>
      </categories>
      <tags>
        <tag>流程开发</tag>
        <tag>培训</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RPKM, FPKM and TPM]]></title>
    <url>%2F2019%2F03%2F02%2F2019-03-02.RNA%E8%A1%A8%E8%BE%BE%E9%87%8F%E7%9A%84%E8%AE%A1%E7%AE%97%2F</url>
    <content type="text"><![CDATA[过去，进行 RNA-seq 时，会以 RPKM（每千碱基百万读取数）或 FPKM（每千碱基百万片段数）的形式报告结果。然而， TPM（每千基百万转录本）现在变得非常流行。由于这些术语似乎有很多混淆，我想我会使用 StatQuest 来清除所有内容。 这三个指标试图标准化测序深度和基因长度。 RPKM 的计算过程参考如下操作： 计算样本中的总读数并将该数字除以 1,000,000——这是我们的“每百万”比例因子。 将读取计数除以“每百万”比例因子。这使测序深度标准化，为您提供每百万读数 (RPM) 将 RPM 值除以基因的长度，以千碱基为单位。这为您提供 RPKM。 FPKM 与 RPKM 非常相似。 RPKM 是为单端 RNA-seq 制作的，其中每个读取对应一个已测序的片段。 FPKM 是为PE测序的 RNA-seq 制作的。使用配对末端 RNA-seq，两个读数可以对应一个片段，或者，如果对中的一个读数没有映射，一个读数可以对应一个片段。 RPKM 和 FPKM 之间的唯一区别是 FPKM 考虑到两次读取可以映射到一个片段（因此它不会将该片段计算两次）。 TPM 与 RPKM 和 FPKM 非常相似。唯一的区别是操作顺序。以下是计算 TPM 的方法： 将读取计数除以每个基因的长度（以千碱基为单位）。这为您提供了每千碱基 (RPK) 的读数。 计算一个样本中的所有 RPK 值并将这个数字除以 1,000,000。这是您的“每百万”比例因子。 将 RPK 值除以“每百万”比例因子。这为您提供了 TPM。 所以你看，在计算 TPM 时，唯一的区别是你首先对基因长度进行归一化，然后对测序深度进行归一化。然而，这种差异的影响是相当深远的。 当您使用 TPM 时，每个样本中所有 TPM 的总和是相同的。这使得比较每个样本中映射到基因的读数比例变得更加容易。相比之下，使用 RPKM 和 FPKM，每个样本中归一化读数的总和可能不同，这使得直接比较样本变得更加困难。 这是一个例子。如果样本 1 中基因 A 的 TPM 为 3.33，样本 B 中的 TPM 为 3.33，那么我知道在两个样本中映射到基因 A 的总读数的比例完全相同。这是因为两个样本中的 TPM 总和总是相同的数字（因此计算比例所需的分母是相同的，无论您正在查看哪个样本。） 使用 RPKM 或 FPKM，每个样本中归一化读数的总和可能不同。因此，如果样本 1 中基因 A 的 RPKM 为 3.33，样本 2 中 RPKM 为 3.33，我不知道样本 1 中相同比例的读数是否与样本 2 中的基因 A 对应。这是因为需要分母计算两个样本的比例可能不同。 参考来源rna-seqblog]]></content>
      <categories>
        <category>RNA</category>
      </categories>
      <tags>
        <tag>NGS</tag>
        <tag>RNA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SGE任务调度系统相关命令记录]]></title>
    <url>%2F2019%2F02%2F23%2FLinux-SGE%E4%BB%BB%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%B3%BB%E7%BB%9F%E7%9B%B8%E5%85%B3%E5%91%BD%E4%BB%A4%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[http://gridscheduler.sourceforge.net/htmlman/ http://gridscheduler.sourceforge.net/htmlman/htmlman1/qstat.html?pathrev=V62u5_TAG sge系统管理命令队列信息查询 #### 命令 功能 qconf -sq 查询特定队列的信息 qconf -sprjl 显示项目列表 qsub12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970-V: 将当前的环境变量传递到执行命令的节点中。可以使用-v PWD 来代替-cwdcwd: 在当前目录下执行任务, sge的日志会输出到当前路径。 不增加该指令，所有投递的任务都会在家目录下执行-l resource=value: 请求资源数, 例如 -l vf=25G -l h=node1 就是任务的预估内存要25G(内存估计的值应稍微大于真实的内存，内存预估偏小可能会导致节点跑挂), 申请在node1上运行eg: qsub -cwd -l h=compute-12-13 run.sh -S： /bin/bash: 表示在bash环境下执行命令。默认tcsh.-sync y|n: 是否等待任务结束，返回退出码-o path: 指定标准输出的文件夹-j y|n ：是否将标准输入和标准输入合并成一个文件-a date_time 作业开始运行时间-b y[es]|n[o]判断作业指定是二进制文件或scripts。y ：是 n：scripts-display 使用X-windows-dl date_time 定义作业到期时间，在作业到期时间之前，作业的优先级会逐步提高，直到管理员指定的最高级别。-e 指定输出error文件的路径及文件名-hard 定义作业被调度的硬性要求-h 作业hold类型。u：表示用户hold,s:表示系统hold，o：表示被操作员hold，n：取消hold，U：取消用户hold，S：取消系统hold，O：取消操作员hold。-i 定义输入文件-j y[es]|n[o] 定义作业的标准错误输出是否写入的输出文件中-l resource=value, 表明作业运行所需要的资源。-m b|e|a|s|n 。定义邮件发送规则。b：作业开始时发送。e：作业结束时发送。a：作业失败时发送 s：作业挂起时发送。n：不发送-M user[@host] 定义邮件地址-notify ：定义发送SIGSTOP or SIGKILL信号的延迟时间-now y[es]|n[o]：立即执行作业-N 作业名-o [[hostname]:]path ：定义输出文件路径、文件名-P project_name：定义项目名称-p priority ：定义优先级-pe parallel_environment：定义并行环境-q wc_queue_list：定义作业运行队列-R y[es]|n[o]：定义是否为作业保留资源。-r y[es]|n[o]：定义作业失败后是否重新运行-soft 定义作业被调度的软性要求-u username,只有qlter命令可以使用该参数。修改作业的用户名-v variable：定义环境变量-verbose 使qrsh命令输出信息-verify 验证作业参数时使用-V 传递当前命令的所有环境变量 qconf 队列 1234567# 显示所有队列qconf -sql #显示一个队列的详细配置信息（包含的节点和负载等信息）qconf -sq queue_name #显示当前配置为执行主机的所有主机的名称列表#添加一个队列qconf -aq queue_name 用户组 12345678# 查看所有用户组qconf -sul# 查看某个用户组信息qconf -su 用户组名# 编辑用户组配置qconf -mu 用户组名# 创建用户组并把用户添加到用户组qconf -au 用户名 用户组名 其他 12345678910111213141516171819202122232425262728293031323334353637&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADqconf -sel #显示当前配置为执行主机的所有主机的名称列表qconf -se hostname #显示指定的执行主机的详细信息qconf -sh #显示具有管理权限的主机列表qconf -ss #显示提交主机列表qconf -sc #显示所配置的资源属性列表qconf -su #显示指定项目下的用户 &#123;project&#125;_userqconf -sconf #显示当前配置qconf -aprj #添加一个新项目qconf -sprjl #显示项目列表qconf -aq queue_name #添加一个队列qconf -ahgrp @host_group_name #添加主机组，hostlist中主机列表间隔用空格qconf -mconf #编辑默认Shell【login_shells bash,sh,ksh,csh,tcsh】qconf -aq #显示默认队列模板=======qconf -sel #显示指定的执行主机的详细信息qconf -se hostname #显示具有管理权限的主机列表qconf -sh #显示提交主机列表qconf -ss #显示所配置的资源属性列表qconf -sc #显示当前配置qconf -sconf #添加一个新项目qconf -aprj #显示项目列表qconf -sprjl #添加主机组，hostlist中主机列表间隔用空格qconf -ahgrp @host_group_name #编辑默认Shell【login_shells bash,sh,ksh,csh,tcsh】qconf -mconf #显示默认队列模板qconf -aq &gt;&gt;&gt;&gt;&gt;&gt;&gt; e7a8e06b1c3a982becd2d275b5cf8fbca298153c qstat 显示队列和作业的状态qstat 命令—用于查询作业状态信息123456789101112131415命令格式：qatat [-f][-a][-i] [-n][-s] [-R] [-Q][-q][-B][-u]参数说明：-f jobid 列出指定作业的信息-a 列出系统所有作业-i 列出不在运行的作业-n 列出分配给此作业的结点-s 列出队列管理员与scheduler 所提供的建议-R 列出磁盘预留信息-Q 操作符是destination id，指明请求的是队列状态-q 列出队列状态，并以alternative 形式显示-au userid 列出指定用户的所有作业-B 列出PBS Server 信息-r 列出所有正在运行的作业-Qf queue 列出指定队列的信息-u 若操作符为作业号，则列出其状态。 任务状态123456qw: 表示等待状态hqw: 任务挂起等待中，待依赖的任务完成后执行Eqw: 投递任务出错r: 表示任务正在运行s: 暂时挂起dr: 节点挂了之后，删除任务就会出现这个状态，只有节点重启之后，任务才会消失 qmod 修改队列和作业的状态123456789# 任务的挂起与恢复qmod -sj jid (已在run的job) 或 qhold jid(qw的job)挂起qmod -usj jid 或 qrls jid恢复之前挂起的任务## 登陆节点任务挂起kill -STOP pid ## 登陆节点任务恢复kill -CONT pid]]></content>
      <categories>
        <category>任务调度</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>SGE</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git-1.安装配置及基本操作]]></title>
    <url>%2F2019%2F02%2F20%2FGit-1.%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%E5%8F%8A%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[培训材料组内培训PPT官方文档 Git安装主流系统安装参考如下： linux：Debian或Ubuntu：sudo apt-get install gitCentos: sudo yum install git Windows/ macOS ：下载地址：https://git-scm.com/downloads 其他机器或系统版本可参考官网 Git安装 账号配置配置全局的name和email，参照你创建的工程Git global setup 12345git config --global user.name &quot;liubo4&quot; #存储账号git config --global user.email &quot;liubo4@genomics.cn&quot; #存储邮箱# --global：表示该机器上所有的Git仓库都会使用这个配置ssh-keygen -t rsa -C &quot;liubo4@genomics.cn&quot; #生成秘钥, 将秘钥生成的文件： id_rsa.pub 中的内容复制到gitlab中；后期可以通过密钥进行身份验证。 基本知识Git的4个结构区域git的整体工作结构区域分为如下4个区域类型 工作区：项目的工作目录 暂存区：修改的文件会暂时存储在该区域，也叫index区 本地仓库：即隐藏目录 .git，是 Git 的版本库 远程仓库：即常说的github，gitlab，可在线获取 Git文件的4种基本状态 未追踪（untracked）文件已经在文件夹中，但没有加入git库，也不参与版本控制 已修改（modified）已修改表示修改了文件，但还没保存到本地git仓库中 已暂存（staged）已暂存表示对一个已修改的文件的当前版本做了标记，使之包含在下次提交的快照中。 已提交（committed）已提交表示数据已经安全的保存在本地git仓库中。 Git的常见配置文件忽略文件（.gitignore）当不想把某些文件纳入版本控制中，比如数据库文件，临时文件，设计文件时，可以使用“.gitignore”文件进行标识“.gitignore”文件规则： 忽略文件中的空行或以井号（#）开始的行。 可以使用Linux通配符。例如：星号（*）代表任意多个字符，问号（？）代表一个字符，方括号（[abc]）代表可选字符范围，大括号（{string1,string2,…}）代表可选的字符串等。 如果名称的最前面有一个感叹号（!），表示例外规则，将不被忽略。 如果名称的最前面是一个路径分隔符（/），表示要忽略的文件在此目录下，而子目录中的文件不忽略。 如果名称的最后面是一个路径分隔符（/），表示要忽略的是此目录下该名称的子目录，而非文件（默认文件或目录都忽略）。 eg：12345#为注释*.txt #忽略所有.txt结尾的文件!lib.txt #lib.txt除外build/ #忽略build/目录下的所有文件doc/*.txt #会忽略 doc目录下“.txt”为后缀的文件 常用命令仓库的初始化 本地创建新的仓库 12git init# 新建一个git仓库，运行完后会在当前目录下生成一个.git 目录 从远程仓库中拉取一个仓库到本地 完成秘钥配置后，可以将gitlab上的项目下载到本地进行部署 1git clone remote-repertor（https://github.com/libgit2/libgit2） local—repertory(可以省了默认保持原仓库名称) 完成项目到本地的传输后，可以进行相应的安装或使用，git clone仅能用于将远程项目初始化到本地（从无到有）不支持后续的更新同步 下载更新作为多人版本协作，会有不同的人同时对项目进行更新，所以有时候会有需求将他人的更新同步到本地流程中，使用 git pull命令 正规流程 123456789git status（查看本地分支文件信息，确保更新时不产生冲突）git checkout – [file name] （若文件有修改，可以还原到最初状态; 若文件需要更新到服务器上，应该先merge到服务器，再更新到本地）git branch（查看当前分支情况）git checkout remote branch (若分支为本地分支，则需切换到服务器的远程分支)git pull 快速流程 12#上面是比较安全的做法，如果你可以确定什么都没有改过只是更新本地代码git pull (一句命令搞定) 提交更新提交更新主要分三个部分，1，更新提交到本地暂存区；2.更新到本地版本库；3.推送更新。 1234567git add file.name #将更新的文件提交到本地的缓存区；git add . # 提交目录下所有更新git rm file.name # 把目录的文件从跟踪中移除git status # 查看当前提交到缓存区的所有更新git commit -m &quot;version description&quot; #将缓存区的内容更新到本地的版本库；git commit --amend -m &quot;新的提交信息&quot; # 更新已经提交过的commit内容git push #将本地最新的版本推送到远程仓库。如果是clone下来的仓库，会推送到原下载链接所在的仓库。 版本管理对本地版本进行操作123456git reset gitversion filename# 撤销提交缓存区的偶作git reset --hard gitversion # 还原本地流程到之前的gitversion版本，放弃本地的后续版本git reset --hard HEAD^ #回退到上一个版本（&quot;^&quot; 代表回退的版本数，两个版本用&quot;^^&quot;git reset --hard HEAD~50#还原git到指定版本git log # 查看版本更新日志 –hard 不保存所有变更–soft 保留表更且变更内容处于staged–mixed 保留biang且变更内容处于modified（默认） 分支管理1234567891011121314151617181920212223#列出分支命令：git branch#创建分支命令：git branch (branchname)#切换分支命令:git checkout (branchname)#创建并切换该分支git checkout -b &lt;name&gt;#合并分支命令:git merge newtest # 将newtest分支合并到当前分支#重命名分支git branch -m/-M &lt;oldname&gt; &lt;newname&gt; #删除分支命令：git branch -d (branchname)#恢复的删除分支git branch &lt;name&gt; &lt;删除分支的commitID&gt; 远程仓库操作12345678910111213#克隆一个已有的远程git仓库git clone https://github.com/lh3/wgsim.git#把一个已有的本地仓库与远程仓库关联起来。git remote add origin https://github.com/lh3/wgsim.git#可以把本地库的所有内容推送到远程库master/dev分支git push origin master/ git push origin dev#将远程 origin 的 master 分支拉取过来，与本地的test分支合并。git pull origin master:testgit pull = git fetch + git merge Patching有记录的进行版本回退。 1234# Given one or more existing commits, revert the changes that the related patches introduce, and record some new commits that record them.git revert 当发生一次错误的提交以后，可以进行版本的还原（同时保留错误的提交记录） 大文件管理 通过使用 git lfs 进行流程中大文件的管理，需要提前安装 1.8.5以上版本的git 。 参考文档 git lfs下载安装下载 git-lfs-linux-386-v2.10.0.tar.gz 拷贝至集群。 1234567891011121314tar -zxvf git-lfs-linux-386-v2.10.0.tar.gz解压后会在当前目录产生下列4个文件-rw-r--r-- 1 OseqPub b2c1 77881 May 9 00:17 CHANGELOG.md-rwxr-xr-x 1 OseqPub b2c1 10248192 May 9 00:20 git-lfs-rwxr-xr-x 1 OseqPub b2c1 389 May 9 00:17 install.sh-rw-r--r-- 1 OseqPub b2c1 7522 May 9 00:17 README.md#将git-lfs所在目录加到环境变量中$PATH #执行 安装git lfsgit lfs install for i in `find . -type f -size +100M ` ;do git lfs track $i ;done # 跟踪大文件git lfs ls-files 可以显示当前跟踪的文件列表git lfs clone 下载lfs文件]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>培训</tag>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[天河二号作业调度系统简单使用]]></title>
    <url>%2F2018%2F12%2F07%2F2018-12-07.task-manage-in-Tianhe2%2F</url>
    <content type="text"><![CDATA[天河用户手册天河用户手册 现将天河2号的作业调度系统的简单使用方法记录于此: MPI天河2号默认使用mpich-3.2.1（使用icc-14.0.2 编译），是天河2号自主实现的mpi版本，具有较高的效率。 module 模块管理1234567module avail # 查看可用的模块的列表。module load [modulesfile] # 加载需要使用的modulefiles。module load OpenFOAM/2.2.2 # 示例 module其它用法，可在help中查询 作业调度基础12345678yhi # yhinfo命令的简写，用于查看节点状态 其中PARTITION表示分区；NODES表示节点数；NODELIST为节点列表；STATE表示节点运行状态， 其中，idle表示节点处于空闲状态，allocated表示节点已经分配了一个或多个作业。yhq # yhqueue命令的简写，用于查看作业运行情况 推荐使用“yhq -a”查看作业状态信息 其中JOBID 表示任务ID，Name表示任务名称，USER为用户，TIME为已运行时间，NODES表示占用节点数，NODELIST为任务运行的节点列表。 交互式提交作业在shell窗口中执行yhrun命令，主要命令格式如下： 123456789101112131415161718192021222324252627282930yhrun [options] program-n, --ntasks=number # 指定要运行的任务数-c, --cpus-per-task=ncpus # 每个任务需要ncpus 个处理器核-N, --nodes=minnodes[-maxnodes] # 请求为作业至少分配minnodes（最大maxnodes）个节点。 （例如“-N 2-4”或“--nodes=2-4”） 如果没有指定-N，缺省行为是分配足够多的节点以满足-n和-c参数的需求-p, --partition=partition name # 在指定分区中分配资源。如未指定，则由控制进程在系统默认分区中分配资源。-w, --nodelist=node name list # 请求指定的节点名字列表。作业分配资源中将至少包含这些节点。 列表可以用逗号分隔的节点名或节点范围（如cn[1-5,7,...]）指定，或者用文件名指定；如果参数中包含“/”字符，则会被当作文件名。-x, --exclude=node name list # 不要将指定的节点分配给作业-D, --workdir=directory # set working directory for batch script-I, --immediate[=secs] # exit if resources not available in &quot;secs&quot;-o, --output=out # location of stdout redirection-J, --job-name=jobname # name of job-l, --label # prepend task number to lines of stdout/err-h, --help # 若需使用yhrun更多选项，可通过“yhrun –h”或“yhrun --help”查看。# eg:yhrun -n 4 -p bigdata hostname yhrun -n 4 -w cn[7303-7306] -p bigdata hostname yhrun -n 4 -N 4 -w cn[7303-7304] -p bigdata hostname yhrun -n 4 -N 4 -x cn[7303-7304] -p bigdata hostname 节点资源抢占命令 yhalloc该命令支持用户在提交作业前，抢占所需计算资源 1yhalloc -N 1 -p bigdata 通过yhq查看相应的jobID 为1051，节点为cn7314，然后ssh到对应节点进行操作 ####取消自己的作业 使用yhcancel命令 1yhcancel jobid 批处理作业命令 yhbatch在资源满足要求时，分配完计算节点之后，系统将在所分配的第一个计算节点（而不是登录节点）上加载执行用户的作业脚本。 123456789cat &gt; mybash.sh #!/bin/bash yhrun -n 4 -N 4 -p bigdata hostname chmou mybash.sh yhbatch -N 4 -p bigdata ./mybash.sh 计算开始后，工作目录中会生成以slurm开头的.out 文件为输出文件。更多选项，用户可以通过yhbatch --help命令查看。如果不需要使用MPI的话，也可以不使用yhrun 单个节点上提交多个作业因为天河2是独享作业，当一个节点上已经被分配出去之后，即便没有使用全部的核心，也无法继续提交作业。所以，若想在一个节点上运行多个作业，必须同时提交上去，如下：某用户有4个 a.out 需要运行，每个a.out最多只能高效运用6 个CPU 核，那么可以构建下面的任务脚本，在一个计算节点上同时运行多个作业: 12345678cat &gt; job.sh #!/bin/bashyhrun –n 4 a.out arg.1 &amp; yhrun –n 4 a.out arg.2 &amp;yhrun –n 4 a.out arg.3 &amp;yhrun –n 4 a.out arg.4 &amp;wait # important 然后通过yhbatch –N 1 job.sh来一次提交计算任务，使所有小的计算任务都可以在一个节点同时进行计算。如果不需要使用MPI的话，也可以不使用yhrun。]]></content>
      <categories>
        <category>任务调度</category>
      </categories>
      <tags>
        <tag>任务调度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬虫学习记录-相关软件&包记录]]></title>
    <url>%2F2018%2F11%2F22%2FPython-%E7%88%AC%E8%99%AB%E5%AD%A6%E4%B9%A0%E8%AE%B0%E5%BD%95-%E7%9B%B8%E5%85%B3%E8%BD%AF%E4%BB%B6-%E5%8C%85%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[爬虫学习过程涉及的软件： 软件1. Python3.5.5整体爬虫代码的框架语言，所有Python程序及包均基于本版本。 2. chromeDriver模拟登陆chrome浏览器，驱动浏览器完成相关操作。 3.PhantomJS - 官方文档一个无界面的，可脚本编程的WebKit浏览器引擎，原生支持多种Web标准：DOM操作、CSS选择器、JSON、Canvas和SVG。Selenium包支持该引擎，使用该引擎，就可以避免运行过程中不断弹出浏览器。 4.MYSQL一个关系型数据库，用于存储相关的数据。 5.Docker一种容器技术，可以将环境和应用打包，形成一个独立的应用，这个应用可以直接被分发到任意一个支持Docker的环境中，通过简单的命令启动运行。 Python包请求库1. requests - 中文文档Python中唯一的一个http原生库。 2.Selenium - 中文文档一个自动化测试工具，利用他可以驱动浏览器执行特定的动作，如点击、下拉等操作。针对一些JavaScript渲染的页面来说，这种抓去方式非常有效。 3.aiohttp可以在爬取过程中，提供异步Web服务的库。 解析库1.lxmlPython的一个解析库，可以支持HTML和XML的解析，支持XPath的解析方式，解析效率较高。 2.beautifulsoup4HTML和XML的解析库 3.pyquery网页解析工具，提供了和jQuery类似的语法来解析html文档，支持css选择器，。 相关模块1.tesserocrPython的一个ORC（Optical Character Recognition光学字符识别）识别库。 2.pymysql用于连接MYSQL数据库，在Python中访问Mysql数据库。 3.Web库-FlaskFlask一个轻量级的Web服务程序，用来做一些Web的API服务。 4.TornodeTornode一个支持异步的Web框架。 APP爬取相关库的安装1.Charles一个网络抓包工具。 2.mitmproxy一个支持http和https的抓包工具，类似Charles和Fiddler的功能，通过控制台操作。 爬虫框架1.Pyspider2.Scrapy]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[下机数据(fastq)质控软件汇总]]></title>
    <url>%2F2018%2F11%2F19%2F2018-11-19.%E4%B8%8B%E6%9C%BA%E6%95%B0%E6%8D%AE%EF%BC%88fastq%EF%BC%89%E8%B4%A8%E6%8E%A7%E8%BD%AF%E4%BB%B6%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[常用的生物信息学ruan jian SoapNuke Fastp trimmomatic AfterQC seqtk]]></content>
      <categories>
        <category>NGS</category>
        <category>software</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>NGS</tag>
        <tag>质控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[肿瘤组Linux培训资料]]></title>
    <url>%2F2018%2F11%2F01%2FLinux-%E8%82%BF%E7%98%A4%E7%BB%84Linux%E5%9F%B9%E8%AE%AD%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[肿瘤组内部Linux系统操作普及培训材料1.简单了解Linux系统的使用 Windows安装软件XshellXftp Mac 安装软件FileZilla]]></content>
      <categories>
        <category>Linux</category>
        <category>内部培训材料</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[参考基因组版本问题汇总]]></title>
    <url>%2F2018%2F07%2F11%2F2018-07-11.%E5%8F%82%E8%80%83%E5%9F%BA%E5%9B%A0%E7%BB%84%E7%89%88%E6%9C%AC%E9%97%AE%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[不同版本参考基因组的位置坐标转换在使用参考基因组时，经常会遇到一些版本的问题，比如使用注释文件和bed文件时，不同版本的位置坐标不能直接使用，这时候，我们就需要对坐标进行转换，这里记录下一些常用的坐标转换工具： 类型 支持格式 地址 推荐指数 Liftover 在线 bed http://genome.ucsc.edu/cgi-bin/hgLiftOver 一般 Liftover 本地 bed和gff http://hgdownload.cse.ucsc.edu/admin/exe/linux.x86_64/liftOver 推荐 Remap 在线 hgvs，bed，gvf，gff，gtf，Text ASN.1，Binary ASN.1，UCSC Region和VCF https://www.ncbi.nlm.nih.gov/genome/tools/remap 推荐 CrossMap 本地 SAM/BAM,，Wiggle/BigWig， bed， gff/gtf，VCF http://crossmap.sourceforge.net/ 推荐 picard 本地 interval和VCF http://broadinstitute.github.io/picard/ 推荐VCF转换]]></content>
      <categories>
        <category>NGS</category>
        <category>知识沉淀</category>
        <category>数据库</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>参考基因</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python-包-包管理器Conda]]></title>
    <url>%2F2018%2F07%2F10%2FPython-%E5%8C%85-%E5%8C%85%E7%AE%A1%E7%90%86%E5%99%A8Conda%2F</url>
    <content type="text"><![CDATA[参考文档官方文档Github下载地址 Conda安装和卸载Conda安装下载相应的安装sh 示例如下:更多发行版本获取123wget https://repo.continuum.io/archive/Anaconda3-5.0.0-Linux-x86_64.sh #(下载Anaconda的Linux版本)bash Anaconda3-5.0.0-Linux-x86_64.sh #安装source ~/.bashrc #更新环境变量 mamba安装conda的一个优化插件，可以大幅度提高安装速度1conda install -c conda-forge -c bioconda mamba Conda配置镜像管理 添加清华的Conda镜像 1234conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/conda config --add channels defaultsconda config --add channels conda-forgeconda config --add channels bioconda 删除某个镜像 1conda config --remove channels &apos;https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/&apos; 删除所有镜像 1conda config --remove-key channels Conda卸载修改~/.bash_profile中的环境变量，去除家目录中隐藏的.condarc文件.conda文件和.continuum目录12rm -rf ~/minicondarm -rf ~/.condarc ~/.conda ~/.continuum Conda使用环境管理（conda env） 命令 功能 conda env list 列出所有Conda的环境 conda info -e 列出所有的conda环境 conda env create 创建环境 conda env create -f *.yaml 基于配置文件创建环境 conda create -n $env_name [package] 创建conda环境，同时安装相关的package（可选） conda remove -n env_name –all 删除环境 source activate \$env 切换环境 source deactivate \$env 退出环境 包管理 命令 功能 conda list 查看已经安装的包 conda list -n \$env 查看环境\$env中安装的包 conda search 查看可用的软件包 conda install &lt; package&gt;=x.x 安装x.x版本的package 更新conda环境conda update conda 创建环境conda create -n ENV_Demo package1 package2 package3；创建一个名为ENV_Demo的环境，并在环境中安装 package1 package2 package3 三个软件包 激活环境source activate ENV_Demo]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用shell命令 - cp]]></title>
    <url>%2F2018%2F07%2F10%2FLinux-%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4-cp%2F</url>
    <content type="text"><![CDATA[Linux cp（英文全拼：copy file）命令主要用于复制文件或目录。 语法1cp [options] source dest 或1cp [options] source... directory 参数说明：-a 或 --archive 此选项通常在复制目录时使用，它保留链接、文件属性，并复制目录下的所有内容。其作用等于dpR参数组合 -b 或--backup 删除，覆盖目标文件之前的备份，备份文件会在字尾加上一个备份字符串。 -d 或--no-dereference 当复制符号连接时，把目标文件或目录也建立为符号连接，并指向与源文件或目录连接的原始文件或目录。 相当于 Windows 系统中的快捷方式。 -f 或 --force 强行复制文件或目录， 不论目的文件或目录是否已经存在，不给出提示。 -i 或 --interactive 与 -f 选项相反，覆盖文件之前先询问用户，回答 y 时目标文件将被覆盖。 -l 或 --link 对源文件建立硬链接，而非复制文件 -p 或 --preserve 保留源文件或目录的属性，包括所有者、所属组、权限与时间 -P 或 --parents 保留源文件或目录的路径，此路径可以是绝对路径或相对路径，且目的目录必须已经存在 -r 递归处理，将指定目录下的文件与子目录一并处理。若源文件或目录的形态，不属于目录或符号链接，则一律视为普通文件处理 -R 或 --recursive 递归处理，将指定目录下的文件及子目录一并处理 -s 或 --symbolic-link 对源文件建立符号链接，而非复制文件 -S &lt;备份字尾字符串&gt; 或 --suffix=&lt;备份字尾字符串&gt; 用&quot;-b&quot;参数备份目的文件后，备份文件的字尾会被加上一个备份字符串。默认的备份字尾符串是符号&quot;~&quot; -u 或 --update 使用这项参数之后，只会在源文件的修改时间(Modification Time)较目的文件更新时，或是名称相互对应的目的文件并不存在，才复制文件 -v 或 --verbose 显示执行过程 -V &lt;备份方式&gt; 或 --version-control=&lt;备份方式&gt; 指定当备份文件时，备份文件名的命名方式，有以下3种: 1.numbered或t, 将使用备份编号，会在字尾加上~1~字符串，其数字编号依次递增 2.simple或never 将使用简单备份，默认的备份字尾字符串是~, 也可通过-S来指定 3.existing或nil将使用当前方式，程序会先检查是否存在着备份编号，若有则采用备份编号，若无则采用简单备份 -x 或 --one-file-system 复制的文件或目录存放的文件系统，必须与cp指令执行时所处的文件系统相同，否则不复制，亦不处理位于其他分区的文件 --help 显示在线帮助 --sparse=&lt;使用时机&gt; 设置保存希疏文件的时机 --version 显示版本 示例 将文件file1复制成文件file2cp file1 file2 复制文件，只有源文件比目标文件的修改时间新时，才复制文件cp -u -v file1 file2 将文件file1复制成file2，因为目的文件已经存在，所以指定使用强制复制的模式cp -f file1 file2 同时将文件file1、file2、file3与目录dir1复制到dir2cp -R file1 file2 file3 dir1 dir2 复制时保留文件属性（权限、时间戳）cp -p a.txt tmp/ 复制时保留文件的目录结构cp -P /var/tmp/a.txt ./temp/ 复制时产生备份文件cp -b a.txt tmp/ 复制时产生备份文件，尾标 ~1~格式cp -b -V t a.txt /tmp 指定备份文件尾标cp -b -S _bak a.txt /tmp]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用shell命令 - awk]]></title>
    <url>%2F2018%2F07%2F10%2FLinux-%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4-awk%2F</url>
    <content type="text"><![CDATA[awk是行处理器: 相比较屏幕处理的优点，在处理庞大文件时不会出现内存溢出或是处理缓慢的问题，通常用来格式化文本信息awk处理过程: 依次对每一行进行处理，然后输出awk命令形式:12345678awk [-F|-f|-v] ‘BEGIN&#123;&#125; //&#123;command1; command2&#125; END&#123;&#125;’ file [-F|-f|-v] 大参数，-F指定分隔符，-f调用脚本，-v定义变量 var=value&apos; &apos; 引用代码块BEGIN 初始化代码块，在对每一行进行处理之前，初始化代码，主要是引用全局变量，设置FS分隔符// 匹配代码块，可以是字符串或正则表达式&#123;&#125; 命令代码块，包含一条或多条命令； 多条命令使用分号分隔END 结尾代码块，在对每一行进行处理之后再执行的代码块，主要是进行最终计算或输出结尾摘要信息 特殊要点:|变量 | 含义||-|-||$0 |表示整个当前行 ||$1 | 每行第一个字段 ||NF | 字段数量变量 ||NR | 每行的记录号，多文件记录递增 ||FNR | 与NR类似，不过多文件记录不递增，每个文件都从1开始 ||\t | 制表符 ||\n | 换行符 ||FS | BEGIN时定义分隔符 ||RS | 输入的记录分隔符， 默认为换行符(即文本是按一行一行输入) ||~ | 匹配，与==相比不是精确比较 ||!~ | 不匹配，不精确比较 ||== | 等于，必须全部相等，精确比较 ||!= | 不等于，精确比较 ||&amp;&amp; | 逻辑与|||| | 逻辑或||+ | 匹配时表示1个或1个以上 ||/[0-9][0-9]+/ | 两个或两个以上数字 ||/[0-9][0-9]*/ | 一个或一个以上数字 ||FILENAME| 文件名||OFS | 输出字段分隔符， 默认也是空格，可以改为制表符等||ORS | 输出的记录分隔符，默认为换行符,即处理结果也是一行一行输出到屏幕||-F’[:#/]’ | 定义三个分隔符| 1234567891011121314151617181920print &amp; $0print 是awk打印指定内容的主要命令awk &apos;&#123;print&#125;&apos; /etc/passwd == awk &apos;&#123;print $0&#125;&apos; /etc/passwd awk &apos;&#123;print &quot; &quot;&#125;&apos; /etc/passwd //不输出passwd的内容，而是输出相同个数的空行，进一步解释了awk是一行一行处理文本awk &apos;&#123;print &quot;a&quot;&#125;&apos; /etc/passwd //输出相同个数的a行，一行只有一个a字母awk -F&quot;:&quot; &apos;&#123;print $1&#125;&apos; /etc/passwd awk -F: &apos;&#123;print $1; print $2&#125;&apos; /etc/passwd //将每一行的前二个字段，分行输出，进一步理解一行一行处理文本awk -F: &apos;&#123;print $1,$3,$6&#125;&apos; OFS=&quot;\t&quot; /etc/passwd //输出字段1,3,6，以制表符作为分隔符-f指定脚本文件awk -f script.awk fileBEGIN&#123;FS=&quot;:&quot;&#125;&#123;print $1&#125; //效果与awk -F&quot;:&quot; &apos;&#123;print $1&#125;&apos;相同,只是分隔符使用FS在代码自身中指定 awk &apos;BEGIN&#123;X=0&#125; /^$/&#123; X+=1 &#125; END&#123;print &quot;I find&quot;,X,&quot;blank lines.&quot;&#125;&apos; test I find 4 blank lines. ls -l|awk &apos;BEGIN&#123;sum=0&#125; !/^d/&#123;sum+=$5&#125; END&#123;print &quot;total size is&quot;,sum&#125;&apos; //计算文件大小total size is 17487 -F指定分隔符$1 指指定分隔符后，第一个字段，$3第三个字段， \t是制表符一个或多个连续的空格或制表符看做一个定界符，即多个空格看做一个空格1234567891011121314awk -F&quot;:&quot; &apos;&#123;print $1&#125;&apos; /etc/passwdawk -F&quot;:&quot; &apos;&#123;print $1 $3&#125;&apos; /etc/passwd //$1与$3相连输出，不分隔awk -F&quot;:&quot; &apos;&#123;print $1,$3&#125;&apos; /etc/passwd //多了一个逗号，$1与$3使用空格分隔awk -F&quot;:&quot; &apos;&#123;print $1 &quot; &quot; $3&#125;&apos; /etc/passwd //$1与$3之间手动添加空格分隔awk -F&quot;:&quot; &apos;&#123;print &quot;Username:&quot; $1 &quot;\t\t Uid:&quot; $3 &#125;&apos; /etc/passwd //自定义输出 awk -F: &apos;&#123;print NF&#125;&apos; /etc/passwd //显示每行有多少字段awk -F: &apos;&#123;print $NF&#125;&apos; /etc/passwd //将每行第NF个字段的值打印出来 awk -F: &apos;NF==4 &#123;print &#125;&apos; /etc/passwd //显示只有4个字段的行awk -F: &apos;NF&gt;2&#123;print $0&#125;&apos; /etc/passwd //显示每行字段数量大于2的行awk &apos;&#123;print NR,$0&#125;&apos; /etc/passwd //输出每行的行号awk -F: &apos;&#123;print NR,NF,$NF,&quot;\t&quot;,$0&#125;&apos; /etc/passwd //依次打印行号，字段数，最后字段值，制表符，每行内容awk -F: &apos;NR==5&#123;print&#125;&apos; /etc/passwd //显示第5行awk -F: &apos;NR==5 || NR==6&#123;print&#125;&apos; /etc/passwd //显示第5行和第6行route -n|awk &apos;NR!=1&#123;print&#125;&apos; //不显示第一行 //匹配代码块//纯字符匹配 !//纯字符不匹配 ~//字段值匹配 !~//字段值不匹配 ~/a1|a2/字段值匹配a1或a2123456789101112awk &apos;/mysql/&apos; /etc/passwdawk &apos;/mysql/&#123;print &#125;&apos; /etc/passwdawk &apos;/mysql/&#123;print $0&#125;&apos; /etc/passwd //三条指令结果一样awk &apos;!/mysql/&#123;print $0&#125;&apos; /etc/passwd //输出不匹配mysql的行awk &apos;/mysql|mail/&#123;print&#125;&apos; /etc/passwdawk &apos;!/mysql|mail/&#123;print&#125;&apos; /etc/passwdawk -F: &apos;/mail/,/mysql/&#123;print&#125;&apos; /etc/passwd //区间匹配awk &apos;/[2][7][7]*/&#123;print $0&#125;&apos; /etc/passwd //匹配包含27为数字开头的行，如27，277，2777...awk -F: &apos;$1~/mail/&#123;print $1&#125;&apos; /etc/passwd //$1匹配指定内容才显示awk -F: &apos;&#123;if($1~/mail/) print $1&#125;&apos; /etc/passwd //与上面相同awk -F: &apos;$1!~/mail/&#123;print $1&#125;&apos; /etc/passwd //不匹配awk -F: &apos;$1!~/mail|mysql/&#123;print $1&#125;&apos; /etc/passwd IF语句必须用在{}中，且比较内容用()扩起来123awk -F: &apos;&#123;if($1~/mail/) print $1&#125;&apos; /etc/passwd //简写awk -F: &apos;&#123;if($1~/mail/) &#123;print $1&#125;&#125;&apos; /etc/passwd //全写awk -F: &apos;&#123;if($1~/mail/) &#123;print $1&#125; else &#123;print $2&#125;&#125;&apos; /etc/passwd //if...else... 条件表达式== != &gt; &gt;=1234567awk -F&quot;:&quot; &apos;$1==&quot;mysql&quot;&#123;print $3&#125;&apos; /etc/passwd awk -F&quot;:&quot; &apos;&#123;if($1==&quot;mysql&quot;) print $3&#125;&apos; /etc/passwd //与上面相同 awk -F&quot;:&quot; &apos;$1!=&quot;mysql&quot;&#123;print $3&#125;&apos; /etc/passwd //不等于awk -F&quot;:&quot; &apos;$3&gt;1000&#123;print $3&#125;&apos; /etc/passwd //大于awk -F&quot;:&quot; &apos;$3&gt;=100&#123;print $3&#125;&apos; /etc/passwd //大于等于awk -F&quot;:&quot; &apos;$3&lt;1&#123;print $3&#125;&apos; /etc/passwd //小于awk -F&quot;:&quot; &apos;$3&lt;=1&#123;print $3&#125;&apos; /etc/passwd //小于等于 逻辑运算符&amp;&amp; ||1234awk -F: &apos;$1~/mail/ &amp;&amp; $3&gt;8 &#123;print &#125;&apos; /etc/passwd //逻辑与，$1匹配mail，并且$3&gt;8awk -F: &apos;&#123;if($1~/mail/ &amp;&amp; $3&gt;8) print &#125;&apos; /etc/passwdawk -F: &apos;$1~/mail/ || $3&gt;1000 &#123;print &#125;&apos; /etc/passwd //逻辑或awk -F: &apos;&#123;if($1~/mail/ || $3&gt;1000) print &#125;&apos; /etc/passwd 数值运算12345678awk -F: &apos;$3 &gt; 100&apos; /etc/passwd awk -F: &apos;$3 &gt; 100 || $3 &lt; 5&apos; /etc/passwd awk -F: &apos;$3+$4 &gt; 200&apos; /etc/passwdawk -F: &apos;/mysql|mail/&#123;print $3+10&#125;&apos; /etc/passwd //第三个字段加10打印 awk -F: &apos;/mysql/&#123;print $3-$4&#125;&apos; /etc/passwd //减法awk -F: &apos;/mysql/&#123;print $3*$4&#125;&apos; /etc/passwd //求乘积awk &apos;/MemFree/&#123;print $2/1024&#125;&apos; /proc/meminfo //除法awk &apos;/MemFree/&#123;print int($2/1024)&#125;&apos; /proc/meminfo //取整 输出分隔符OFS123awk &apos;$6 ~ /FIN/ || NR==1 &#123;print NR,$4,$5,$6&#125;&apos; OFS=&quot;\t&quot; netstat.txtawk &apos;$6 ~ /WAIT/ || NR==1 &#123;print NR,$4,$5,$6&#125;&apos; OFS=&quot;\t&quot; netstat.txt //输出字段6匹配WAIT的行，其中输出每行行号，字段4，5,6，并使用制表符分割字段 输出处理结果到文件①在命令代码块中直接输出 route -n|awk ‘NR!=1{print &gt; “./fs”}’②使用重定向进行输出 route -n|awk ‘NR!=1{print}’ &gt; ./fs 格式化输出1netstat -anp|awk &apos;&#123;printf &quot;%-8s %-8s %-10s\n&quot;,$1,$2,$3&#125;&apos; printf表示格式输出%格式化输出分隔符-8长度为8个字符s表示字符串类型打印每行前三个字段，指定第一个字段输出字符串类型(长度为8)，第二个字段输出字符串类型(长度为8),第三个字段输出字符串类型(长度为10) 12netstat -anp|awk &apos;$6==&quot;LISTEN&quot; || NR==1 &#123;printf &quot;%-10s %-10s %-10s \n&quot;,$1,$2,$3&#125;&apos;netstat -anp|awk &apos;$6==&quot;LISTEN&quot; || NR==1 &#123;printf &quot;%-3s %-10s %-10s %-10s \n&quot;,NR,$1,$2,$3&#125;&apos; IF语句1234567891011121314awk -F: &apos;&#123;if($3&gt;100) print &quot;large&quot;; else print &quot;small&quot;&#125;&apos; /etc/passwdsmallsmallsmalllargesmallsmallawk -F: &apos;BEGIN&#123;A=0;B=0&#125; &#123;if($3&gt;100) &#123;A++; print &quot;large&quot;&#125; else &#123;B++; print &quot;small&quot;&#125;&#125; END&#123;print A,&quot;\t&quot;,B&#125;&apos; /etc/passwd //ID大于100,A加1，否则B加1awk -F: &apos;&#123;if($3&lt;100) next; else print&#125;&apos; /etc/passwd //小于100跳过，否则显示awk -F: &apos;BEGIN&#123;i=1&#125; &#123;if(i&lt;NF) print NR,NF,i++ &#125;&apos; /etc/passwd awk -F: &apos;BEGIN&#123;i=1&#125; &#123;if(i&lt;NF) &#123;print NR,NF&#125; i++ &#125;&apos; /etc/passwd另一种形式awk -F: &apos;&#123;print ($3&gt;100 ? &quot;yes&quot;:&quot;no&quot;)&#125;&apos; /etc/passwd awk -F: &apos;&#123;print ($3&gt;100 ? $3&quot;:\tyes&quot;:$3&quot;:\tno&quot;)&#125;&apos; /etc/passwd while语句1234567awk -F: &apos;BEGIN&#123;i=1&#125; &#123;while(i&lt;NF) print NF,$i,i++&#125;&apos; /etc/passwd 7 root 17 x 27 0 37 0 47 root 57 /root 6 数组12345678910netstat -anp|awk &apos;NR!=1&#123;a[$6]++&#125; END&#123;for (i in a) print i,&quot;\t&quot;,a[i]&#125;&apos;netstat -anp|awk &apos;NR!=1&#123;a[$6]++&#125; END&#123;for (i in a) printf &quot;%-20s %-10s %-5s \n&quot;, i,&quot;\t&quot;,a[i]&#125;&apos;9523 1 9929 1 LISTEN 6 7903 1 3038/cupsd 1 7913 1 10837 1 9833 1 应用11234awk -F: &apos;&#123;print NF&#125;&apos; helloworld.sh #输出文件每行有多少字段awk -F: &apos;&#123;print $1,$2,$3,$4,$5&#125;&apos; helloworld.sh #输出前5个字段awk -F: &apos;&#123;print $1,$2,$3,$4,$5&#125;&apos; OFS=&apos;\t&apos; helloworld.sh #输出前5个字段并使用制表符分隔输出awk -F: &apos;&#123;print NR,$1,$2,$3,$4,$5&#125;&apos; OFS=&apos;\t&apos; helloworld.sh #制表符分隔输出前5个字段，并打印行号 应用212awk -F&apos;[:#]&apos; &apos;&#123;print NF&#125;&apos; helloworld.sh //指定多个分隔符: #，输出每行多少字段awk -F&apos;[:#]&apos; &apos;&#123;print $1,$2,$3,$4,$5,$6,$7&#125;&apos; OFS=&apos;\t&apos; helloworld.sh //制表符分隔输出多字段 应用312awk -F&apos;[:#/]&apos; &apos;&#123;print NF&#125;&apos; helloworld.sh //指定三个分隔符，并输出每行字段数awk -F&apos;[:#/]&apos; &apos;&#123;print $1,$2,$3,$4,$5,$6,$7,$8,$9,$10,$11,$12&#125;&apos; helloworld.sh //制表符分隔输出多字段 应用4计算/home目录下，普通文件的大小，使用KB作为单位123456ls -l|awk &apos;BEGIN&#123;sum=0&#125; !/^d/&#123;sum+=$5&#125; END&#123;print &quot;total size is:&quot;,sum/1024,&quot;KB&quot;&#125;&apos;ls -l|awk &apos;BEGIN&#123;sum=0&#125; !/^d/&#123;sum+=$5&#125; END&#123;print &quot;total size is:&quot;,int(sum/1024),&quot;KB&quot;&#125;&apos; //int是取整的意思``` 应用5统计netstat -anp 状态为LISTEN和CONNECT的连接数量分别是多少 netstat -anp|awk ‘$6~/LISTEN|CONNECTED/{sum[$6]++} END{for (i in sum) printf “%-10s %-6s %-3s \n”, i,” “,sum[i]}’123应用6统计/home目录下不同用户的普通文件的总数是多少？ ls -l|awk ‘NR!=1 &amp;&amp; !/^d/{sum[$3]++} END{for (i in sum) printf “%-6s %-5s %-3s \n”,i,” “,sum[i]}’mysql 199root 374统计/home目录下不同用户的普通文件的大小总size是多少？ls -l|awk ‘NR!=1 &amp;&amp; !/^d/{sum[$3]+=$5} END{for (i in sum) printf “%-6s %-5s %-3s %-2s \n”,i,” “,sum[i]/1024/1024,”MB”}’123应用7输出成绩表 awk ‘BEGIN{math=0;eng=0;com=0;printf “Lineno. Name No. Math English Computer Total\n”;printf “————————————————————\n”}{math+=$3; eng+=$4; com+=$5;printf “%-8s %-7s %-7s %-7s %-9s %-10s %-7s \n”,NR,$1,$2,$3,$4,$5,$3+$4+$5} END{printf “————————————————————\n”;printf “%-24s %-7s %-9s %-20s \n”,”Total:”,math,eng,com;printf “%-24s %-7s %-9s %-20s \n”,”Avg:”,math/NR,eng/NR,com/NR}’ test0 [root@localhost home]# cat test0Marry 2143 78 84 77Jack 2321 66 78 45Tom 2122 48 77 71Mike 2537 87 97 95Bob 2415 40 57 62` awk手册http://www.chinaunix.net/old_jh/7/16985.html]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用shell命令 - crontabs]]></title>
    <url>%2F2018%2F07%2F09%2FLinux-%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4-crontabs%2F</url>
    <content type="text"><![CDATA[crontabscrontab 是用来让使用者在固定时间或固定间隔执行程序之用，换句话说，也就是类似使用者的时程表。-u user 是指设定指定 user 的时程表，这个前提是你必须要有其权限(比如说是 root)才能够指定他人的时程表。如果不使用 -u user 的话，就是表示设定自己的时程表。常用参数:12345678910crontab -l //查看当前用户下的cron任务crontab -e //编辑当前用户的定时任务crontab -u linuxso -e //编辑用户linuxso的定时任务crontab file [-u user]-用指定的文件替代目前的crontab。crontab-[-u user]-用标准输入替代目前的crontab.crontab-1[user]-列出用户目前的crontab.crontab-e[user]-编辑用户目前的crontab.crontab-d[user]-删除用户目前的crontab.crontab-c dir- 指定crontab的目录。crontab文件的格式：M H D m d cmd. 基本格式 :1* * * * * command 分 时 日 月 周 命令 第1列表示分钟1～59 每分钟用或者 /1表示 第2列表示小时1～23（0表示0点） 第3列表示日期1～31 第4列表示月份1～12 第5列标识号星期0～6（0表示星期天） 第6列要运行的命令 f1 f2 f3 f4 f5 program其中 f1 是表示分钟，f2 表示小时，f3 表示一个月份中的第几日，f4 表示月份，f5 表示一个星期中的第几天。program 表示要执行的程序。 当 f1 为 时表示每分钟都要执行 program，f2 为 时表示每小时都要执行程序，其馀类推 当 f1 为 a-b 时表示从第 a 分钟到第 b 分钟这段时间内要执行，f2 为 a-b 时表示从第 a 到第 b 小时都要执行，其馀类推 当 f1 为 /n 时表示每 n 分钟个时间间隔执行一次，f2 为 /n 表示每 n 小时个时间间隔执行一次，其馀类推 当 f1 为 a, b, c,… 时表示第 a, b, c,… 分钟要执行，f2 为 a, b, c,… 时表示第 a, b, c…个小时要执行，其馀类推使用者也可以将所有的设定先存放在档案 file 中，用 crontab file 的方式来设定时程表。 环境变量的重新引入 cmd要运行的程序，程序被送入sh执行，这个shell只有USER,HOME,SHELL这三个环境变量；如果执行的shell、Perl脚本中引用其他的变量或者是相应的模块包等，则需要重新导入相应的环境变量；如下： 12345#/bin/shexport PERL5LIB=&quot;/share/nas2/genome/biosoft/perl/current/lib/::/share/nas2/genome/biosoft/perl/current/lib/:/share/nas2/genome/biosoft/perl/current/lib/5.20.0/x86_64-linux-thread-multi:/share/nas2/genome/biosoft/perl/current/lib/:/share/nas2/genome/biosoft/perl/5.20.0/lib/site_perl/5.20.0/x86_64-linux-thread-multi:/share/nas2/genome/biosoft/perl/5.20.0/lib/site_perl/5.20.0:/share/nas2/genome/biosoft/perl/5.20.0/lib/5.20.0/x86_64-linux-thread-multi&quot; ;source /root/.bashrc;source /home/liubo/.bshrc ;/share/nas2/genome/bin/perl /share/nas2/database/genome/test.pl &gt;/home/liubo/err ;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用shell命令 - mail]]></title>
    <url>%2F2018%2F07%2F08%2FLinux-%E5%B8%B8%E7%94%A8shell%E5%91%BD%E4%BB%A4-mail%2F</url>
    <content type="text"><![CDATA[12[root@localhost ~]# mail -s &quot;test mail&quot; root &lt;/root/ anaconda-ks.cfg#把/root/anaconda-ks.cfg文件的内容发送给root用户 1234567891011121314151617181920212223-f 表示发送者的邮箱-t 表示接收者的邮箱-cc 表示抄送发给谁-bcc 表示暗抄送给谁-o message-content-type=html 邮件内容的格式,html表示它是html格式-o message-charset=utf8 邮件内容编码-s 表示SMTP服务器的域名或者ip-u 表示邮件的主题-xu 表示SMTP验证的用户名-xp 表示SMTP验证的密码(注意,这个密码貌似有限制,例如我用d!5neyland就不能被正确识别)-m 邮件的内容-a 要发送的附件]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用数据库目录]]></title>
    <url>%2F2018%2F06%2F23%2FDatabase-Cosmic%2F</url>
    <content type="text"><![CDATA[1. COSMIC癌症相关的体细胞位点，是整个网站的核心，收录了来自不同研究机构和数据库的体细胞突变数据，并提供了方便的浏览，检索，下载功能。 2. Cell Lines Project对癌症研究中常用的细胞系样本进行深入研究，分析其突变信息。相比COSMIC, 整个项目中涵盖的变异数据会少一点。该项目网址如下： `https://cancer.sanger.ac.uk/cell_lines` 3. COSMIC-3D通过交互式的网页，展现了基因突变导致的蛋白结构域的变化。该项目网址如下 `https://cancer.sanger.ac.uk/cosmic3d/` 在搜索框中输入一个具体的基因名称或者蛋白名称，可以查看具体的记录。 4. Cancer Gene Census在癌症研究中，找到相关的突变基因是最核心的目的之一。通过对各种癌症进行调研，整理了一份癌症相关的突变基因列表，这份列表就是Cancer Gene Census,简称CGC。该项目网址如下 `https://cancer.sanger.ac.uk/census` 在CGC种，将所有的癌症相关基因分成两类 - Tier1 : 对于这部分基因，有充分的证据表明，正是由于这些基因的突变，导致癌症的进一步发生。 - Tier2 : 对于这部分基因，只能说在癌症中检测到了大量该基因的突变，但是并没有充分证据表明该基因突变对癌症发生的影响。]]></content>
      <categories>
        <category>知识沉淀</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C语言学习-基础知识学习]]></title>
    <url>%2F2018%2F06%2F16%2F2018-06-16.C%E8%AF%AD%E8%A8%80%E5%AD%A6%E4%B9%A0-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[工作需要，前同事很多程序是用C编写的，而自己之前只是会有Perl、Python、R，没有接触过C语言的编程，都说C是底层编程语言，虽然在编写上会麻烦，但是执行效率会甩高级语言好几条街，所以想借着这个机会，学习一下C语言的编程，虽然没时间学精学熟，但是至少以后如果有些对效率需求比较的数据处理，可以通过C语言进行简单的实现。 编译过程简介和之前学习的Perl、Python之间最大的不同主要就是C语言在编写后执行前需要对代码编译，这也是C语言的一个被诟病的地方，尤其是在进行小规模的数据处理时，代码编写调试过程中，会在编译过程中浪费大量的时间，所以一般简单的小程序，可能用Perl、Python在实现上更简单一些。 看介绍，c语言在执行前，需要先编译然后进行连接，但是我在学习测试的时候，发现gcc会默认同步完成的，当然也可以通过-c参数分开进行执行。对于我们一些小程序来讲可能没有多少影响，但是在进行大型项目的时候，可能可以有效的帮助进行错误的判断。因为我是一步编译的，所以目前还不是很确定差异。编辑的C语言程序必须是 .c 为后缀， 在测试中，发现如果缺少后缀的话，是不能直接通过gcc进行编译的。这个很奇怪，因为一直感觉在Linux系统中，文件后缀其实是个摆设，这个还需要后期又时间详细了解一下原因。 1234gcc -o helloWorld helloWrold.c #多数情况下我们可以一步到位的编译+链接程序；gcc -c helloWrold.c # 进行编译会生成helloWorld.h 文件gcc -o helloWorld helloWorld.h #链接器将源代码文件中由编译器产生的各种对象模块组合起来，再从 C语言提供的程序库中添加必要的代码模块，将它们组合成一个可执行文件。 链接成功后就会生成一个可执行程序 C语言的结构简介第一个c语言程序代码如下： 123456#include&lt;stdio.h&gt;int main() # 函数首&#123; # &#123;&#125;括号里面的内容是对应的函数体，即函数功能。 printf(&quot;Hello World&quot;); # 定义函数的内容，以分号“；”结尾 。 return 0; # 函数结束的返回值。&#125; # 其中第一行 #include&lt;stdio.h&gt; #号不代表注释，而是一个预处理的标志，include相当于Python的import，perl的use，相当于通过include会导入一个头文件，头文件中定义了一些基本函数的说明。 后面main（）中的内容则是每个程序的一个主程序，每个c程序，都有且只有一个main（）函数， C语言常用函数1. 格式输出函数 printf一般形式：printf(格式控制，输出表列)。例如：printf(&quot;%d,%d&quot;,a,b); 括号内包含两个部分： “格式控制”是用双撇号括起来的一个字符串，称“转换控制字符串”，简称“格式字符串”，它包括两个信息： 格式声明：格式声明由 % 和格式字符组成，如 %d （%d 代表输出整数，%f 代表输出实数），它的作用是将输出的数据转换为指定的格式然后输出。格式声明总是由 % 字符开始。 普通字符：普通字符即在需要输出时原样输出的字符。例如上例中的 printf(“Please enter a value：”);中的 Please enter a value: 即为原样输出。 （2）“输出表列”是程序需要输出的数据。看下面例子： 1printf(&quot;I love %d and %d&quot;,x,s); 第一个 %d 对应的是x 的值，第二个 %d 对应的是 s 的值。 I love 和 and （注意这里包括空格）都是 普通字符会原样输出。 假如 x 的值是 3，s 的值是 4，这条语句将会输出“ I love 3 and 4 ”。常用格式字符 12345678910111213％d整型输出，%md：以m指定的字段宽度输出，右对齐，％ld长整型输出，%mld：输出指定宽度的长整型数据，％o以八进制数形式输出整数，％x以十六进制数形式输出整数，或输出字符串的地址。％u以十进制数输出unsigned型数据(无符号数)。注意：%d与%u有无符号的数值范围，也就是极限的值，不然数值打印出来会有误。％c用来输出一个字符，％s用来输出一个字符串，％f用来输出实数，以小数形式输出，默认情况下保留小数点6位。%.100f用来输出实数，保留小数点100位。％e以指数形式输出实数，％g根据大小自动选f格式或e格式，且不输出无意义的零。 2. 格式输入函数 scanf()一般形式：scanf(格式控制，地址表列)。“格式控制”的含义同 printf 函数。“地址表列”是由若干地址组成的表列，可以是变量的地址。 看下面的例子： 1scanf(&quot;a=%d,b=%d&quot;,&amp;a,&amp;b); 在格式字符串中除了有格式声明的 %d 以外，其它普通字符原样输出（如“ a= ”，“ b= ”和“，”），假如给 a 和 b 分别赋值 5 和 6 ，将显示“ a=5，b=6 ”。 注意：scanf()函数中的表列是地址表列。 scanf(“a=%d,b=%d”,&amp;a,&amp;b); 中 a 和 b 前面的 &amp; 不能省掉，这一点要和 printf 作区分。** printf() 函数和 scanf() 函数我们会在以后的“数据的输入与输出”版块继续讲述。 3. 输出函数putchar（）,输出一个字符 一般形式：putchar(c); 功能：输出变量 c 所代表的一个字符； 说明：c 为字符型变量或整型变量。 4.输入一个字符 一般形式：getchar(); 功能：要求用户从终端（键盘）输入单个ss注意：运行程序时，系统等待用户输入，注意回车也是一个合法字符。字符； 说明：返回值为从输入设备上得到的字符。 5. 注释位于“ /…….. / ”中的和“ // ”后面的内容为注释，用来对程序进行说明；注释在编译时会被自动忽略。 这是一个简单的计算程序，通过定义变量让用户可以自由设定 a 和 b 的值，之后通过 c=a+b; 这条语句实现把 a 和 b 的和计算出来并赋值给 c 。究竟什么是变量，什么是常量呢？接下来我们来一一讲述。 常量1.整型常量，如：整数2.实型常量，如：实数。小数还可以用指数形式表现，如32.23e3（表示 32.2310^3）, -323.34e-6（表示 323.3410^-6）, 由于计算机无法表示上角和下角，所以规定以字母 e 或者 E 代表以 10 为底的指数。 注意：e 或者 E 之前必须有数字，且 e 或者 E 后面必须为整数，不能是 12e4.1 或者 e3 这种形式。 字符常量 普通字符 用单撇号括起来的一个字符，如 ‘a’ 、’E’ 、’%’ 、’3’ 。不能写成 ‘ab’ 、’12’ 。字符常量只能是一个字符，不包括单撇号。 转义字符 除了以上形式的字符常量外，C 语言还允许用一种特殊形式的字符常量，就是以字符 \ 开头的字符序列，比如我们本节课的 3-1.c 中，\n 代表的就是换行符，显示跳转到下一行。这是一种在屏幕上无法显示的“控制字符”。常用转义字符 字符 含义 \n 换行 \r 回车（不换行） \t 制表符 \f 换页 \b 退格 变量变量代表一个有名字的、具有特殊属性的存储单元。它可以用来保存数据。变量的值是可以改变的。变量在程序中定义的一般形式就是： &lt;类型名称&gt; &lt;变量名称&gt;。例如：int a； int b; int a,b; int price;等。C 语言规定变量名只能由字母、数字和下划线构成，且第一个字符必须为字母或下划线。 数据类型C语言包含的数据类型 数组在C语言中不存在字符串类型的概念，字符串都是存储在一个字符数组中，同时数组中的每个字符以ASCII的形式存储在存储单元中。 int student[10]; # 定义一个包含10个元素的数组，从student[0]开始到student[9] ; 在数组定义时要指定元素个数。元素个数的定义不能包含变量。char string[10] ； #定义一个字符串，可以省略数组维数（10）； 数组常用函数 函数 说明 puts（字符数组） 其作用是讲一个字符串输出到终端，因此该函数用的不是很多，我们可以编写小程序来体验。 gets（字符数组） 其作用是从终端输入一个字符串到字符数组，并且得到一个函数值。 strcat（字符数组1，字符数组2） 把两个字符数组中的字符串连接起来，把字符串2接到1后面，结果放到字符串1中。注意字符串1必须足够长，不然长度会溢出。 strlen(字符数组) 测量字符串长度的函数。函数的值为字符串中的实际长度，比占用长度小（没有计算字符串结尾的 “\0”） strcpy（字符串 1，字符串 2） 作用是将字符串 2 复制到字符串 1 中。 strcmp（字符串1，字符串2） 比较字符串1和字符串2 (从左向右逐个比较每个字符的ASCII码) strlwr 函数 转换为小写的函数 strupr 函数 转换为大写的函数 整数类型 基本类型（int）：编译系统分配给 int 类型数据 2 个字节或者 4 个字节（由具体的编译系统自行决定）。我们使用的 gcc 编译器为每个整数类型分配四个字节（32 个二进位）。在存储单元中的存储方式是：用整数的补码形式存放。所以当 4 个字节的整数类型取值范围是 -2^31~（2^31-1）。无符号的基本整型表示为 unsigned int，和 int 类型占有的字节数相同，取值范围是 0~（2^32-1）。 短类型（short 类型）：短整型的类型名为 short，gcc 编译系统分配给 short 类型 2 个字节，存储方式和 int 类型一样，也是补码的形式存储，取值范围是 -2^15~（2^15-1），无符号短整型 unsigned short 的取值范围是 0~（2^16-1）。 长整型（long 类型）：gcc 编译系统分配给 long 类型 8 个字节，存储方式和 int 类型一样，也是补码的形式存储，取值范围是 -2^63~（2^63-1），无符号长整型 unsigned long 的取值范围是 0~（2^64-1）。 同类型占用的空间：在这里大家可以通过 sizeof() 运算符查看各类型的常量占据多少字节。 浮点型数据 单精度浮点数（float）gcc编译器为每个浮点数分配4个字节（32个位），每个浮点数的存储结构分为3个部分，+or- | 小数部分 | 指数部分 但是小数部分和指数部分所分配的位数根据编译器进行确定。 双精度浮点数（double）为了扩大数据的范围，用8个字节存储一个double类型的数据，可以编程查看 double 极限值，符号的下限为：DBL_MIN,上限为 DBL_MAX。 指针指针变量的类型说明1.对指针变量的类型说明包括三个内容： 指针类型说明，即定义变量为一个指针变量； 指针变量名； 变量值(指针)所指向的变量的数据类型。 1234567int *p1;表示p1是一个指针变量，它的值是某个整型变量的地址。staic int *p2; /*p2是指向静态整型变量的指针变量*/float *p3; /*p3是指向浮点变量的指针变量*/char *p4; /*p4是指向字符变量的指针变量*/ 应该注意的是，一个指针变量只能指向同类型的变量，如P3 只能指向浮点变量，不能时而指向一个浮点变量， 时而又指向一个字符变量。 2.指针变量的赋值(1)指针变量初始化的方法 12int a;int *p=&amp;a; (2)赋值语句的方法 123int a;int *p;p=&amp;a; 不允许把一个数赋予指针变量，故下面的赋值是错误的： int p;p=1000; 被赋值的指针变量前不能再加“”说明符，如写为*p=&amp;a 也是错误的 3.指针变量的运算指针变量只能进行赋值运算和部分算术运算及关系运算。 取地址运算符&amp; 取内容运算符 用来表示指针变量所指的变量，在运算符之后跟的变量必须是指针变量。需要注意的是指针运算符和指针变量说明中的指针说明符 不是一回事。 指针变量的运算 赋值运算 指针变量的赋值运算有以下几种形式： 指针变量初始化赋值，前面已作介绍。 把一个变量的地址赋予指向相同数据类型的指针变量。 把一个指针变量的值赋予指向相同类型变量的另一个指针变量。 把数组的首地址赋予指向数组的指针变量。 把字符串的首地址赋予指向字符类型的指针变量。 把函数的入口地址赋予指向函数的指针变量。 加减算数运算 指针变量的加减运算只能对数组指针变量进行， 对指向其它类型变量的指针变量作加减运算是毫无意义的。指针变量的加减运算，相当于以指针为原点，通过相对位置寻找数组中的其他元素。 两个指针变量之间的运算只有指向同一数组的两个指针变量之间才能进行运算， 否则运算毫无意义。 数组指针变量的说明和使用 12int a[5],*pa;pa=a; pa,a,&amp;a[0]均指向同一单元，它们是数组a的首地址，也是0 号元素a[0]的首地址。pa+1,a+1,&amp;a[1]均指向1号元素a[1]。类推可知a+i,a+i,&amp;a[i]指向i号 元素a[i]。应该说明的是pa是变量，而a,&amp;a[i]都是常量。引入指针变量后，就可以用两种方法来访问数组元素了。 第一种方法为下标法，即用a[i]形式访问数组元素。 第二种方法为指针法，即采用*(pa+i)形式，用间接访问的方法来访问数组元素。 字符型数据 字符常量C中字符型的基本类型是char,这是一个字符型常量，字符型常量是指用单引号扩起来的一个字符，每个字符在所有编译系统中均占用1个字节（8个位），利用ASCII码的形式进行存储，因此每个字符型常量都可以进行数学运算，运算时就是调用的每个字符对应的ASCII码值。同样在进行输出时，系统也会根据输出格式，确定输出字符还是输出其对应的ASCII码值。 字符串常量字符串常量是用一对双引号括起来的零个或多个字符组成的序列，如 “hello”，”China”，”b” 都是字符串常量。 字符串常量的存储与字符常量的存储是不同的。字符串中的每个字符占用一个字节，在存储字符串常量时还要自动在其末尾加上 ‘\0’ 作为字符串结束的标志。 “How do you do.” 存储示意如下。因此字符常量和字符串常量’b’ 和 “b” 是完全不同的。前者是字符常量，在内存中占用的字节数为 1；而后者是字符串常量，在内存中占用的字节数为 2，包含字符 ‘b’ 和 ‘\0’。 注意：在 C 语言中没有专门的字符串变量，如果你想要将一个字符串存放在变量中，必须使用字符数组，数组中每一个元素存放一个字符，数组的内容我们会在以后的课程中和大家详细讲述。 基础运算符四则运算12345x + y：将x与y相加x - y：将x与y相减x * y：将x与y相乘x / y：x除以yx % y：求x除以y的余数 x/y 中，两个实数（亲！注意说的是实数）相除的结果是双精度实数，两个整数相除的结果为整数。如 5/3 的结果为 1，舍去小数部分。 % 运算符要求参加运算的对象为整数，结果也是整数。如 7%3，结果为 1，除了%以外的运算符的操作数都可以是任何算数类型。 自增自减作用是使变量的值加 1 或减 1 ，例如：++i ，–i（在使用 i 之前，先使 i 加（减）1 ）；i++，i–（在使用 i 之后，使 i 的值加（减）1 ）。 不同数据类型混合运算在程序中经常会遇到不同类型的数据进行运算，比如 7*3.5。如果一个运算符的两侧数据类型不同，则先进行类型的转换，使两者具有同一种类型，然后进行运算。如下表，先转换成优先级较高的数据类型然后进行运算。 类型 优先级 long double 高 double float long unsigned int int short char 低 如果 int 类型的数据和 float 或 double 型数据进行运算时，先把 int 型和 float 型数据转换为 double 型数据，然后进行运算，结果为 double 型。其他的大家可以按照上图来做。字符 (char) 型数据和整形数据进行运算，就是把字符的 ASCII 代码与整形运算。如 4+’B’，由于字符 ‘B’ 的 ASCII 代码是 66，相当于 66+4=70。字符型数据可以直接和整形数据进行运算。如果字符型数据和浮点型数据运算，则将字符的 ASCII 码先转化为 double 型，然后在进行运算。 强制转换类型在运算前，可以根据需要对数据格式进行强制转换，一般形式就是（数据类型名）（表达式）如下: 123(double)a // (将a转换成为double型)(int)(x+y) //（将x+y的值转换成为int类型)(int)x+y //（将x的值转换成为int类型，然后进行加法运算) 基础结构switchif是一个但分支的逻辑结构，当我们有多个筛选条件时，如果用if会不断使用elsif， switch（表达式） { case 常量1：语句1 case 常量2：语句2 . . . case 常量n ：语句n default ： 语句n+1 } while循环1234while(expression) statement1;statament2; do…while123do statement;while(expression); for 循环12345for（表达式 1；表达式 2；表达式 3） 语句- 表达式 1：设置初始条件，只执行一次。可以为零个、一个或者多个表达式赋初值。 表达式可以省略但分号不可省略；- 表达式 2：是循环条件表达式，用来判定是否继续循环。在每次执行循环体前限制性此表达式，决定是否继续执行循环。 可以省略，省略后默认为真。- 表达式 3：作为循环的调整，例如循环变量的增值，是在执行完循环体后才进行的。可以省略，放入执行语句中。 break退出循环，执行后续命令。 continue退出本轮循环进行下一轮循环，（跳过循环中的后续命令）。 函数函数声明指定函数的类型为 void，表示函数无类型，即无函数值，也就是说，执行这函数不会返回任何值如果函数的定义之前被引用了的话，则在引用前进行声明。函数示意 123456789101112131415161718192021#include&lt;stdio.h&gt;int main()&#123; int fun(int m ) ; #函数使用在函数定义之前，需要先引用在使用 int x=fun(100); printf(&quot;x:%d&quot;,x) ;&#125;int fun(int m)&#123; int a[100]; int n=0; for(int i=1;i&lt;m;i++)&#123; if(i%7==0)&#123; a[n]=i ; n++; &#125; &#125; for(int i=0;i&lt;n;i++)&#123; printf(&quot;num is %d\n&quot;,a[i]); &#125; return(n) ;&#125; 函数的分类]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>C++</category>
      </categories>
      <tags>
        <tag>编程语言</tag>
        <tag>C</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Book:机器学习实战-2.KNN(K-nearest-neighbor)]]></title>
    <url>%2F2018%2F06%2F12%2F2018-06-12.Book-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98-2-KNN-K-nearest-neighbor%2F</url>
    <content type="text"><![CDATA[算法概述1、指导思想kNN算法的指导思想是“近朱者赤，近墨者黑”，由你的邻居来推断出你的类别。计算步骤如下： 1）算距离：给定测试对象，计算它与训练集中的每个对象的距离 2）找邻居：圈定距离最近的k个训练对象，作为测试对象的近邻 3）做分类：根据这k个近邻归属的主要类别，来对测试对象分类 2、距离或相似度的衡量 1）在计算距离时，如果具有最大差值的属性值对距离的影响非常大时，需要对数据进行归一化（例如：newValue=oldValue/（MaxValue-MinValue））。 2）什么是合适的距离衡量？距离越近应该意味着这两个点属于一个分类的可能性越大。觉的距离衡量包括欧式距离、夹角余弦等。对于文本分类来说，使用余弦(cosine)来计算相似度就比欧式(Euclidean)距离更合适。 3、类别的判定 1）投票决定：少数服从多数，近邻中哪个类别的点最多就分为该类。 2）加权投票法：根据距离的远近，对近邻的投票进行加权，距离越近则权重越大（权重为距离平方的倒数） 优缺点1、优点简单，易于理解，易于实现，无需估计参数，无需训练适合对稀有事件进行分类（例如当流失率很低时，比如低于0.5%，构造流失预测模型）特别适合于多分类问题(multi-modal,对象具有多个类别标签)，例如根据基因特征来判断其功能分类，kNN比SVM的表现要好 2、缺点懒惰算法，对测试样本分类时的计算量大，内存开销大，评分慢可解释性较差，无法给出决策树那样的规则。 常见问题1、k值设定为多大？k太小，分类结果易受噪声点影响；k太大，近邻中又可能包含太多的其它类别的点。（对距离加权，可以降低k值设定的影响）k值通常是采用交叉检验来确定（以k=1为基准）经验规则：k一般低于训练样本数的平方根 2、类别如何判定最合适？投票法没有考虑近邻的距离的远近，距离更近的近邻也许更应该决定最终的分类，所以加权投票法更恰当一些。 3、如何选择合适的距离衡量？高维度对距离衡量的影响：众所周知当变量数越多，欧式距离的区分能力就越差。变量值域对距离的影响：值域越大的变量常常会在距离计算中占据主导作用，因此应先对变量进行标准化。 4、训练样本是否要一视同仁？在训练集中，有些样本可能是更值得依赖的。可以给不同的样本施加不同的权重，加强依赖样本的权重，降低不可信赖样本的影响。 5、性能问题？kNN是一种懒惰算法，平时不好好学习，考试（对测试样本分类）时才临阵磨枪（临时去找k个近邻）。懒惰的后果：构造模型很简单，但在对测试样本分类地的系统开销大，因为要扫描全部训练样本并计算距离。已经有一些方法提高计算的效率，例如压缩训练样本量等。 6、能否大幅减少训练样本量，同时又保持分类精度？浓缩技术(condensing)编辑技术(editing) 使用示例影片分类 电影分类简介： 电影有很多种，这里仅考虑两种，爱情片和动作片，爱情片里也会有打斗场景，动作片里也会有接吻镜头，因此不能单纯的依靠有无对影片进行分类，那这种时候，我们应该怎么去划分一个影片是爱情片还是动作片呢，这时候，我们可以利用该算法。方法： 首先一部影片中，接吻的镜头和打斗的镜头是可以进行量化的，比如我们可以数一下，有多少个打斗镜头，有多少个接吻镜头等等，因此，针对每个影片我们可以得到一个长度为2的数组c（接吻镜头数，打斗镜头数） ，同时我们需要寻找一些以知分类的影片同时我们知道这些电影的镜头信息。这些每个电影都可以在二维坐标系里面对应一个坐标点。 当我们需要对一部影片进行分类的时候，我们统计该影片的镜头信息，去计算这个影片和所有以知分类的影片间的距离，然后选取和这个影片距离最近的K个电影，然后看看这K个电影所属的分类，选取权重最高的1个电影分类（注意这里提到了是权重，而不是数目，因为有些情况下，可能需要考虑实际应用的关系，根据数据的可信程度，距离关系等对分类信息进行加权，从而提高分类的准确性），作为该电影的类别或者也可以得到该影片属于不同类别的概率。 代码1print &apos;a&apos; 手写识别 手写识别系统]]></content>
      <categories>
        <category>算法</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-Numpy]]></title>
    <url>%2F2018%2F06%2F10%2FPython-%E5%8C%85-Numpy%2F</url>
    <content type="text"><![CDATA[基本属性数组 函数 &amp; 属性 功能 示例 array=np.array([1,2,3],dtype=np.float) 构建一个数组，通过dtype可以是指数组的数据格式 np.arange 生成满足数列的数组 np.arange(start,end,sep) np.linspace 生成固定数目的数组 np.linspace(start,end,num) array.reship(m,n) 将array 重构为一个m行n列的矩阵 矩阵 函数 &amp; 属性 功能 示例 \$matrix=np.mat(\$array ) 将一个数组对象转换成矩阵 RandMat=mat(random.rand(4,4)) *.I 求矩阵 matrix.I 的逆 invRandMat=RandMat.I np.eye 创建一个单位矩阵 i=np.eye(4) np.zeros((m,n)) 构建一个值都是0的矩阵 np.ones((m,n)) 构建一个值都是1的矩阵 矩阵的基本运算 矩阵 * 矩阵的逆 = 单位矩阵 （单位矩阵是对角线元素为1 ，其他元素均为0 ）]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-python-docx撰写word]]></title>
    <url>%2F2018%2F06%2F10%2FPython-%E5%8C%85-python-PyMouse_%E6%8E%A7%E5%88%B6%E9%BC%A0%E6%A0%87%2F</url>
    <content type="text"><![CDATA[参考博客 python-sendkeys 模拟键盘事件的模块 导入需要的包 12345import win32apiimport win32conimport win32guifrom ctypes import *import time 设置鼠标双击的函数，通过坐标控制双击位点 1234567 def double_click(x=0,y=0):mouse_move(x,y)time.sleep(0.05) #延迟时间，尤其是在电脑反映不是很快的时候，win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,0,0,0,0) #点击鼠标win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0,0,0,0) #抬起鼠标win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN,0,0,0,0)win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0,0,0,0) 捕获鼠标当前位置函数 123456def get_mouse_position(): po = POINT() windll.user32.GetCursorPos(byref(po)) return int(po.x),int(po.y)class POINT(Structure): fields_=[(&quot;x&quot;,c_ulong),(&quot;y&quot;,c_ulong)] 模拟键盘输入 1win32api.keybd_event(86,0,0,0) 键码表Win32 api函数表附个键位码表： 字母和数字键 数字小键盘的键 功能键 其它键 键 键码 键 键码 键 键码 键 键码 A 65 0 96 F1 112 Backspace 8 B 66 1 97 F2 113 Tab 9 C 67 2 98 F3 114 Clear 12 D 68 3 99 F4 115 Enter 13 E 69 4 100 F5 116 Shift 16 F 70 5 101 F6 117 Control 17 G 71 6 102 F7 118 Alt 18 H 72 7 103 F8 119 Caps Lock 20 I 73 8 104 F9 120 Esc 27 J 74 9 105 F10 121 Spacebar 32 K 75 * 106 F11 122 Page Up 33 L 76 + 107 F12 123 Page Down 34 M 77 Enter 108 – – End 35 N 78 - 109 – – Home 36 O 79 . 110 – – Left Arrow 37 P 80 / 111 – – Up Arrow 38 Q 81 – – – – Right Arrow 39 R 82 – – – – Down Arrow 40 S 83 – – – – Insert 45 T 84 – – – – Delete 46 U 85 – – – – Help 47 V 86 – – – – Num Lock 144 其他未列出的字母和数字键盘为：ord(c)]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-Numpy记录]]></title>
    <url>%2F2018%2F06%2F10%2FPython-%E5%8C%85-threading_%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[threading用于提供线程相关的操作，线程是应用程序中工作的最小单元。python当前版本的多线程库没有实现优先级、线程组，线程也不能被停止、暂停、恢复、中断。 threading模块提供的类：Thread, Lock, Rlock, Condition, [Bounded]Semaphore, Event, Timer, local。 threading 模块提供的常用方法： threading.currentThread(): 返回当前的线程变量。 threading.enumerate(): 返回一个包含正在运行的线程的list。正在运行指线程启动后、结束前，不包括启动前和终止后的线程。 threading.activeCount(): 返回正在运行的线程数量，与len(threading.enumerate())有相同的结果。 threading 模块提供的常量：threading.TIMEOUT_MAX 设置threading全局超时时间。 代码实例：1234567891011121314151617181920212223242526272829# coding:utf-8import threadingimport timeISOTIMEFORMAT=&apos;%Y-%m-%d %X&apos;def action(arg): print &apos;sub thread start!the thread name is:%s\r&apos; % threading.currentThread().getName() , print time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) ) time.sleep(5) print &apos;the arg is:%s\r&apos; %arg , print time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) )for i in xrange(1000): t =threading.Thread(target=action,args=(i,)) t.setDaemon(True)# print time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) ) t.start() while True: #判断正在运行的线程数量,如果小于5则退出while循环, #进入for循环启动新的进程.否则就一直在while循环进入死循环 if(len(threading.enumerate()) &lt; 20): break t.join()print &apos;main_thread end! :&apos;,print time.strftime( ISOTIMEFORMAT, time.localtime( time.time() ) ) 线程 多线程模块参考资料]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-python-docx撰写word]]></title>
    <url>%2F2018%2F06%2F10%2FPython-%E5%8C%85-python-docx%E6%92%B0%E5%86%99word%2F</url>
    <content type="text"><![CDATA[用途处于某些上下游对接需求，所以需要频繁的将生信的分析结果整理成word文件，以便以进行信息的传递。所以基于该模块可以更方便的在集群上自动化生成相关的文档示例，用于进行后续的处理。 环境安装使用Python进行doc文档编写的过程中，需要安装下列软件 &amp; 包 docx #对应安装命令 pip install python-docx 简介参考信息https://zhuanlan.zhihu.com/p/82880510 https://blog.csdn.net/weixin_44601149/article/details/106660853?utm_medium=distribute.pc_relevant.none-task-blog-title-1&amp;spm=1001.2101.3001.4242 示例首先构建一个Word模板，在模板中使用双大括号来标记后期word编辑的过程中，需要进行替换的变量 {{var}} 。]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Office处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-Numpy记录]]></title>
    <url>%2F2018%2F06%2F10%2FPython-%E5%8C%85-pysam%2F</url>
    <content type="text"><![CDATA[文件读写文件读写句柄bam_file : bam文件路径 读取文件1ReadBam = pysam.AlignmentFile(bam_file) # 读取文件句柄 写入文件1234567WriteBam = pysam.AlignmentFile(bam_file , &quot;wb&quot;, header=pysamFile.header)for read in samfile.fetch(): if read.is_paired: WriteBam.write(read)pairedreads.close()samfile.close() Bam操作提取特定区域的Reads12345# 获取染色体chr1 上 100~120bp的readsfor read in samfile.fetch(&apos;chr1&apos;, 100, 120): print(read)samfile.close() 文件函数1234567891011121314151617181920#region : 提取的区域# mapq : 比对质量# baseq ：碱基质量# ref :参考基因组for pileup_column in bam_file.pileup(region=&quot;chr1:1-10&quot;,mapq=mapq , baseq = baseq, stepper=stepper, fastaFile=ref, max_depth=200000, **&#123;&quot;truncate&quot;: True&#125;):# for pileup_read in pileup_column.pileups: aln = pileup_read.alignment read_name = aln.query_name pair = &apos;pe1&apos; if aln.is_read1 else &apos;pe2&apos; strand = &apos;-&apos; if aln.is_reverse else &apos;+&apos; read = Read(read_name, pair, strand) if pileup_read.is_del or pileup_read.is_refskip or (aln.flag &gt; 1024) or (aln.mapping_quality &lt; mapq) or \ aln.query_qualities[pileup_read.query_position] &lt; baseq: continue start_reads[read] = [pileup_read.query_position, aln]]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-pandas]]></title>
    <url>%2F2018%2F06%2F10%2FPython-%E5%8C%85-Pandas%2F</url>
    <content type="text"><![CDATA[官方资料api参考文档官方文档-en官方文档-cn 常用功能及代码块示例得到一个DataFrame创建一个空的dataframe1234#指定dataframe的所有字段columns=[&quot;sampleName&quot;,&quot;#Gene&quot;,&quot;Transcript,&quot;cHGVS&quot;,&quot;pHGVS&quot;,&quot;Frequence&quot;]#创建一个含字段结构的空数据框DF = pd.DataFrame(columns=columns) 从文件中读取一个dataframe 读取Excel 123DF = pd.read_excel(file, sheet_name=None)DF = pd.read_csv(file,sep=&quot;\t&quot; )# sheet_name 指定 None时，读取所有sheet返回一个字典，key为sheet名； 不指定默认读取第一个sheet） 读取tsv文件 1pd.read_csv(filename, sep=&quot;\t&quot;) 读取压缩文件 123df = pd.read_csv(&apos;filename.zip&apos;)# 指定压缩格式 df = pd.read_csv(&apos;filename.zip&apos;, compression=&apos;zip&apos;, header=0, sep=&apos;,&apos;, quotechar=&apos;&quot;&apos;) 压缩：{‘infer’，’gzip’，’bz2’，’zip’，’xz’，无}，默认为’infer’用于对磁盘数据进行实时解压缩。如果’infer’和filepath_or_buffer与路径类似，则从以下扩展名检测压缩：’.gz’，’。bz2’，’。zip’或’.xz’（否则不进行解压缩）。如果使用“ zip”，则ZIP文件必须仅包含一个要读取的数据文件。设置为“无”将不进行解压缩。 获取DataFrame的信息查看头尾数据123456# 查看开头的N（默认值5） 行df.head()# 查看开头的10行df.head(10) # 查看结尾的N（默认值5） 行df.tail() 随机查看数据12# 随机查看N（默认1 ）行数据df.sample(N) DataFrame的数据筛选单个条件筛选12345678910$ print(df)name age sexTim 10 男Sam 20 女Tom 30 NaN$ df[df[&quot;age&quot;]&gt;15]name age sexSam 20 女Tom 30 NaN 多个条件筛选存在多个比较条件的时候，需要注意 多个条件同时满足不能用and，使用 &amp; 多个条件满足其中一个即可，不能使用or，使用 | 每个条件要使用 小括号 123456789$ print(df)name age sexTim 10 男Sam 20 女Tom 30 NaN$ df[(df[&quot;age&quot;]&gt;15) &amp; (df[&quot;age&quot;]&lt;25&gt;)]name age sexSam 20 女 筛选常用的数值函数123456df.eq() # 等于相等 ==df.ne() # 不等于 !=df.le() # 小于等于 &gt;=df.lt() # 小于 &lt;df.ge() # 大于等于 &gt;=df.gt() # 大于 &gt; 使用单个数值函数筛选123$ df[(df[&quot;age&quot;] eq 20)]name age sexSam 20 女 筛选常用的字符型函数123包含：str.contains开始：str.startswith结束：str.endswith 示例如下：12345678$ df[(df[&quot;name&quot;].str.contains(&quot;o&quot;))]name age sexTom 30 NaN# 如果字符串所在列存在空值，则可以通过添加参数进行剔除，否则报错$ df[(df[&quot;sex&quot;].str.contains(&quot;男&quot;,na=False))]name age sexTim 10 男 基于索引筛选情况比较少，但是特殊情况也会用到12$ df[df.index == 1]Sam 20 女 筛选存在缺失值的行123$ df[df.isnull().values==True]name age sexTom 30 NaN 逐行读取dataframe的每行DataFrame.iterrows()12for index, row in df.iterrows(): print row[&quot;c1&quot;], row[&quot;c2&quot;] DataFrame.itertuples()12for row in df.itertuples(index=True, name=&apos;Pandas&apos;): print getattr(row, &quot;c1&quot;), getattr(row, &quot;c2&quot;) itertuples()应该比iterrows()快 DataFrame.apply()1234def valuation_formula(x, y): return x * y * 0.5 df[&apos;price&apos;] = df.apply(lambda row: valuation_formula(row[&apos;x&apos;], row[&apos;y&apos;]), axis=1) iloc12for i in range(0, len(df)): print df.iloc[i][&apos;c1&apos;], df.iloc[i][&apos;c2&apos;] 将DataFrame转为List 略麻烦，但是更高效，1234567891011121314from collections import namedtuple def myiter(d, cols=None): if cols is None: v = d.values.tolist() cols = d.columns.values.tolist() else: j = [d.columns.get_loc(c) for c in cols] v = d.values[:, j].tolist() n = namedtuple(&apos;MyTuple&apos;, cols) for line in iter(v): yield n(*line) DataFrame 数据的筛选dataframe 内容的更改替换dataframe中的nandata.fillna(value=values,inplace=True) 整列改为相同的值1DF[&apos;sampleName&apos;] = &quot;S1&quot; # 将数据框DF的sampleName列都改为 &quot;S1&quot; 根据特定条件修改某一列的值1234# 调用apply()方法，可以作用于 Series 或者整个 DataFrame，它自动遍历整个 Series 或者 DataFrame, 对每一个元素运行指定的函数。df[&apos;label&apos;]=df.id.apply(lambda x: 1 if &apos;M&apos; in x else 0)# 如果id列值包含‘L’,那么就将label列中对应的值从1替换成0：df.loc[df[&apos;id&apos;].str.contains(&apos;L&apos;),&apos;label&apos;]=0 基于现有列进行拼接12345678910111213data#GENE1 GENE2 Gene1_Chr Gene1_BreakPos Gene2_Chr Gene2_BreakPos Cancer_SoftClip_Sup Normal_SoftClip_Sup Gene1_Orientation Gene2_Orientation Gene1_BP_Depth Gene2_BP_Depth frequency signalRPN2 SRC chr20 35868878 chr20 36012640 11 0 R L 9 3024 0.3627 PELINC00486 PLXNA1 chr2 33141303 chr3 126733308 5 0 R R 130 2486 0.1911 PELINC00486 TRRAP chr2 33141470 chr7 98507956 8 0 R R 953 1658 0.3064 PELINC00486 MAPK3 chr2 33141307 chr16 30134444 6 0 R R 188 1376 0.3836 PEdata[&quot;a&quot;] = data[&apos;Gene1_Chr&apos;].str.cat(data.Gene1_BreakPos.astype(&apos;str&apos;),sep=&quot;:&quot;)#GENE1 GENE2 Gene1_Chr Gene1_BreakPos Gene2_Chr Gene2_BreakPos Cancer_SoftClip_Sup Normal_SoftClip_Sup Gene1_Orientation Gene2_Orientation Gene1_BP_Depth Gene2_BP_Depth frequency signal aRPN2 SRC chr20 35868878 chr20 36012640 11 0 R L 9 3024 0.3627 PE chr20:35868878LINC00486 PLXNA1 chr2 33141303 chr3 126733308 5 0 R R 130 2486 0.1911 PE chr2:33141303LINC00486 TRRAP chr2 33141470 chr7 98507956 8 0 R R 953 1658 0.3064 PE chr2:33141470LINC00486 MAPK3 chr2 33141307 chr16 30134444 6 0 R R 188 1376 0.3836 PE chr2:33141307 更新DataFrame某一列（值位于另一个DataFrame）12345678import pandas as pddf1=pd.DataFrame(&#123;&apos;id&apos;:[1,2,3],&apos;name&apos;:[&apos;Andy1&apos;,&apos;Jacky1&apos;,&apos;Bruce1&apos;]&#125;)df2=pd.DataFrame(&#123;&apos;id&apos;:[1,2],&apos;name&apos;:[&apos;Andy2&apos;,&apos;Jacky2&apos;]&#125;)s = df2.set_index(&apos;id&apos;)[&apos;name&apos;]df1[&apos;name&apos;] = df1[&apos;id&apos;].map(s).fillna(df1[&apos;name&apos;]).astype(str)print(df1) 两个dataframe的合并 merge （着重关注的是行的合并）12345678910111213141516171819202122232425262728293031323334&gt;&gt;&gt; print(df1) Courses Fee Durationr1 Spark 20000 30daysr2 PySpark 25000 40daysr3 Python 22000 35daysr4 pandas 30000 50days&gt;&gt;&gt; print(df2) Courses Discountr1 Spark 2000r6 Java 2300r3 Python 1200r5 Go 2000# pandas.merge()df3=pd.merge(df1,df2, how=&apos;left&apos;)print(df3)# DataFrame.merge()df3=df1.merge(df2, how=&apos;left&apos;)print(df3) Courses Fee Duration Discount0 Spark 20000 30days 2000.01 PySpark 25000 40days NaN2 Python 22000 35days 1200.03 pandas 30000 50days NaN# 按特定的列进行两个dataframe的合并# Merge DataFrames by Columnsdf3=pd.merge(df1,df2, on=&apos;Courses&apos;, how=&apos;left&apos;)# When column names are differentdf3=pd.merge(df1,df2, left_on=&apos;Courses&apos;, right_on=&apos;Courses&apos;, how=&apos;left&apos;)print(df3) Data manipulations 数据处理 方法 简介 示例 concat Concatenate pandas objects along a particular axis with optional set logic along the other axes. df_result = pd.concat([dataframe1 , dataframe2]) 数据的筛选dataframe数据内容替换1data.replace(&quot;\r\n&quot;,&quot;&lt;br&gt;&quot;,regex=True,inplace=True) # 将数据中的换行符统一替换成 &lt;br&gt; .regex：是否使用正则，若不适用，则只能进行整体的替换。 dataframe中逐行添加数据1AllSampleFastqQC.loc[len(AllSampleFastqQC)+1] = [SampleDir,SampleDirPath,Chip,lane,barcode,umi,Q20,Q30,GC] 两个dataframe的合并12# df_result = pd.concat([dataframe1 , dataframe2])]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-Numpy记录]]></title>
    <url>%2F2018%2F06%2F10%2FPython-%E5%8C%85-vcf%2F</url>
    <content type="text"><![CDATA[官方文档 模块的安装1pip install pyvcf VCF文件的读写1234567891011import vcf#读取vcf文件 vcf_reader = vcf.Reader(open(&apos;vcf/test/example-4.0.vcf&apos;, &apos;r&apos;))for var in vcf_reader: print (var)# 写入vcf文件vcf_writer = vcf.Writer(open(&apos;/dev/null&apos;, &apos;w&apos;), vcf_reader)for var in vcf_reader: vcf_writer.write_record(var) vcf文件迭代子类的属性12345678910Record.CHROM Record.POSRecord.IDRecord.REFRecord.ALTRecord.QUALRecord.FILTERRecord.INFO # 返回一个字典，可以用Record.INFO[&apos;type&apos;],Record.INFO[&apos;DP&apos;] 键值继续提取Record.FORMAT #返回format列 字符串 如果你的vcf文件中没有FORMAT 返回 &quot;GT:DP:RO:QR:AO:QA:GL&quot;print i.samples # 返回的是三个样 call object 组成的列表。]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-Scipy_科学计算库]]></title>
    <url>%2F2018%2F06%2F10%2FPython-%E5%8C%85-Scipy_%E7%A7%91%E5%AD%A6%E8%AE%A1%E7%AE%97%E5%BA%93%2F</url>
    <content type="text"><![CDATA[Scipy库的简介 Scipy高级科学计算库：和Numpy联系很密切，Scipy一般都是操控Numpy数组来进行科学计算、统计分析，所以可以说是基于Numpy之上了。Scipy有很多子模块可以应对不同的应用，例如插值运算，优化算法等等。SciPy则是在NumPy的基础上构建的更为强大，应用领域也更为广泛的科学计算包。正是出于这个原因，SciPy需要依赖NumPy的支持进行安装和运行。 Scipy是世界上著名的Python开源科学计算库，建立在Numpy之上。它增加的功能包括数值积分、最优化、统计和一些专用函数。 SciPy函数库在NumPy库的基础上增加了众多的数学、科学以及工程计算中常用的库函数。例如线性代数、常微分方程数值求解、信号处理、图像处理、稀疏矩阵等等。Scipy是基于Numpy构建的一个集成了多种数学算法和方便的函数的Python模块。通过给用户提供一些高层的命令和类，SciPy在python交互式会话中，大大增加了操作和可视化数据的能力。通过SciPy，Python的交互式会话变成了一个数据处理和一个system-prototyping环境，足以和MATLAB，IDL，Octave，R-Lab，以及SciLab抗衡。 更重要的是，在Python中使用SciPy，还可以同时用一门强大的语言————Python来开发复杂和专业的程序。用SciPy写科学应用，还能获得世界各地的开发者开发的模块的帮助。从并行程序到web到数据库子例程到各种类，都已经有可用的给Python程序员了。这些强大的功能，SciPy都有，特别是它的数学库。Scipy是在Python的NumPy扩展上构建的数学算法和方便函数的集合。它通过为用户提供高级命令和类来操作和可视化数据，为交互式Python会话添加了强大的功能。有了SciPy，交互式Python会话就变成了一个数据处理和系统原型环境，可以与MATLAB、IDL、Octave、R-Lab和SciLab等系统相匹敌。以Python为基础的SciPy的另一个好处是，它还提供了一种强大的编程语言，可用于开发复杂的程序和专门的应用程序。使用SciPy的科学应用程序受益于世界各地的开发人员在软件领域的许多小众领域中开发的附加模块。从并行编程到web和数据库的子例程和类，Python程序员都可以使用。除了SciPy中的数学库之外，所有这些功能都是可用的 scipy.orgscipy.pypiSciPy User GuideRead the doc for SciPy 常用功能常见的子包 Subpackage Description cluster Clustering algorithms 聚类算法在信息理论、目标检测、通信、压缩等领域有着广泛的应用。vq模块只支持矢量量化和k-均值算法。 constants Physical and mathematical constants fftpack Fast Fourier Transform routines integrate Integration and ordinary differential equation solvers interpolate Interpolation and smoothing splines 此子包包含样条函数和类、一维和多维（单变量和多变量）插值类、Lagrange和Taylor多项式插值器以及FITPACK和DFITPACK函数的包装器。 io Input and Output linalg Linear algebra ndimage N-dimensional image processing odr Orthogonal distance regression optimize Optimization and root-finding routines signal Signal processing sparse Sparse matrices and associated routines spatial Spatial data structures and algorithms special Special functions stats Statistical distributions and functions 该模块包含大量的概率分布以及不断增长的统计函数库。每个单变量分布都是rv_连续（rv_离散用于离散分布）的一个子类的实例。 常用检验Fisher检验12from scipy.stats import fisher_exactoddsratio, pvalue = fisher_exact([[8, 2], [1, 5]])]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python包-OpenCV_图像处理]]></title>
    <url>%2F2018%2F06%2F10%2FPython-%E5%8C%85-OpenCV_%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[参考网址 http://wiki.opencv.org.cn/index.php/%E9%A6%96%E9%A1%B5 http://www.opencv.org.cn/opencvdoc/2.3.2/html/index.html http://opencv.org/ 官网下载经常会有断，python 2.7 可以在github上的备份中获取;下载文件后，解压，并将文件放入python的库中即可；同时使用open CV需要另一个python的库文件。Numpy； 该model可以直接通过python安装命令进行安装；1python -m pip install numpy 文件的读取12cv2.namedWindow(&apos;image&apos;, cv2.WINDOW_NORMAL) #cv2.WINDOW_AUTOSIZE 窗口不可调节;cv2.namedWindow(&apos;image&apos;, cv2.WINDOW_NORMAL) #cv2.WINDOW_NORMAL 窗口大小可以调节； import numpy as np import cv2 # Load an color image in grayscale img = cv2.imread(&apos;1.png&apos;,0) cv2.imshow(&apos;image&apos;,img) #展示图片 cv2.waitKey(0) #等待键盘输入 cv2.destroyAllWindows() #关闭窗口 print img]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[变异检出标准化-HGVS]]></title>
    <url>%2F2018%2F06%2F05%2F2018-06-05.%E5%8F%98%E5%BC%82%E6%A3%80%E5%87%BA%E7%BB%93%E6%9E%9C%E6%A0%87%E5%87%86%E5%8C%96-HGVS%2F</url>
    <content type="text"><![CDATA[为什么要标准化？简单讲，就是为了让一个特定的突变具有一个唯一的表述方式，一个突变如果不进行标准化，会出现多种不同的表达方式，即MNP（Multi Nucleotide Polymorphism ），这会给大家的交流带来诸多的问题， 试想每个人有自己的习惯，最终一个突变可能会有成百上千种表达方式，这无疑会给研究人员交流带来诸多的困扰。因此标准化是很有必要的，目前主流的标准化原则是涉及尽可能少的碱基，尽可能做对齐。 首先我们来看一下，目前的变异检测多是依靠序列比对，然后会针对不同的比对情况进行变异检出的，我们先来看一下SNV， 如果不标准化，一个相同的变异 CAT =&gt; TGC 的突变，会出现下列所示的多种不同的表述方法。 随着基因检测技术的广泛应用，越来越多与疾病相关的基因和变异被明确。为了让变异注释更程序化、对变异文献的检索更全面化以及对变异的描述更标准化故需要形成统一突变命名规则，HGVS命名规则是目前公认的命名规则（人类基因组变异学会(HGVS)、人类变异项目(HVP)和人类基因组组织(HUGO)授权）。HGVS命名规则从不同层面对变异进行描述，反应变异的位置及对编码的蛋白的影响。参考序列的选择、转录版本号的不同及描述层面（DNA水平、RNA水平及蛋白水平）的不同，均会导致同一变异描述的形式不同。 HGVS规范参考序列只接受NCBI或EBI公共数据库中的参考序列ID，且必须同时包含accession和version信息；如NC_000023.10中，NC_000023代表accession号，10代表version号。参考序列中下划线前的大写字母代表参考序列格式，目前批准的参考序列格式有：|格式|解释|举例||-|-|-||NC_＃|代表完整的基因组序列，标记的类别包括基因组、染色体、细胞器、质粒。|NC_000023.10:g.32407761G&gt;A||LRG_#|Locus Reference Genomic，基因座参考基因组序列。（不能在其他基因组找到的）|NG_012232.1:g.954966C&gt;T||NG_＃|不完整的基因组区域（不转录的假基因或者那些很难自行化注释的基因组区域）|LRG_199:g.954966C&gt;T||NM_＃|编码蛋白的转录本序列。基因检测报告中最常用此作为参考序列。|NM004006.2:c.4375C&gt;T||NR_＃|非编码的转录本序列，包括结构RNAs，假基因转子等。|NR002196.1:n.601G&gt;T||NP_＃|蛋白质序列|NP-003997.1:p.Arg1459*(p.Arg1459Tero| g.代表线性基因组参考序列； o.代表环状基因组参考序列； m.代表线粒体参考序列； c.代表编码DNA参考序列； n.代表非编码DNA参考序列； r.代表RNA参考序列； p.代表蛋白（氨基酸）参考序列。 变异位置 编码区（CDS） 以起始密码子ATG的第一个碱基A开始，并记为c.1，以终止密码子（TAA, TAG, TGA）的最后一个碱基为终点。 内含子区（Intron） 靠近内含子5’末端的变异位点，需依据上游最近外显子的最后一个碱基来定位，如c.87+4，代表上游最近外显子的边界位置为87，变异位点在内含子5’ 端开始的第4个碱基； 靠近内含子3’ 末端的变异位点，要依据下游最近外显子的第一个碱基来定位，如c.88-11， 内含子碱基个数为偶数时，中间碱基平分后按上下游外显子碱基来定位命名，如…,c.87+676, c.87+677, c.87+678, c.88-678, c.88-677, c.88-676, … 内含子碱基个数为奇数时，中间碱基相对于上游外显子最后一个碱基来定位命名，如…,c.87+677, c.87+678, c.87+679, c.88-678, c.88-677, … 非编码区（UTR区）： 起始密码子ATG上游（5’ UTR区）标记为“-”，编号为c.-1, c.-2, c.-3… 终止密码子下游（3’ UTR区）标记为“”，编号为c.1, c.2, c.3… 位于靠近5’ UTR和3’ UTR区的内含子变异位点，命名规则同内含子区，如：5’ UTR区内含子为c.-85+1，c.-84-3等；3’ UTR区内含子为c.37+1，c.38-3等。 变异类型 置换（&gt;）：一个核苷酸被另一个核苷酸替代，使用“&gt;”来表示；例如g.1318G&gt;T； 缺失（del）:一个或多个核苷酸被移除，使用“del”进行描述；例如g.3661_3706del； 倒置（inv）: 与原始序列反向互补的新的核苷酸序列（大于1个核苷酸）替换原始序列，例如由CTCGA变为TCGAG，使用”inv“表示； 重复（dup）：一个或多个核苷酸拷贝直接插入原始序列的下游，使用“dup”表示； 插入（ins）：序列中插入一个或多个核苷酸，并且插入序列并非上游序列拷贝； 缺失-插入（delins/indel）:一个或多个核苷酸被其他核苷酸替代，但并不是发生替代、倒置和转置； 转换（con）：一种特殊类型的缺失-插入，其中替代原始序列的核苷酸序列是来自基因组中另一个位点的序列拷贝； 5、变异描述示例DNA水平 c.76A&gt;C：76位的核苷酸A变异为C； c.82_83delTG：位于82和83位点上的核苷酸TG缺失，ACTTTGTGCC变异为ACTTTGCC（A是第76位）； c.83_84dupTG： ACTTTGTGCC（A为第76位）的83-84位之间插入短的串联重复序列TG，变为ACTTTGTGTGCC； g.333_590con1844_2011：基因组中编号为333-590的核苷酸序列替代1844-2011原有序列，插入其中； g.112_117delinsTG：在基因组序列编号为112-117之间的6个核苷酸被TG替换；多个变异使用”[]”标注变异，并用“；”链接 同一等位基因发生多个变异： c.[76A &gt;C;83G&gt;C]：同一染色体上76位和83位发生两个变异（顺式）； 不同等位基因发生多个变异： c.[76A &gt;C];[83G&gt;C]：两个变异发生在不同染色体上（反式）； 不确定多个变异发生的位置： c.[76A &gt;C](;)[83G&gt;C]：两个变异可能发生在同一染色体，也可能发生在不同染色体上，用(;)来链接； 定义重复序列的核苷酸范围及重复单位的数量，并用“[]”表示 g.123_124[4]:基因组序列中第123-124间的核苷酸重复出现4次； 对于短的/简单的重复，可以展示重复序列 g．123TG[4]:基因组序列中从123位开始TG核苷酸重复出现4次； 当重复序列长度不确定时，使用括号进行指定 g.-128GGC[(600-800)]:基因组编码区上游128位核苷酸处重复插入GGC，重复次数在600-800之间；蛋白质水平 替换：如p.Trp26Cys，表示第26位的Trp被Cys取代（错义突变）；p.Trp26Ter (p.Trp26*)，表示第26位的Trp变为终止密码（无义突变）；p.Cys123=，表示基因突变之后，氨基酸没有发生改变（同义突变）； 缺失：如p.Ala3_Ser5del，表示多肽序列中从第3位的Ala到第5位的Ser发生了缺失； 插入：如p.Lys2_Gly3insGlnSerLys，表示在第2位的Lys和第3位的Gly之间插入了GlnSerLys； 插入缺失：如p.Cys28delinsTrpVal，表示第28位的Cys缺失，同时被TrpVal取代； 重复：如p.Ala2[10]，表示第2位的Ala重复了10次； 移码突变：在起始密码子和终止密码子之间的读码框发生了改变；以“fx”进行表示；如p.Arg97ProfsTer23，表示第97位的Arg是首个发生改变的氨基酸，且Arg变为Pro，同时发生移码突变后，终止密码的位置变为第23位； 变异类型的描述原则一般原则： 所有变异需先从最基本的层面（DNA水平）进行描述，还可从RNA水平和蛋白质水平上进行描述。 用变异的描述是否加“（）” 来说明变异是由实验确定的还是从理论上推导出来的。 所有的变异都应该根据公认的参考序列来描述。 当变异可描述为几种变异类型时，优先级为：(1)替换，(2)删除，(3)倒位，(4)重复，(5)转换，(6)插入。如：当一个变异可以被描述为重复或插入时，根据优先级决定应描述为重复，而不是插入。如：“-ATGCCCA-”插入后变为“-ATGCCCCA-”，应描述为c.7dup，而不是NM_004006.2:c.7_8insC。 在进行变异描述时，基因的描述要采用HGNC的官方基因名。 重复序列变异描述原则：c.123CAG[16]，g.3258796GA[8]对于编码区DNA序列而言，重复序列的描述仅用于重复单元长度为3的倍数的重复序列，即不会影响阅读框的重复单元长度；若重复序列长度不是3的倍数，则不能用该形式描述。如：当CNPTAB基因在编码区的TATA序列后插入TATATATA序列，则对于该插入变异的描述应为NM_024312.4:c.1741_1742insTATATATA，而不是NM_024312.4:c.1738TA[6]。 3’ 端法则：变异的描述需遵循最靠近3’ 端法则。如“-ATGCCCCA-”变异成“-ATGC_CCA-”，根据3’ 端法则应描述为c.7delC，而不是c.5delC。例外：当缺失/重复发生在外显子与外显子衔接处，且衔接处碱基相同，不遵循3’ 端法则。如“..GAT gta..//..cag TCA..”缺失后变为“..GA_ gta..//..cag TCA..”，应描述为NM_004006.2:c.3921del，而不是NM_004006.2:c.3922del；“..GAT gta..//..cag TCA..”重复后变为“..GATT gta..//..cag TCA..”，应描述为NM_004006.2:c.3921dup，而不是NM_004006.2:c.3922dup。 有大量的原始检测软件，在未进行变异注释前是进行的左对齐 delins原则：涉及两个或以上连续核苷酸的替换，描述为delins。若两个变异被一个或多个核苷酸分隔，优先单独描述两个变异，而不采用delins合并描述；若被一个核苷酸分隔的两个变异，共同影响一个氨基酸，则合并描述为delins，如c.142_144delinsTGG (p.Arg48Trp)； 若两个变异中的任何一个为已知的高频变异位点，则需要单独描述两个变异，即NM_004006.1:c.[145C&gt;T;147C&gt;G]，优先于NM_004006.1:c.145_147delinsTGG。(该原则需与解读同事讨论) 起始密码子变异描述：描述取决于变异对蛋白产物改变的结果。 变异后不产生蛋白质：NM_003002.3:p.0 变异对蛋白产物的影响不清楚且无法预测：NM_003002.3:p.? 变异后产生新的起始氨基酸： a）上游：p.Met1ext-5，即原始密码子上游第5位（5’ UTR区）产生了新的起始氨基酸，另可描述为p.Met1extMet-5。 b）下游：p.Leu2_Met124del，即原起始氨基酸丢失且下游产生新的起始氨基酸，导致蛋白的第1到123位氨基酸缺失。终止密码子变异描述：采用“ext”描述 p.Ter110Glnext17(p.110Glnext17)：原终止氨基酸变为谷氨酰胺（Gln），并在下游第17位产生新的终止氨基酸，导致蛋白产物延长17个氨基酸。注：不可描述为p.Ter110GlnextTer17 ，此处的17代表的是位置（3’ UTR区） p.Ter315TyrextAsnLysGlyThrTer(p.315TyrextAsnLysGlyThr) ：原终止氨基酸变为酪氨酸（Tyr），并在下游第5位产生新的终止氨基酸，导致蛋白产物延长5个氨基酸。 p.Ter327Argext?(p.327Argext*?)：原终止氨基酸变为精氨酸（Arg），导致蛋白产物延长，延长的长度未知。 附录1、特殊字符的含义 “+”：c.123+45A&gt;G（代表靠近内含子5’ 端的核苷酸发生变异） “-”：c.124-56C&gt;T（代表靠近内含子3’ 端核苷酸发生变异）；c.-142C&gt;G（代表5’ UTR区） “”：c.32G&gt;A（代表3’ UTR区）；P.Trp41*（代表终止氨基酸） “[]”：代表等位基因，“;”用来分隔变异和等位基因，如g.[123456A&gt;G;345678G&gt;C] 代表顺式，g.[123456A&gt;G];[345678G&gt;C]代表反式， g.123456A&gt;G(;)345678G&gt;C代表这两个变异的顺式反式未知。 “()”：用来表示不确定的或预测的结果，如p.(Ser123Arg) “?”：用来表示核苷酸或氨基酸的位置未知，如g. (?_234567) _ (345678_?)del “^”：代表“或”的意思，如p.Ser124Arg反推核苷酸的改变为c.(370A&gt;C^372C&gt;G^372C&gt;A) ，即AGC变成CGC, AGG或AGA “/”：表示嵌合体（mosaic），如NM_004006.1:c.145=/C&gt;T “//”：表示异源嵌合体（chimeric），如NM_004006.1:c.85=//T&gt;C “|”：代表不是序列的直接改变，而是一种修饰或一种状态的改变，如甲基化。 “::”：用于描述RNA融合转录本和断点连接形成的环状染色体 缩写字符的含义 “fs”代表变异类型为移码变异，主要是针对蛋白水平而言，如p.Arg456GlyfsTer17或p.Arg456Glyfs*17 “ext”代表变异类型为延长，主要是针对起始密码子和终止密码子变异导致的蛋白水平的改变，如p.Met1ext-5 “gom” 表示获得甲基化，如g.12345678_12345901|gom “lom”表示去甲基化，如g.12345678_12345901|lom “met” 表示甲基化，如g.12345678_12345901|met= 软件脚本3’对齐针对变异进行3’对其的工具，可以参考GitHub仓库的脚本 toolkits\03.Deal_mutation\Realn4vcf.py 左对齐目前仍有大量软件本身是进行左对齐的，因此在进行结果比较时可以统一进行左对齐，从而实现变异结果的规范化，进行比较。对齐的命令行1234567891011Commands used are: bcftools norm -f ref.fa in.vcf -O z &gt; out.vcf.gz java -jar GenomeAnalysisTK.jar -T LeftAlignAndTrimVariants --trimAlleles -R ref.fa --variant in.vcf.gz -o out.vcf.gz vt normalize -r ref.vcf.gz -o out.vcf.gzVersions are: bcftools v0.2.0-rc8-5-g0e06231 (using htslib 0.2.0-rc8-6-gd49dfa6) [updated non release development version] GATK v3.1-1-g07a4bf8 vt normalize v0.5 参考资料： WIKIHGVS]]></content>
      <categories>
        <category>NGS</category>
        <category>标准化</category>
        <category>肿瘤检测</category>
      </categories>
      <tags>
        <tag>变异检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R绘图 - ggplot常用参数记录]]></title>
    <url>%2F2018%2F05%2F16%2FR-ggplot-%E7%94%A8%E5%8F%82%E6%95%B0%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[数据读取如果计划使用ggplot绘图，推荐使用数列方式整理数据，数据之间用tab分割。读取后，默认是数据框格式。然后然后根据所要绘制的图片，对数据进行解析。 折叠代码示例 Type Cancer TMB Plasma hepatocellular_carcinoma 9.743589744 Plasma gastric_cancer 4.615384615 Plasma cervical_cancer 1.025641026 Plasma lung_cancer 4.102564103 Plasma lung_cancer 3.58974359 Plasma lung_cancer 5.641025641 Plasma cervical_cancer 1.025641026 Plasma lung_cancer 1.025641026 Plasma hepatocellular_carcinoma 2.564102564 Plasma lung_cancer 2.564102564 Plasma pancreatic_cancer 1.538461538 Plasma lung_cancer 9.743589744 Plasma lung_cancer 1.538461538 Plasma lung_cancer 1.025641026 Plasma lung_cancer 3.58974359 Plasma lung_cancer 3.076923077 Plasma hepatocellular_carcinoma 2.564102564 Plasma colorectal_cancer 1.025641026 Plasma lung_cancer 6.666666667 Plasma lung_cancer 13.84615385 图片类型柱状图：geom_bar（）1position=&quot;dodge&quot; (多组柱状图平行排列，模式是堆叠柱状图) 箱线图： geom_boxplot1aes(fill=Type) （分类分别绘制箱线图） 坐标轴刻度12scale_x_continuous(breaks=seq(start,end,step)) # 设置x轴对应坐标轴的起始、终止和步长信息。也可以使用数组。scale_y_continuous(breaks=seq(start,end,step)) # 设置y轴对应坐标轴的起始、终止和步长信息。也可以使用数组。 标题格式theme对标签文本的格式进行调整 1theme(axos.text.x=element_text(hjust=0.5,size=8,angle=45)) #hjust对应偏移量，size对应文本字体大小，angle对应字体倾斜角度。 标签格式s 图片截取图片绘制完成后，只截取其中的一部分进行展示，通过改名了，可以调整结果途中展示的数据范围。避免因为某些异常值，导致整个图片展示出现偏差。 1coord_cartesian(xlim=c(0,100),ylim=c(10,50)) # 根据x轴y轴的数据，对图片进行截取，仅保留在截取范围内的图片。 添加辅助线添加水平线geom_hline()1geom_hline(yintercept=10) #添加一天y=10的辅助线； 添加辅助标签 geom_text（）12aes(x=1,y=1,label=as.character(&quot;lab_test&quot;)) #在x=1，y=1的位置添加一个标签，标签内容为“lab_test”；col=&quot;black&quot; #设置标签的颜色；]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Software-Mac环境管理软件-Homebrew简介和基本使用]]></title>
    <url>%2F2018%2F05%2F15%2FSoftware-Mac%E7%8E%AF%E5%A2%83%E7%AE%A1%E7%90%86%E8%BD%AF%E4%BB%B6-Homebrew%E7%AE%80%E4%BB%8B%E5%92%8C%E5%9F%BA%E6%9C%AC%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Homebrew官网简介Homebrew是一个开源的包管理器，可以帮助在mac上对一些软件或者命令行工具进行管理，从而补充一些mac上本身缺少但是实用中需要的重要命令，比如 wget等 安装默认安装 首先确认Mac已安装Xcode、Command Line Tool。安装Command Line Tool： 1xcode-select --install 然后把下面的代码粘贴到Terminal中执行安装Homebrew。 1/usr/bin/ruby -e &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)&quot; Homebrew 会将软件包安装到独立目录，并将其文件软链接至 /usr/local 。Homebrew 不会将文件安装到它本身目录之外，所以您可将 Homebrew 安装到任意位置。 指定路径安装安装到/usr/local/homebrew mac 打开终端输入 1mkdir homebrew &amp;&amp; curl -L https://github.com/Homebrew/homebrew/tarball/master | tar xz --strip 1 -C homebrew 在bash文件中 12homebrew=/usr/local/homebrew/bin:/usr/local/homebrew/sbinexport PATH=$homebrew:$PATH 最后更新一下 12source .bash_profilebrew update 卸载1234567$ cd `brew --prefix`$ rm -rf Cellar$ brew prune$ rm `git ls-files`$ rm -r Library/Homebrew Library/Aliases Library/Formula Library/Contributions$ rm -rf .git$ rm -rf ~/Library/Caches/Homebrew 使用 安装任意包的命令 12$ brew install &lt;packageName&gt;$ brew install wget #示例：安装wget 卸载任意包 12$ brew uninstall &lt;packageName&gt;$ brew uninstall git #示例：卸载git 查询可用包 1$ brew search &lt;packageName&gt; 查看已安装包列表 1$ brew list 查看任意包信息 1$ brew info &lt;packageName&gt; 更新Homebrew 1$ brew update 查看Homebrew版本 1$ brew -v Homebrew帮助信息 1$ brew -h 所有可以安装的包列表]]></content>
      <categories>
        <category>software</category>
        <category>Mac</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础知识 - 文件读写]]></title>
    <url>%2F2018%2F05%2F13%2FPython-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E6%96%87%E4%BB%B6%E8%AF%BB%E5%86%99%2F</url>
    <content type="text"><![CDATA[文本文件的读写创建一个文件对象1对象名 = open(文件名,&quot;模式&quot;) 最常用的模式有： 1234567r 打开只读文件，该文件必须存在。r+ 打开可读写的文件，该文件必须存在。w 打开只写文件，若文件存在则文件长度清为0，即该文件内容会消失。若文件不存在则建立该文件。w+ 打开可读写文件，若文件存在则文件长度清为零，即该文件内容会消失。若文件不存在则建立该文件。a 以附加的方式打开只写文件。若文件不存在，则会建立该文件，如果文件存在，写入的数据会被加到文件尾，即文件原先的内容会被保留。a+ 以附加方式打开可读写的文件。若文件不存在，则会建立该文件，如果文件存在，写入的数据会被加到文件尾后，即文件原先的内容会被保留。上述的形态字符串都可以再加一个b字符，如rb、w+b或ab＋等组合，加入b 字符用来告诉函数库打开的文件为二进制文件，而非纯文字文件。 文件对象的方法读取：1234file.read() #读取整个文件，如果文件超过内存2倍，会报错file.read(N) #读取N bytes的数据file.readline() #读取一行file.readlines() #读取所有行，存到列表中，每个元素是一行； 写入：1file.write(&quot;text &quot;) #向文件对象file中写入内容； 关闭：1file.close(); 使用上下文管理器(with…as…),通过缩进确定代码块，确定文件的使用范围， 在使用文件开始时，自动执行特殊方法 enter() 在使用文件结束后，自动执行特殊方法 exit() 特殊方法，完成文件的关闭1234with open(&quot;new.txt&quot;, &quot;w&quot;) as f: #使用文件管理器打开文件 print(f.closed) f.write(&quot;Hello World!&quot;)print(f.closed) #缩进结束时，文件使用结束，自动关闭文件]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础知识 - 文件读写]]></title>
    <url>%2F2018%2F05%2F13%2FPython-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E8%84%9A%E6%9C%AC%E5%8A%A0%E5%AF%86%2F</url>
    <content type="text"><![CDATA[Python解释器在执行代码的过程中，会首先生成.pyc文件，然后再解释执行.pyc中的内容，解释器也能直接执行.pyc文件。 .pyc文件是一个二进制的文件，是不具备可读性的。 假如我们发到客户环境时，是.pyc文件，而不是.py，那么是不是就可以保护我们的Python代码？ 想要做到这一点，并不难。Python标准库就提供了一个名叫compileall的库，使用它就可以做到。123python -m py_compile file.pypython -m py_compile /root/src/&#123;file1,file2&#125;.py 编译成pyc文件。也可以写份脚本来做这事： 12import py_compilepy_compile.compile(&apos;path&apos;) //path是包括.py文件名的路径 用1python -O -m py_compile file.py 编译成pyo文件。1.其中的 -m 相当于脚本中的import，这里的-m py_compile 相当于上面的 import py_compile2.-O 如果改成 -OO 则是删除相应的 pyo文件，具体帮助可以在控制台输入 python -h 查看 ======================== from:http://blogold.chinaunix.net/u3/93255/showart_1944929.html什么是pyc文件 pyc是一种二进制文件，是由py文件经过编译后，生成的文件，是一种byte code，py文件变成pyc文件后，加载的速度有所提高，而且pyc是一种跨平台的字节码，是由python的虚拟机来执行的，这个是类似于JAVA或者.NET的虚拟机的概念。pyc的内容，是跟python的版本相关的，不同版本编译后的pyc文件是不同的，2.5编译的pyc文件，2.4版本的 python是无法执行的。什么是pyo文件pyo是优化编译后的程序 python -O 源文件即可将源程序编译为pyo文件 什么是pyd文件pyd是python的动态链接库。 为什么需要pyc文件 这个需求太明显了，因为py文件是可以直接看到源码的，如果你是开发商业软件的话，不可能把源码也泄漏出去吧？所以就需要编译为pyc后，再发布出去。当然，pyc文件也是可以反编译的，不同版本编译后的pyc文件是不同的，根据python源码中提供的opcode，可以根据pyc文件反编译出 py文件源码，网上可以找到一个反编译python2.3版本的pyc文件的工具，不过该工具从python2.4开始就要收费了，如果需要反编译出新版本的pyc文件的话，就需要自己动手了（俺暂时还没这能力^–^）,不过你可以自己修改python的源代码中的opcode文件，重新编译 python，从而防止不法分子的破解。生成单个pyc文件 python就是个好东西，它提供了内置的类库来实现把py文件编译为pyc文件，这个模块就是 py_compile 模块。 使用方法非常简单，如下所示，直接在idle中，就可以把一个py文件编译为pyc文件了。(假设在windows环境下) import py_compile py_compile.compile(r’H:\game\test.py’) compile函数原型： compile(file[, cfile[, dfile[, doraise]]]) file 表示需要编译的py文件的路径 cfile 表示编译后的pyc文件名称和路径，默认为直接在file文件名后加c 或者 o，o表示优化的字节码 dfile 这个参数英文看不明白，请各位大大赐教。(鄙视下自己)原文：it is used as the name of the source file in error messages instead of file doraise 可以是两个值，True或者False，如果为True，则会引发一个PyCompileError，否则如果编译文件出错，则会有一个错误，默认显示在sys.stderr中，而不会引发异常 (来自python2.5文档)批量生成pyc文件 一般来说，我们的工程都是在一个目录下的，一般不会说仅仅编译一个py文件而已，而是需要把整个文件夹下的py文件都编译为pyc文件，python又为了我们提供了另一个模块：compileall 。使用方法如下： import compileall compileall.compile_dir(r’H:\game’) 也可以直接用命令行编译一个目录下的文件，如：# python -m compileall /root/src/ 这样就把game目录，以及其子目录下的py文件编译为pyc文件了。嘿嘿，够方便吧。来看下compile_dir函数的说明： compile_dir(dir[, maxlevels[, ddir[, force[, rx[, quiet]]]]]) dir 表示需要编译的文件夹位置 maxlevels 表示需要递归编译的子目录的层数，默认是10层，即默认会把10层子目录中的py文件编译为pyc ddir 英文没明白，原文：it is used as the base path from which the filenames used in error messages will be generated。 force 如果为True，则会强制编译为pyc，即使现在的pyc文件是最新的，还会强制编译一次，pyc文件中包含有时间戳，python编译器会根据时间来决定，是否需要重新生成一次pyc文件 rx 表示一个正则表达式，比如可以排除掉不想要的目录，或者只有符合条件的目录才进行编译 quiet 如果为True，则编译后，不会在标准输出中，打印出信息 (来自python2.5文档) 总结 通过上面的方法，可以方便的把py文件编译为pyc文件了，从而可以实现部分的源码隐藏，保证了python做商业化软件时，保证了部分的安全性吧，继续学习下，看怎么修改opcode。]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础知识 - 序列的方法]]></title>
    <url>%2F2018%2F05%2F12%2FPython-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E8%84%9A%E6%9C%AC%E5%8F%91%E5%B8%83%2F</url>
    <content type="text"><![CDATA[发布先要有账号 首先需要注册一个账号： https://pypi.org/]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础知识 - 序列的方法]]></title>
    <url>%2F2018%2F05%2F12%2FPython-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%BA%8F%E5%88%97%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[快速教程中，我们了解了最基本的序列(sequence)。回忆一下，序列包含有定值表(tuple)和表(list)。此外，字符串(string)是一种特殊的定值表。表的元素可以更改，定值表一旦建立，其元素不可更改。 任何的序列都可以引用其中的元素(item)。 下面的内建函数(built-in function)可用于序列(表，定值表，字符串)：s为一个序列12345len(s) 返回： 序列中包含元素的个数min(s) 返回： 序列中最小的元素max(s) 返回： 序列中最大的元素all(s) 返回： True, 如果所有元素都为True的话any(s) 返回： True, 如果任一元素为True的话 下面的方法主要起查询功能，不改变序列本身, 可用于表和定值表：1234sum(s) 返回：序列中所有元素的和# x为元素值，i为下标(元素在序列中的位置)s.count(x) 返回： x在s中出现的次数s.index(x) 返回： x在s中第一次出现的下标 由于定值表的元素不可变更，下面方法只适用于表：12345678# l为一个表, l2为另一个表l.extend(l2) 在表l的末尾添加表l2的所有元素l.append(x) 在l的末尾附加x元素l.sort() 对l中的元素排序l.reverse() 将l中的元素逆序l.pop() 返回：表l的最后一个元素，并在表l中删除该元素del l[i] 删除该元素(以上这些方法都是在原来的表的上进行操作，会对原来的表产生影响，而不是返回一个新表。) 下面是一些用于字符串的方法。尽管字符串是定值表的特殊的一种，但字符串(string)类有一些方法是改变字符串的。这些方法的本质不是对原有字符串进行操作，而是删除原有字符串，再建立一个新的字符串，所以并不与定值表的特点相矛盾。12345678910111213141516171819202122232425262728293031323334353637383940#str为一个字符串，sub为str的一个子字符串。s为一个序列，它的元素都是字符串。width为一个整数，用于说明新生成字符串的宽度。str.count(sub) 返回：sub在str中出现的次数str.find(sub) 返回：从左开始，查找sub在str中第一次出现的位置。如果str中不包含sub，返回 -1str.index(sub) 返回：从左开始，查找sub在str中第一次出现的位置。如果str中不包含sub，举出错误str.rfind(sub) 返回：从右开始，查找sub在str中第一次出现的位置。如果str中不包含sub，返回 -1str.rindex(sub) 返回：从右开始，查找sub在str中第一次出现的位置。如果str中不包含sub，举出错误str.isalnum() 返回：True， 如果所有的字符都是字母或数字str.isalpha() 返回：True，如果所有的字符都是字母str.isdigit() 返回：True，如果所有的字符都是数字str.istitle() 返回：True，如果所有的词的首字母都是大写str.isspace() 返回：True，如果所有的字符都是空格str.islower() 返回：True，如果所有的字符都是小写字母str.isupper() 返回：True，如果所有的字符都是大写字母str.split([sep, [max]]) 返回：从左开始，以空格为分割符(separator)，将str分割为多个子字符串，总共分割max次。将所得的子字符串放在一个表中返回。可以str.split(&apos;,&apos;)的方式使用逗号或者其它分割符str.rsplit([sep, [max]]) 返回：从右开始，以空格为分割符(separator)，将str分割为多个子字符串，总共分割max次。将所得的子字符串放在一个表中返回。可以str.rsplit(&apos;,&apos;)的方式使用逗号或者其它分割符str.join(s) 返回：将s中的元素，以str为分割符，合并成为一个字符串。str.strip([sub]) 返回：去掉字符串开头和结尾的空格。也可以提供参数sub，去掉位于字符串开头和结尾的sub str.replace(sub, new_sub) 返回：用一个新的字符串new_sub替换str中的substr.capitalize() 返回：将str第一个字母大写str.lower() 返回：将str全部字母改为小写str.upper() 返回：将str全部字母改为大写str.swapcase() 返回：将str大写字母改为小写，小写改为大写str.title() 返回：将str的每个词(以空格分隔)的首字母大写str.center(width) 返回：长度为width的字符串，将原字符串放入该字符串中心，其它空余位置为空格。str.ljust(width) 返回：长度为width的字符串，将原字符串左对齐放入该字符串，其它空余位置为空格。str.rjust(width) 返回：长度为width的字符串，将原字符串右对齐放入该字符串，其它空余位置为空格。]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 编码规范]]></title>
    <url>%2F2018%2F05%2F10%2FPython-%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[item detail PEP 8 Title Style Guide for Python Code Version c451868df657 Last-Modified 2016-06-08 10:43:53 -0400 (Wed, 08 Jun 2016) Author Guido van Rossum , Barry Warsaw , Nick Coghlan Status Active Type Process Content-Type text/x-rst Created 05-Jul-2001 Post-History 05-Jul-2001, 01-Aug-2013 Introduction 介绍本文提供的Python代码编码规范基于Python主要发行版本的标准库。Python的C语言实现的C代码规范请查看相应的PEP指南1。 这篇文档以及PEP 257（文档字符串的规范）改编自Guido原始的《Python Style Guide》一文，同时添加了一些来自Barry的风格指南2。 这篇规范指南随着时间的推移而逐渐演变，随着语言本身的变化，过去的约定也被淘汰了。 许多项目有自己的编码规范，在出现规范冲突时，项目自身的规范优先。 A Foolish Consistency is the Hobgoblin of Little Minds 尽信书,则不如无书Guido的一条重要的见解是代码阅读比写更加频繁。这里提供的指导原则主要用于提升代码的可读性，使得在大量的Python代码中保持一致。就像PEP 20提到的，“Readability counts”。 这是一份关于一致性的风格指南。这份风格指南的风格一致性是非常重要的。更重要的是项目的风格一致性。在一个模块或函数的风格一致性是最重要的。 然而，应该知道什么时候应该不一致，有时候编码规范的建议并不适用。当存在模棱两可的情况时，使用自己的判断。看看其他的示例再决定哪一种是最好的，不要羞于发问。 特别是不要为了遵守PEP约定而破坏兼容性！ 几个很好的理由去忽略特定的规则： 当遵循这份指南之后代码的可读性变差，甚至是遵循PEP规范的人也觉得可读性差。 与周围的代码保持一致（也可能出于历史原因），尽管这也是清理他人混乱（真正的Xtreme Programming风格）的一个机会。 有问题的代码出现在发现编码规范之前，而且也没有充足的理由去修改他们。 当代码需要兼容不支持编码规范建议的老版本Python。 Code lay-out 代码布局Indentation 缩进每一级缩进使用4个空格。 续行应该与其包裹元素对齐，要么使用圆括号、方括号和花括号内的隐式行连接来垂直对齐，要么使用挂行缩进对齐3。当使用挂行缩进时，应该考虑到第一行不应该有参数，以及使用缩进以区分自己是续行。 推荐：1234567891011121314# 与左括号对齐foo = long_function_name(var_one, var_two, var_three, var_four)# 用更多的缩进来与其他行区分def long_function_name( var_one, var_two, var_three, var_four): print(var_one)# 挂行缩进应该再换一行foo = long_function_name( var_one, var_two, var_three, var_four) 不推荐：123456789# 没有使用垂直对齐时，禁止把参数放在第一行foo = long_function_name(var_one, var_two, var_three, var_four)# 当缩进没有与其他行区分时，要增加缩进def long_function_name( var_one, var_two, var_three, var_four): print(var_one) 四空格的规则对于续行是可选的。可选：1234# 挂行缩进不一定要用4个空格foo = long_function_name( var_one, var_two, var_three, var_four) 当if语句的条件部分长到需要换行写的时候，注意可以在两个字符关键字的连接处（比如if），增加一个空格，再增加一个左括号来创造一个4空格缩进的多行条件。这会与if语句内同样使用4空格缩进的代码产生视觉冲突。PEP没有明确指明要如何区分i发的条件代码和内嵌代码。可使用的选项包括但不限于下面几种情况：123456789101112131415# 没有额外的缩进if (this_is_one_thing and that_is_another_thing): do_something()# 增加一个注释，在能提供语法高亮的编辑器中可以有一些区分if (this_is_one_thing and that_is_another_thing): # Since both conditions are true, we can frobnicate. do_something()# 在条件判断的语句添加额外的缩进if (this_is_one_thing and that_is_another_thing): do_something() （可以参考下面关于是否在二进制运算符之前或之后截断的讨论）在多行结构中的大括号/中括号/小括号的右括号可以与内容对齐单独起一行作为最后一行的第一个字符，就像这样：12345678my_list = [ 1, 2, 3, 4, 5, 6, ]result = some_function_that_takes_arguments( &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;, ) 或者也可以与多行结构的第一行第一个字符对齐，就像这样：12345678my_list = [ 1, 2, 3, 4, 5, 6,]result = some_function_that_takes_arguments( &apos;a&apos;, &apos;b&apos;, &apos;c&apos;, &apos;d&apos;, &apos;e&apos;, &apos;f&apos;,) Tabs or Spaces？ 制表符还是空格？空格是首选的缩进方式。制表符只能用于与同样使用制表符缩进的代码保持一致。Python3不允许同时使用空格和制表符的缩进。混合使用制表符和空格缩进的Python2代码应该统一转成空格。当在命令行加入-t选项执行Python2时，它会发出关于非法混用制表符与空格的警告。当使用–tt时，这些警告会变成错误。强烈建议使用这样的参数。 Maximum Line Length 行的最大长度所有行限制的最大字符数为79。 没有结构化限制的大块文本（文档字符或者注释），每行的最大字符数限制在72。 限制编辑器窗口宽度可以使多个文件并行打开，并且在使用代码检查工具(在相邻列中显示这两个版本)时工作得很好。 大多数工具中的默认封装破坏了代码的可视化结构，使代码更难以理解。避免使用编辑器中默认配置的80窗口宽度，即使工具在帮你折行时在最后一列放了一个标记符。某些基于Web的工具可能根本不提供动态折行。一些团队更喜欢较长的行宽。如果代码主要由一个团队维护，那这个问题就能达成一致，可以把行长度从80增加到100个字符（更有效的做法是将行最大长度增加到99个字符），前提是注释和文档字符串依然已72字符折行。 Python标准库比较保守，需要将行宽限制在79个字符（文档/注释限制在72）。 较长的代码行选择Python在小括号，中括号以及大括号中的隐式续行方式。通过小括号内表达式的换行方式将长串折成多行。这种方式应该优先使用，而不是使用反斜杠续行。 反斜杠有时依然很有用。比如，比较长的，多个with状态语句，不能使用隐式续行，所以反斜杠是可以接受的： 123with open(&apos;/path/to/some/file/you/want/to/read&apos;) as file_1, \ open(&apos;/path/to/some/file/being/written&apos;, &apos;w&apos;) as file_2: file_2.write(file_1.read()) （请参阅前面关于多行if-语句的讨论，以获得关于这种多行with-语句缩进的进一步想法。）另一种类似情况是使用assert语句。确保在续行进行适当的缩进。 Should a line break before or after a binary operator? 在二元运算符之前应该换行吗？几十年来，推荐的风格是在二元运算符之后中断。但是这回影响可读性，原因有二：操作符一般分布在屏幕上不同的列中，而且每个运算符被移到了操作数的上一行。下面例子这个情况就需要额外注意，那些变量是相加的，那些变量是相减的：123456# 不推荐: 操作符离操作数太远income = (gross_wages + taxable_interest + (dividends - qualified_dividends) - ira_deduction - student_loan_interest) 为了解决这种可读性的问题，数学家和他们的出版商遵循了相反的约定。Donald Knuth在他的Computers and Typesetting系列中解释了传统规则：“尽管段落中的公式总是在二元运算符和关系之后中断，显示出来的公式总是要在二元运算符之前中断”4。遵循数学的传统能产出更多可读性高的代码：123456# 推荐：运算符和操作数很容易进行匹配income = (gross_wages + taxable_interest + (dividends - qualified_dividends) - ira_deduction - student_loan_interest) 在Python代码中，允许在二元运算符之前或之后中断，只要本地的约定是一致的。对于新代码，建议使用Knuth的样式。 Blank Lines 空行顶层函数和类的定义，前后用两个空行隔开。 类里的方法定义用一个空行隔开。 相关的功能组可以用额外的空行（谨慎使用）隔开。一堆相关的单行代码之间的空白行可以省略（例如，一组虚拟实现 dummy implementations）。 在函数中使用空行来区分逻辑段（谨慎使用）。 Python接受control-L（即^L）换页符作为空格；许多工具把这些字符当作页面分隔符，所以你可以在文件中使用它们来分隔相关段落。请注意，一些编辑器和基于Web的代码阅读器可能无法识别control-L为换页，将在其位置显示另一个字形。 Source File Encoding 源文件编码Python核心发布版本中的代码总是以UTF-8格式编码（或者在Python2中用ASCII编码）。 使用ASCII（在Python2中）或UTF-8（在Python3中）编码的文件不应具有编码声明。 在标准库中，非默认的编码应该只用于测试，或者当一个注释或者文档字符串需要提及一个包含内ASCII字符编码的作者名字的时候；否则，使用\x,\u,\U , 或者 \N 进行转义来包含非ASCII字符。 对于Python 3和更高版本，标准库规定了以下策略（参见 PEP 3131）：Python标准库中的所有标识符必须使用ASCII标识符，并在可行的情况下使用英语单词（在许多情况下，缩写和技术术语是非英语的）。此外，字符串文字和注释也必须是ASCII。唯一的例外是（a）测试非ASCII特征的测试用例，以及（b）作者的名称。作者的名字如果不使用拉丁字母拼写，必须提供一个拉丁字母的音译。 鼓励具有全球受众的开放源码项目采取类似的政策。 Imports 导入导入通常在分开的行，例如：123456#推荐: import osimport sys#不推荐: import sys, os 但是可以这样：1from subprocess import Popen, PIPE 导入总是位于文件的顶部，在模块注释和文档字符串之后，在模块的全局变量与常量之前。导入应该按照以下顺序分组： 标准库导入 相关第三方库导入 本地应用/库特定导入 你应该在每一组导入之间加入空行。 推荐使用绝对路径导入，如果导入系统没有正确的配置（比如包里的一个目录在sys.path里的路径后），使用绝对路径会更加可读并且性能更好（至少能提供更好的错误信息）:123import mypkg.siblingfrom mypkg import siblingfrom mypkg.sibling import example 然而，显示的指定相对导入路径是使用绝对路径的一个可接受的替代方案，特别是在处理使用绝对路径导入不必要冗长的复杂包布局时：12from . import siblingfrom .sibling import example 标准库要避免使用复杂的包引入结构，而总是使用绝对路径。 不应该使用隐式相对路径导入，并且在Python 3中删除了它。 当从一个包含类的模块中导入类时，常常这么写：12from myclass import MyClassfrom foo.bar.yourclass import YourClass 如果上述的写法导致名字的冲突，那么这么写：12import myclassimport foo.bar.yourclass 然后使用“myclass.MyClass”和“foo.bar.yourclass.YourClass”。 避免通配符的导入（from import *），因为这样做会不知道命名空间中存在哪些名字，会使得读取接口和许多自动化工具之间产生混淆。对于通配符的导入，有一个防御性的做法，即将内部接口重新发布为公共API的一部分（例如，用可选加速器模块的定义覆盖纯Python实现的接口，以及重写那些事先不知道的定义）。 当以这种方式重新发布名称时，以下关于公共和内部接口的准则仍然适用。 Module level dunder names 模块级的“呆”名像all , author , version 等这样的模块级“呆名“（也就是名字里有两个前缀下划线和两个后缀下划线），应该放在文档字符串的后面，以及除from future 之外的import表达式前面。Python要求将来在模块中的导入，必须出现在除文档字符串之外的其他代码之前。比如：12345678910111213&quot;&quot;&quot;This is the example module.This module does stuff.&quot;&quot;&quot;from __future__ import barry_as_FLUFL__all__ = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;]__version__ = &apos;0.1&apos;__author__ = &apos;Cardinal Biggles&apos;import osimport sys String Quotes 字符串引号在Python中，单引号和双引号字符串是相同的。PEP不会为这个给出建议。选择一条规则并坚持使用下去。当一个字符串中包含单引号或者双引号字符的时候，使用和最外层不同的符号来避免使用反斜杠，从而提高可读性。 对于三引号字符串，总是使用双引号字符来与PEP 257中的文档字符串约定保持一致。 Whitespace in Expressions and Statements 表达式和语句中的空格Pet Peeves 不能忍受的事情在下列情况下，避免使用无关的空格： 紧跟在小括号，中括号或者大括号后。 12Yes: spam(ham[1], &#123;eggs: 2&#125;)No: spam( ham[ 1 ], &#123; eggs: 2 &#125; ) 紧贴在逗号、分号或者冒号之前。 12Yes: if x == 4: print x, y; x, y = y, xNo: if x == 4 : print x , y ; x , y = y , x 然而，冒号在切片中就像二元运算符，在两边应该有相同数量的空格（把它当做优先级最低的操作符）。在扩展的切片操作中，所有的冒号必须有相同的间距。例外情况：当一个切片参数被省略时，空格就被省略了。 12345ham[1:9], ham[1:9:3], ham[:9:3], ham[1::3], ham[1:9:]ham[lower:upper], ham[lower:upper:], ham[lower::step]ham[lower+offset : upper+offset]ham[: upper_fn(x) : step_fn(x)], ham[:: step_fn(x)]ham[lower + offset : upper + offset] 不推荐1234ham[lower + offset:upper + offset]ham[1: 9], ham[1 :9], ham[1:9 :3]ham[lower : : upper]ham[ : upper] 紧贴在函数参数的左括号之前。 12Yes: spam(1)No: spam (1) 紧贴索引或者切片的左括号之前。 12Yes: dct[&apos;key&apos;] = lst[index]No: dct [&apos;key&apos;] = lst [index] 为了和另一个赋值语句对齐，在赋值运算符附件加多个空格。 推荐 123x = 1y = 2long_variable = 3 不推荐： 123x = 1y = 2long_variable = 3 Other Recommendations 其他建议 避免在尾部添加空格。因为尾部的空格通常都看不见，会产生混乱：比如，一个反斜杠后面跟一个空格的换行符，不算续行标记。有些编辑器不会保留尾空格，并且很多项目（像CPython）在pre-commit的挂钩调用中会过滤掉尾空格。 总是在二元运算符两边加一个空格：赋值（=），增量赋值（+=，-=），比较（==,&lt;,&gt;,!=,&lt;&gt;,&lt;=,&gt;=,in,not,in,is,is not），布尔（and, or, not）。 如果使用具有不同优先级的运算符，请考虑在具有最低优先级的运算符周围添加空格。有时需要通过自己来判断；但是，不要使用一个以上的空格，并且在二元运算符的两边使用相同数量的空格。 推荐： 12345i = i + 1submitted += 1x = x*2 - 1hypot2 = x*x + y*yc = (a+b) * (a-b) 不推荐 12345i=i+1submitted +=1x = x * 2 - 1hypot2 = x * x + y * yc = (a + b) * (a - b) 在制定关键字参数或者默认参数值的时候，不要在=附近加上空格。推荐 12def complex(real, imag=0.0): return magic(r=real, i=imag) 不推荐12def complex(real, imag = 0.0): return magic(r = real, i = imag) 功能型注释应该使用冒号的一般性规则，并且在使用-&gt;的时候要在两边加空格。（参考下面的功能注释得到能够多信息） 推荐12def munge(input: AnyStr): ...def munge() -&gt; AnyStr: ... 不推荐12def munge(input:AnyStr): ...def munge()-&gt;PosInt: ... 当给有类型备注的参数赋值的时候，在=两边添加空格（仅针对那种有类型备注和默认值的参数）。推荐：12def munge(sep: AnyStr = None): ...def munge(input: AnyStr, sep: AnyStr = None, limit=1000): ... 不推荐12def munge(input: AnyStr=None): ...def munge(input: AnyStr, limit = 1000): ... 复合语句(同一行中的多个语句)通常是不允许的。推荐：12345if foo == &apos;blah&apos;: do_blah_thing()do_one()do_two()do_three() 不推荐12if foo == &apos;blah&apos;: do_blah_thing()do_one(); do_two(); do_three() 虽然有时候将小的代码块和 if/for/while 放在同一行没什么问题，多行语句块的情况不要这样用，同样也要避免代码行太长！不推荐123if foo == &apos;blah&apos;: do_blah_thing()for x in lst: total += xwhile t &lt; 10: t = delay() 不要12345678910if foo == &apos;blah&apos;: do_blah_thing()else: do_non_blah_thing()try: something()finally: cleanup()do_one(); do_two(); do_three(long, argument, list, like, this)if foo == &apos;blah&apos;: one(); two(); three() Comments 注释与代码相矛盾的注释比没有注释还糟，当代码更改时，优先更新对应的注释！ 注释应该是完整的句子。如果一个注释是一个短语或句子，它的第一个单词应该大写，除非它是以小写字母开头的标识符(永远不要改变标识符的大小写！)。 如果注释很短，结尾的句号可以省略。块注释一般由完整句子的一个或多个段落组成，并且每句话结束有个句号。 在句尾结束的时候应该使用两个空格。 当用英文书写时，遵循Strunk and White （译注：《Strunk and White, The Elements of Style》）的书写风格。 在非英语国家的Python程序员，请使用英文写注释，除非你120%的确信你的代码不会被使用其他语言的人阅读。 Block Comments 块注释块注释通常适用于跟随它们的某些（或全部）代码，并缩进到与代码相同的级别。块注释的每一行开头使用一个#和一个空格（除非块注释内部缩进文本）。 块注释内部的段落通过只有一个#的空行分隔。 Inline Comments 行内注释有节制地使用行内注释。行内注释是与代码语句同行的注释。行内注释和代码至少要有两个空格分隔。注释由#和一个空格开始。事实上，如果状态明显的话，行内注释是不必要的，反而会分散注意力。比如说下面这样就不需要：1x = x + 1 # Increment x 但有时，这样做很有用： 1x = x + 1 # Compensate for border Documentation Strings 文档字符串编写好的文档说明（也叫“docstrings”）的约定在PEP 257中永恒不变。 要为所有的公共模块，函数，类以及方法编写文档说明。非公共的方法没有必要，但是应该有一个描述方法具体作用的注释。这个注释应该在def那一行之后。 PEP 257 描述了写出好的文档说明相关的约定。特别需要注意的是，多行文档说明使用的结尾三引号应该自成一行，例如： 1234&quot;&quot;&quot;Return a foobangOptional plotz says to frobnicate the bizbaz first.&quot;&quot;&quot; 对于单行的文档说明，尾部的三引号应该和文档在同一行。 Naming Conventions 命名规范Python库的命名规范很乱，从来没能做到完全一致。但是目前有一些推荐的命名标准。新的模块和包（包括第三方框架）应该用这套标准，但当一个已有库采用了不同的风格，推荐保持内部一致性。 Overriding Principle 最重要的原则那些暴露给用户的API接口的命名，应该遵循反映使用场景而不是实现的原则。 Descriptive: Naming Styles 描述：命名风格有许多不同的命名风格。这里能够帮助大家识别正在使用什么样的命名风格，而不考虑他们为什么使用。以下是常见的命名方式： b（单个小写字母） B（单个大写字母） lowercase 小写字母 lower_case_with_underscores 使用下划线分隔的小写字母 UPPERCASE 大写字母 UPPER_CASE_WITH_UNDERSCORES 使用下划线分隔的大写字母 CapitalizedWords（或者叫 CapWords，或者叫CamelCase 驼峰命名法 —— 这么命名是因为字母看上去有起伏的外观5）。有时候也被称为StudlyCaps。注意：当在首字母大写的风格中用到缩写时，所有缩写的字母用大写，因此，HTTPServerError 比 HttpServerError 好。 mixedCase（不同于首字母大写，第一个单词的首字母小写） Capitalized_Words_With_Underscores（巨丑无比！） 也有用唯一的短前缀把相关命名组织在一起的方法。这在Python中不常用，但还是提一下。比如，os.stat()函数中包含类似以st_mode，st_size，st_mtime这种传统命名方式命名的变量。（这么做是为了与 POSIX 系统的调用一致，以帮助程序员熟悉它。）X11库的所有公共函数都加了前缀X。在Python里面没必要这么做，因为属性和方法在调用的时候都会用类名做前缀，函数名用模块名做前缀。另外，下面这种用前缀或结尾下划线的特殊格式是被认可的（通常和一些约定相结合）： _single_leading_underscore：（单下划线开头）弱“内部使用”指示器。比如 from M import * 是不会导入以下划线开始的对象的。 single_trailing_underscore_：（单下划线结尾）这是避免和Python内部关键词冲突的一种约定，比如：Tkinter.Toplevel(master, class_=’ClassName’) double_leading_underscore：（双下划线开头）当这样命名一个类的属性时，调用它的时候名字会做矫正（在类FooBar中，boo变成了_FooBar__boo；见下文）。 double_leading_and_trailing_underscore：（双下划线开头，双下划线结尾）“magic”对象或者存在于用户控制的命名空间内的属性，例如：init,import或者file。除了作为文档之外，永远不要命这样的名。 Prescriptive: Naming Conventions 约定俗成：命名约定Names to Avoid 应避免的名字永远不要使用字母‘l’（小写的L），‘O’（大写的O），或者‘I’（大写的I）作为单字符变量名。在有些字体里，这些字符无法和数字0和1区分，如果想用‘l’，用‘L’代替。 Package and Module Names 包名和模块名模块应该用简短全小写的名字，如果为了提升可读性，下划线也是可以用的。Python包名也应该使用简短全小写的名字，但不建议用下划线。当使用C或者C++编写了一个依赖于提供高级（更面向对象）接口的Python模块的扩展模块，这个C/C++模块需要一个下划线前缀（例如：_socket） Class Names 类名类名一般使用首字母大写的约定。在接口被文档化并且主要被用于调用的情况下，可以使用函数的命名风格代替。注意，对于内置的变量命名有一个单独的约定：大部分内置变量是单个单词（或者两个单词连接在一起），首字母大写的命名法只用于异常名或者内部的常量。 Exception Names 异常名因为异常一般都是类，所有类的命名方法在这里也适用。然而，你需要在异常名后面加上“Error”后缀（如果异常确实是一个错误）。 Global Variable Names 全局变量名（我们希望这一类变量只在模块内部使用。）约定和函数命名规则一样。通过 from M import * 导入的模块应该使用all机制去防止内部的接口对外暴露，或者使用在全局变量前加下划线的方式（表明这些全局变量是模块内非公有）。 Function Names 函数名函数名应该小写，如果想提高可读性可以用下划线分隔。大小写混合仅在为了兼容原来主要以大小写混合风格的情况下使用（比如 threading.py），保持向后兼容性。 Function and method arguments 函数和方法参数始终要将 self 作为实例方法的的第一个参数。始终要将 cls 作为类静态方法的第一个参数。如果函数的参数名和已有的关键词冲突，在最后加单一下划线比缩写或随意拼写更好。因此 class_ 比 clss 更好。（也许最好用同义词来避免这种冲突） Method Names and Instance Variables 方法名和实例变量遵循这样的函数命名规则：使用下划线分隔小写单词以提高可读性。在非共有方法和实例变量前使用单下划线。通过双下划线前缀触发Python的命名转换规则来避免和子类的命名冲突。Python通过类名对这些命名进行转换：如果类 Foo 有一个叫 a 的成员变量， 它无法通过 Foo.a 访问。（执着的用户可以通过 Foo._Foo__a 访问。）一般来说，前缀双下划线用来避免类中的属性命名与子类冲突的情况。注意：关于__names的用法存在争论（见下文）。 Constants 常量常量通常定义在模块级，通过下划线分隔的全大写字母命名。例如： MAX_OVERFLOW 和 TOTAL。 Designing for inheritance 继承的设计始终要考虑到一个类的方法和实例变量（统称：属性）应该是共有还是非共有。如果存在疑问，那就选非共有；因为将一个非共有变量转为共有比反过来更容易。公共属性是那些与类无关的客户使用的属性，并承诺避免向后不兼容的更改。非共有属性是那些不打算让第三方使用的属性；你不需要承诺非共有属性不会被修改或被删除。我们不使用“私有（private）”这个说法，是因为在Python中目前还没有真正的私有属性（为了避免大量不必要的常规工作）。另一种属性作为子类API的一部分（在其他语言中通常被称为“protected”）。有些类是专为继承设计的，用来扩展或者修改类的一部分行为。当设计这样的类时，要谨慎决定哪些属性时公开的，哪些是作为子类的API，哪些只能在基类中使用。贯彻这样的思想，一下是一些让代码Pythonic的准则： 公共属性不应该有前缀下划线。 如果公共属性名和关键字冲突，在属性名之后增加一个下划线。这比缩写和随意拼写好很多。（然而，尽管有这样的规则，在作为参数或者变量时，‘cls’是表示‘类’最好的选择，特别是作为类方法的第一个参数。）注意1：参考之前的类方法参数命名建议 对于单一的共有属性数据，最好直接对外暴露它的变量名，而不是通过负责的 存取器（accessor）/突变（mutator） 方法。请记住，如果你发现一个简单的属性需要成长为一个功能行为，那么Python为这种将来会出现的扩展提供了一个简单的途径。在这种情况下，使用属性去隐藏属性数据访问背后的逻辑。注意1：属性只在new-style类中起作用。注意2：尽管功能方法对于类似缓存的负面影响比较小，但还是要尽量避免。注意3：属性标记会让调用者认为开销（相当的）小，避免用属性做开销大的计算。 如果你的类打算用来继承的话，并且这个类里有不希望子类使用的属性，就要考虑使用双下划线前缀并且没有后缀下划线的命名方式。这会调用Python的命名转换算法，将类的名字加入到属性名里。这样做可以帮助避免在子类中不小心包含了相同的属性名而产生的冲突。注意1：只有类名才会整合进属性名，如果子类的属性名和类名和父类都相同，那么你还是会有命名冲突的问题。注意2：命名转换会在某些场景使用起来不太方便，例如调试，getattr()。然而命名转换的算法有很好的文档说明并且很好操作。注意3：不是所有人都喜欢命名转换。尽量避免意外的名字冲突和潜在的高级调用。 ################################################ Public and internal interfaces 公共和内部的接口任何向后兼容保证只适用于公共接口，因此，用户清晰地区分公共接口和内部接口非常重要。 文档化的接口被认为是公开的，除非文档明确声明它们是临时或内部接口，不受通常的向后兼容性保证。所有未记录的接口都应该是内部的。 为了更好地支持内省（introspection），模块应该使用all属性显式地在它们的公共API中声明名称。将all设置为空列表表示模块没有公共API。 即使通过all设置过，内部接口（包，模块，类，方法，属性或其他名字）依然需要单个下划线前缀。 如果一个命名空间（包，模块，类）被认为是内部的，那么包含它的接口也应该被认为是内部的。 导入的名称应该始终被视作是一个实现的细节。其他模块必须不能间接访问这样的名称，除非它是包含它的模块中有明确的文档说明的API，例如 os.path 或者是一个包里从子模块公开函数接口的 init 模块。 Programming Recommendations 编程建议 代码应该用不损害其他Python实现的方式去编写（PyPy，Jython，IronPython，Cython，Psyco 等）。比如，不要依赖于在CPython中高效的内置字符连接语句 a += b 或者 a = a + b。这种优化甚至在CPython中都是脆弱的（它只适用于某些类型）并且没有出现在不使用引用计数的实现中。在性能要求比较高的库中，可以种 ”.join() 代替。这可以确保字符关联在不同的实现中都可以以线性时间发生。 和像None这样的单例对象进行比较的时候应该始终用 is 或者 is not，永远不要用等号运算符。另外，如果你在写 if x 的时候，请注意你是否表达的意思是 if x is not None。举个例子，当测试一个默认值为None的变量或者参数是否被设置为其他值的时候。这个其他值应该是在上下文中能成为bool类型false的值。 使用 is not 运算符，而不是 not … is 。虽然这两种表达式在功能上完全相同，但前者更易于阅读，所以优先考虑。 12345推荐：if foo is not None:不推荐：if not foo is None: 当使用富比较（rich comparisons，一种复杂的对象间比较的新机制，允许返回值不为-1,0,1）实现排序操作的时候，最好实现全部的六个操作符（eq, ne, lt, gt, ge）而不是依靠其他的代码去实现特定的比较。为了最大程度减少这一过程的开销， functools.total_ordering() 修饰符提供了用于生成缺少的比较方法的工具。PEP 207 指出Python实现了反射机制。因此，解析器会将 y &gt; x 转变为 x &lt; y，将 y &gt;= x 转变为 x &lt;= y，也会转换x == y 和 x != y的参数。sort() 和 min()方法确保使用&lt;操作符，max()使用&gt;操作符。然而，最好还是实现全部六个操作符，以免在其他地方出现冲突。 始终使用def表达式，而不是通过赋值语句将lambda表达式绑定到一个变量上。1234推荐：def f(x): return 2*x不推荐：f = lambda x: 2*x 第一个形式意味着生成的函数对象的名称是“f”而不是泛型“&lt; lambda &gt;”。这在回溯和字符串显示的时候更有用。赋值语句的使用消除了lambda表达式优于显式def表达式的唯一优势（即lambda表达式可以内嵌到更大的表达式中）。 从Exception继承异常，而不是BaseException。直接继承BaseException的异常适用于几乎不用来捕捉的异常。 设计异常的等级，要基于扑捉异常代码的需要，而不是异常抛出的位置。以编程的方式去回答“出了什么问题？”，而不是只是确认“出现了问题”（内置异常结构的例子参考 PEP 3151 ） 类的命名规范适用于这里，但是你需要添加一个“Error”的后缀到你的异常类，如果异常是一个Error的话。非本地流控制或者其他形式的信号的非错误异常不需要特殊的后缀。 适当地使用异常链接。在Python 3里，为了不丢失原始的根源，可以显式指定“raise X from Y”作为替代。 当故意替换一个内部异常时（Python 2 使用“raise X”， Python 3.3 之后 使用 “raise X from None”），确保相关的细节转移到新的异常中（比如把AttributeError转为KeyError的时候保留属性名，或者将原始异常信息的文本内容内嵌到新的异常中）。 在Python 2中抛出异常时，使用 rasie ValueError(‘message’) 而不是用老的形式 raise ValueError, ‘message’。 第二种形式在Python3 的语法中不合法 使用小括号，意味着当异常里的参数非常长，或者包含字符串格式化的时候，不需要使用换行符。 当捕获到异常时，如果可以的话写上具体的异常名，而不是只用一个except: 块。比如说： 1234try: import platform_specific_moduleexcept ImportError: platform_specific_module = None 如果只有一个except: 块将会捕获到SystemExit和KeyboardInterrupt异常，这样会很难通过Control-C中断程序，而且会掩盖掉其他问题。如果你想捕获所有指示程序出错的异常，使用 except Exception: （只有except等价于 except BaseException:）。两种情况不应该只使用‘excpet’块： 如果异常处理的代码会打印或者记录log；至少让用户知道发生了一个错误。 如果代码需要做清理工作，使用 raise..try…finally 能很好处理这种情况并且能让异常继续上浮。 当给捕捉的异常绑定一个名字时，推荐使用在Python 2.6中加入的显式命名绑定语法：1234try: process_data()except Exception as exc: raise DataProcessingFailedError(str(exc)) 为了避免和原来基于逗号分隔的语法出现歧义，Python3只支持这一种语法。 当捕捉操作系统的错误时，推荐使用Python 3.3 中errno内定数值指定的异常等级。 另外，对于所有的 try/except 语句块，在try语句中只填充必要的代码，这样能避免掩盖掉bug。 123456789101112131415推荐：try: value = collection[key]except KeyError: return key_not_found(key)else: return handle_value(value)不推荐：try: # Too broad! return handle_value(collection[key])except KeyError: # Will also catch KeyError raised by handle_value() return key_not_found(key) 当代码片段局部使用了某个资源的时候，使用with 表达式来确保这个资源使用完后被清理干净。用try/finally也可以。 无论何时获取和释放资源，都应该通过单独的函数或方法调用上下文管理器。举个例子：123456推荐：with conn.begin_transaction(): do_stuff_in_transaction(conn)不推荐：with conn: do_stuff_in_transaction(conn) 第二个例子没有提供任何信息去指明enter和exit方法在事务之后做出了关闭连接之外的其他事情。这种情况下，明确指明非常重要。 返回的语句保持一致。函数中的返回语句都应该返回一个表达式，或者都不返回。如果一个返回语句需要返回一个表达式，那么在没有值可以返回的情况下，需要用 return None 显式指明，并且在函数的最后显式指定一条返回语句（如果能跑到那的话）。 123456789101112131415161718192021推荐：def foo(x): if x &gt;= 0: return math.sqrt(x) else: return Nonedef bar(x): if x &lt; 0: return None return math.sqrt(x)不推荐：def foo(x): if x &gt;= 0: return math.sqrt(x)def bar(x): if x &lt; 0: return return math.sqrt(x) 使用字符串方法代替字符串模块。 字符串方法总是更快，并且和unicode字符串分享相同的API。如果需要兼容Python2.0之前的版本可以不用考虑这个规则。 使用 ”.startswith() 和 ”.endswith() 代替通过字符串切割的方法去检查前缀和后缀。 startswith()和endswith()更干净，出错几率更小。比如： 12推荐: if foo.startswith(&apos;bar&apos;):糟糕: if foo[:3] == &apos;bar&apos;: 对象类型的比较应该用isinstance()而不是直接比较type。 12正确: if isinstance(obj, int):糟糕: if type(obj) is type(1): 当检查一个对象是否为string类型时，记住，它也有可能是unicode string！在Python2中，str和unicode都有相同的基类：basestring，所以你可以这样：1if isinstance(obj, basestring): 注意，在Python3中，unicode和basestring都不存在了（只有str）并且bytes类型的对象不再是string类型的一种（它是整数序列） 对于序列来说（strings，lists，tuples），可以使用空序列为false的情况。 12345正确: if not seq: if seq:糟糕: if len(seq): if not len(seq): 书写字符串时不要依赖单词结尾的空格，这样的空格在视觉上难以区分，有些编辑器会自动去掉他们（比如 reindent.py （译注：re indent 重新缩进）） 不要用 == 去和True或者False比较：123正确: if greeting:糟糕: if greeting == True:更糟: if greeting is True: Function Annotations 功能注释[PEP 484的引入，功能型注释的风格规范有些变化。 为了向前兼容，在Python3代码中的功能注释应该使用 PEP 484的语法规则。（在前面的章节中对注释有格式化的建议。） 不再鼓励使用之前在PEP中推荐的实验性样式。 然而，在stdlib库之外，在PEP 484中的实验性规则是被鼓励的。比如用PEP 484的样式标记大型的第三方库或者应用程序，回顾添加这些注释是否简单，并观察是否增加了代码的可读性。 Python的标准库代码应该保守使用这种注释，但新的代码或者大型的重构可以使用这种注释。 如果代码希望对功能注释有不同的用途，建议在文件的顶部增加一个这种形式的注释：1# type: ignore 这会告诉检查器忽略所有的注释。（在 PEP 484中可以找到从类型检查器禁用投诉的更细粒度的方法。） 像linters一样，类型检测器是可选的可独立的工具。默认情况下，Python解释器不应该因为类型检查而发出任何消息，也不应该基于注释改变它们的行为。 不想使用类型检测的用户可以忽略他们。然而，第三方库的用户可能希望在这些库上运行类型检测。为此， PEP 484 建议使用存根文件类型：.pyi文件，这种文件类型相比于.py文件会被类型检测器读取。存根文件可以和库一起，或者通过typeshed repo6独立发布（通过库作者的许可） 对于需要向后兼容的代码，可以以注释的形式添加功能型注释。参见PEP 484的相关部分7。 参考pep8 Python PEP8 编码规范中文版 PEP 7, Style Guide for C Code, van Rossum Barry’s GNU Mailman style guide http://barry.warsaw.us/software/STYLEGUIDE.txt 挂行缩进是一种类型设置样式，其中除第一行之外，段落中的所有行都缩进。在Python中，这个术语是用来描述一种风格：在被括号括起来的语句中，左括号是这一行最后一个非空格字符，随后括号内的内容每一行进行缩进，直到遇到右括号。 Donald Knuth’s The TeXBook, pages 195 and 196 http://www.wikipedia.com/wiki/CamelCase Typeshed repo https://github.com/python/typeshed Suggested syntax for Python 2.7 and straddling code https://www.python.org/dev/peps/pep-0484/#suggested-syntax-for-python-2-7-and-straddling-code]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础知识]]></title>
    <url>%2F2018%2F05%2F10%2FPython-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%AF%B9%E8%B1%A1%E5%AD%97%E5%85%B8%2F</url>
    <content type="text"><![CDATA[基本板书函数 命令 作用 range(N) 生成从０到N-1共 Ｎ个数字的列表 continue 跳过本轮进入下一轮循环（相当于Perl的 next） break 终止循环 （相当于Perl的 last） def 定义函数（相当于Perl的 sub） dir() dir()用来查询一个类或者对象所有属性 print dir(list) help() help()用来查询的说明文档 print help(list) 对象通过class 创建一个对象；对于对象的属性可以直接在class 块中进行赋值；同时可以通过def 对对象添加一些方法； 123456789101112class Bird(object): ##括号中为该对象的父类，如果是object则表明是顶级类，没有父类have_feather = Trueway_of_reproduction = ‘egg’class Chicken(Bird): ###Chicken的父类是Bird，所以Chicken将会集成父类Bird的所有属性和动作way_of_move = ‘walk’possible_in_KFC = Truedef show_laugh(self):#self 用于内部的调用；参数传递时不会传递selfprint self.laughdef laugh_100th(self):for i in range(100):self.show_laugh() #通过self 调用了方法： show_laugh 特殊方法(特殊的方法特点是名称前后各有2个下划线（__）)：init_() 是一个特殊方法；如果在类中定义了这个方法，则在创建对象时，python会在对象创建后自动调用这个方法，完成对象创建后，会直接打印 ‘print ‘We are happy birds.’,more_words’ 12345class happyBird(Bird):def __init__(self,more_words):print &apos;We are happy birds.&apos;,more_wordssummer = happyBird(&apos;Happy,Happy!&apos;) 字典字典的创建1dic = &#123;&quot;key_a&quot;:&quot;value_1&quot;,&quot;key_b&quot;:&quot;value_1&quot;&#125; 或者先构建一个空字典，然后想字典中添加值； 12345dic=&#123;&#125; #构建一个空的字典；dic[&quot;key&quot;] = &quot;value&quot;for 循环默认遍历字典的keyfor i in dicprint i 字典的常用方法|示例命令|功能||-|-||print dic.keys() | 返回dic所有的键||print dic.values()| 返回dic所有的值||print dic.items()| 返回dic所有的元素（键值对）||dic.clear() | 清空dic，dict变为{}||del dic[“key”] | # 删除字典元素||print len(dic)| len查询元素总数|]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python 基础知识]]></title>
    <url>%2F2018%2F05%2F10%2FPython-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E5%B0%86%E8%84%9A%E6%9C%AC%E6%89%93%E5%8C%85%E5%88%B6%E4%BD%9C%E6%88%90%E5%8F%AF%E6%89%A7%E8%A1%8C%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[在支持PIP的情况下pip install pyinstaller安装 pyinstaller 后执行pyinstaller --version查看所安装的版本 pyinstaller : 打包可执行文件的主要命令，详细用法下面会介绍。 pyi-archive_viewer : 查看可执行包里面的文件列表。 pyi-bindepend : 查看可执行文件依赖的动态库（.so或.dll文件） pyi-... : 等等。 打包程序pyinstaller mycript.py然后会看到新增加了两个目录build和dist，dist下面的文件就是可以发布的可执行文件，对于上面的命令你会发现dist目录下面有一堆文件，各种都动态库文件和myscrip可执行文件。有时这样感觉比较麻烦，需要打包dist下面的所有东西才能发布，万一丢掉一个动态库就无法运行了，好在pyInstaller支持单文件模式，只需要执行： pyinstaller -F mycript.py 你会发现dist下面只有一个可执行文件，这个单文件就可以发布了，可以运行在你正在使用的操作系统类似的系统的下面。 可能问题 注意点12341.windows系统的版本和位数 （mac系统和linux 没有进行测试过）2.python3的版本和位数3.pyqt5的版本和位数 （如果pip安装，则位数同python3）4.pyinstaller的版本和位数（一般pip安装，无需考虑位数） 为程序添加图标运行出现cmd窗口取消cmd窗口弹出的参考方式如下： 方法一：pyinstaller -F mycode.py --noconsole 方法二：pyinstaller -F -w mycode.py （-w就是取消窗口） pyinstaller打成的包，可以在64位操作系统使用，无法在32位操作系统使用1234567坑的成因：python存在64位版本和32位版本。64位版本打成的包，只能在64位操作系统使用。32位版本打成的包，即可以在64位操作系统使用，也可以在32位操作系统使用。解决方案：重新安装32位版本的python，进行开发。 pyinstaller打成的包，可以在win7以上操作系统使用，无法在xp操作系统使用12345坑的成因：python3 从3.5版本开始，就已经不支持xp操作系统了。解决方案：重新安装3.4版本的python，进行开发。 pyqt5应用，开发运行时是正常，但pyinstaller打成的包，界面失真变丑。12345678坑的成因：pyinstaller 不支持最新版本的pyqt5。解决方案：重新安装低版本的pyqt5，进行开发。（当前推荐：5.8.2版本）命令pip uninstall pyqt5pip install pyqt5==5.8.2 pyqt5应用，开发运行时是正常，无法打包成功或打包成功但pyinstaller打成的包，无法运行，提示failed to execute script xxx。12345678坑的成因：（同坑3）pyinstaller 不支持最新版本的pyqt5。解决方案：（同坑3）重新安装低版本的pyqt5，进行开发。（当前推荐：5.8.2版本）命令pip uninstall pyqt5pip install pyqt5==5.8.2 pyqt5、pyqt5-tools 安装失败12345坑的成因：你的python3可能是最新版本，pyqt5、pyqt5-tools、pyqtchart还不支持最新版本的python3解决方案：重新安装低版本的python3，进行开发。（当前推荐：3.6.6版本） pyqtchart、pyqtdatavisualization 安装失败123456坑的成因：pyqtchart、pyqtdatavisualization对pyqt5的版本有依赖需求。解决方案：针对pyqt5的版本进行安装。命令如： pip install pyqtchart==5.8 打包中，部分包加载异常12]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两组数据差异显著性检验]]></title>
    <url>%2F2018%2F05%2F02%2F2018-05-02.%E4%B8%A4%E7%BB%84%E6%95%B0%E6%8D%AE%E5%B7%AE%E5%BC%82%E6%98%BE%E8%91%97%E6%80%A7%E6%A3%80%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[简述 1、如果两组数每组数的个数&lt;30，且已知方差服从正态分布，可以比较2组数的均值是否显著不同，用t检验； 2、如果两组数每组数的个数≥30，也可以比较2组数的均值是否显著不同，用z检验； 3、如果两组数每组数的分布未知，可以比较2组数是否显著性同分布，可以用非参数检验 Mann-Whitney U test进行； 4、如果两组数已知都服从正态分布，可以比较2组数的方差是否显著相同，用F检验； K-S检验K-S检验（Kolmogorov-Smirnov检验），K-S检验不仅能够检验单个总体是否服从某一理论分布，还能够检验两总体分布是否存在显著差异。其原假设是：两组独立样本来自的两总体的分布无显著差异。 K-S检验以变量的秩作为分析对象，检验两个独立样本群体，或者一个样本群体和一个特定标准分布之间的关系。K-S就是对两组数据的累积分布进行比较，寻找两个群体累积分布曲线之前的最大值作为D值。获得D值后，查表确定临界值。]]></content>
      <categories>
        <category>统计知识</category>
      </categories>
      <tags>
        <tag>显著性检验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NGS测序原理]]></title>
    <url>%2F2018%2F04%2F27%2F2018-04-27.NGS%E6%B5%8B%E5%BA%8F%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[# 参考资料： 百度文库 华大基因：知学云]]></content>
      <categories>
        <category>NGS</category>
        <category>原理</category>
      </categories>
      <tags>
        <tag>测序原理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客文章优化]]></title>
    <url>%2F2018%2F04%2F19%2Fhexo-%E6%89%A9%E5%B1%95%E5%8A%9F%E8%83%BD-%E6%96%87%E7%AB%A0%E6%B7%BB%E5%8A%A0%E6%8A%98%E5%8F%A0%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[博客文章添加折叠功能博客文章中，有些内容篇幅较大，但是可能对一部分读者来说，并不会特别关注，所以这些数据的展示，可能会直接导致整篇博文变得臃肿，而对另一部分读者，这部分详细的介绍却非常重要，因此不能简单的缩减博文，所以这个时候，针对文章中这部分篇幅较大的内容，增加折叠功能可以很好的解决这类问题。 在main.js中添加折叠jsnext主题的主要js位于 themes/next/source/js/src/post-details.js在里面找合适的位置，添加如下代码： 12345678$(document).ready(function()&#123; $(document).on(&apos;click&apos;, &apos;.fold_hider&apos;, function()&#123; $(&apos;&gt;.fold&apos;, this.parentNode).slideToggle(); $(&apos;&gt;:first&apos;, this).toggleClass(&apos;open&apos;); &#125;); //默认情况下折叠 $(&quot;div.fold&quot;).css(&quot;display&quot;,&quot;none&quot;);&#125;); 自定义内建标签在主题scripts下添加一个tags.js, 位于themes/next/scripts/tags.js 123456789101112131415161718192021222324/* @haohuawu 修复 Nunjucks 的 tag 里写 ```代码块```，最终都会渲染成 undefined 的问题 https://github.com/hexojs/hexo/issues/2400*/const rEscapeContent = /&lt;escape(?:[^&gt;]*)&gt;([\s\S]*?)&lt;\/escape&gt;/g;const placeholder = &apos;\uFFFD&apos;;const rPlaceholder = /(?:&lt;|&amp;lt;)\!--\uFFFD(\d+)--(?:&gt;|&amp;gt;)/g;const cache = [];function escapeContent(str) &#123; return &apos;&lt;!--&apos; + placeholder + (cache.push(str) - 1) + &apos;--&gt;&apos;;&#125;hexo.extend.filter.register(&apos;before_post_render&apos;, function(data) &#123; data.content = data.content.replace(rEscapeContent, function(match, content) &#123; return escapeContent(content); &#125;); return data;&#125;);hexo.extend.filter.register(&apos;after_post_render&apos;, function(data) &#123; data.content = data.content.replace(rPlaceholder, function() &#123; return cache[arguments[1]]; &#125;); return data;&#125;); 再继续添加一个themes/next/scripts/fold.js 12345678/* global hexo */// Usage: &#123;% fold ???? %&#125; Something &#123;% endfold %&#125;function fold (args, content) &#123; var text = args[0]; if(!text) text = &quot;点击显/隐&quot;; return &apos;&lt;div&gt;&lt;div class=&quot;fold_hider&quot;&gt;&lt;div class=&quot;close hider_title&quot;&gt;&apos; + text + &apos;&lt;/div&gt;&lt;/div&gt;&lt;div class=&quot;fold&quot;&gt;\n&apos; + hexo.render.renderSync(&#123;text: content, engine: &apos;markdown&apos;&#125;) + &apos;\n&lt;/div&gt;&lt;/div&gt;&apos;;&#125;hexo.extend.tag.register(&apos;fold&apos;, fold, &#123;ends: true&#125;); 最后，添加几个自定义样式，位置 themes/next/source/css/_custom/custom.styl 12345678910.hider_title&#123; font-family: &quot;Microsoft Yahei&quot;; cursor: pointer;&#125;.close:after&#123; content: &quot;▼&quot;;&#125;.open:after&#123; content: &quot;▲&quot;;&#125; 最后，在我们需要折叠的地方前后添加便签，示例用法： 折叠示例代码 123&#123;% fold 点击显/隐内容 %&#125;something you want to fold, include code block.&#123;% endfold %&#125; 参考博客 Hexo博文置顶（自定义排序）HEXO默认是按照时间顺序排一条线，然后按照时间顺序来决定显示的顺序的。按照网上的教程整理了一份方法。 使用的是top属性，top值越高，排序越在前，不设置top值得博文按照时间顺序排序。修改Hexo文件夹下的node_modules/hexo-generator-index/lib/generator.js 打开在最后添加如下javascript代码代码 12345678910111213posts.data = posts.data.sort(function(a, b) &#123;if(a.top &amp;&amp; b.top) &#123; // 两篇文章top都有定义 if(a.top == b.top) return b.date - a.date; // 若top值一样则按照文章日期降序排 else return b.top - a.top; // 否则按照top值降序排&#125;else if(a.top &amp;&amp; !b.top) &#123; // 以下是只有一篇文章top有定义，那么将有top的排在前面（这里用异或操作居然不行233） return -1;&#125;else if(!a.top &amp;&amp; b.top) &#123; return 1;&#125;else return b.date - a.date; // 都没定义按照文章日期降序排)&#125;; 更改以后，在写博客的时候，添加top属性就可以啦；]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[密钥设置实现免密码访问]]></title>
    <url>%2F2018%2F04%2F19%2F2018-04-19.%E5%AF%86%E9%92%A5%E8%AE%BE%E7%BD%AE%E5%AE%9E%E7%8E%B0%E5%85%8D%E5%AF%86%E7%A0%81%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[进行项目分析等工作，经常要链接服务器，登陆过程中总会需要我们输入密码，如果频率比较低，还好，但是每天的重复输入，总归会浪费我们大量的时间。另一方面部分工具或任务，可能不方便进行交互式的密码输入，因此通过使用密钥来实现免密码展现出较大的优势。 通过公钥与私钥创建公钥与私钥对在本地机器上运行 1ssh-keygen 将公钥复制到远程目录123ssh-copy-id -i ~/.ssh/id_rsa.pub remote-host# 会提示输入远程服务器的密码# 密码输入后，会将key写到远程机器的 ~/.ssh/authorized_key.文件中 配置完成进行测试1ssh remote-host 不需要输入密码即可登录到远程服务器 sshpass 工具先在机器A上安装 sshpass 工具，然后使用 12sshpass -p passwd ssh(scp) ** 或者 sshpass -f file ssh(scp) ** 其中 -p 直接指定密码，-f 则从文件中读取密码。]]></content>
      <categories>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R绘图-ggplot-箱线图绘制]]></title>
    <url>%2F2018%2F04%2F18%2FR-ggplot-%E7%AE%B1%E7%BA%BF%E5%9B%BE%E7%BB%98%E5%88%B6%2F</url>
    <content type="text"><![CDATA[数据处理过程中，好的数据展示，可以帮助我们更好的理解数据，发现数据之间的关系，记录下各种常见的绘图方式。 结果示例箱线图上方标注的为每个样品对应的中位数，可以根据需要进行调整。 绘图命令1Rscript ../ggplot_boxplot.R -i ggplot_boxplot.demo.data -o ggplot_boxplot.demo.data.png -X &quot;gene&quot; -Y &quot;depth&quot; 输入文件Demo数据 123456789101112131415161718192021222324252627282930313233Cluster Value IDKIT 0.85192541182175 1KIT 0.864711404642792 1KIT 1.12599180249189 1KIT 0.634586693569092 1KIT 1.16825284052483 1KIT 0.68284662568039 1KIT 0.579859358706082 1KIT 1.04258938018236 1KIT 0.753529870275851 1KIT 0.806402805442452 1KIT 0.951605801848777 1KIT 0.941741338875395 1KIT 0.880335826035274 1KIT 0.998844046813315 1。。。。BRCA1 1.20329612016347 2BRCA1 1.16319047052218 2BRCA1 0.779834117567836 2BRCA1 0.79095228570136 2BRCA1 0.835548863196455 2BRCA1 1.52532474830366 2BRCA1 1.13679352537476 2BRCA1 0.598936767501402 2BRCA1 1.1724422960551 2BRCA1 0.924227501396964 2BRCA1 0.691209808851361 2BRCA1 0.73454091210198 2。。 程序目录R脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107library(&apos;getopt&apos;);library (&apos;ggplot2&apos;)library(MASS)library(plyr)#-----------------------------------------------------------------# getting parameters#-----------------------------------------------------------------#get options, using the spec as defined by the enclosed list.#we read the options from the default: commandArgs(TRUE).spec = matrix(c( &apos;help&apos; , &apos;h&apos;, 0, &quot;logical&quot;, &apos;infile&apos; , &apos;i&apos;, 1, &quot;character&quot;, &apos;outfile&apos; , &apos;o&apos;, 1, &quot;character&quot;, &apos;title&apos; , &apos;T&apos; , 2 , &quot;character&quot;, &apos;x.lab&apos; , &apos;X&apos;, 2, &quot;character&quot;, &apos;y.lab&apos; , &apos;Y&apos;, 2, &quot;character&quot;, &apos;type&apos; , &apos;t&apos;, 2, &quot;character&quot; ), byrow=TRUE, ncol=4);opt = getopt(spec);# define usage functionprint_usage &lt;- function(spec=NULL)&#123; cat(getopt(spec, usage=TRUE)); cat(&quot;Usage example: \n&quot;) cat(&quot;Rscript ggplot_boxplot.R -i input_tab -o Demo_out -t png -X xtest -Y ytest -W 100 -H 100 infile format： Cluster Value ID Clus_A 0.51 1 Clus_A 0.31 1 . . . Clus_Z 0.42 21 Clus_Z 0.72 21Options: --help -h NULL get this help--infile -i character the input file [forced]--outfile -o character the prefix for output graph [forced]--title -T character the Title for the picture (default:Title)--x.lab -X character the lab for x in SubPlot (default:xlab)--y.lab -Y character the lab for y in SubPlot (default:ylab)--type -t character save format(png,tiff,jpeg,svg,pdf default:png)\n&quot;) q(status=1);&#125;# if help was asked for print a friendly message# and exit with a non-zero error codeif ( !is.null(opt$help) ) &#123; print_usage(spec) &#125;if ( is.null(opt$infile) ) &#123; print_usage(spec) &#125;if ( is.null(opt$outfile)) &#123; print_usage(spec) &#125;if ( is.null(opt$type) ) &#123; opt$type=&quot;png&quot; &#125;if ( is.null(opt$x.lab) ) &#123; opt$x.lab=&quot;xlab&quot; &#125;if ( is.null(opt$y.lab) ) &#123; opt$y.lab=&quot;ylab&quot; &#125;if ( is.null(opt$title) ) &#123; opt$title=&apos;Title&apos;&#125;Args &lt;- commandArgs();file_tab=read.table(opt$infile,header=F,sep=&quot;\t&quot;);out_file=paste(opt$outfile,opt$type,sep=&quot;.&quot;)if(opt$type == &quot;png&quot;) &#123; png(file=out_file) &#125; #, 400*length(file_tab[1,]) , 400*length(file_tab[,1])) &#125;if(opt$type == &quot;tiff&quot;) &#123;tiff(file=out_file) &#125; #, 400*length(file_tab[1,]) , 400*length(file_tab[,1])) &#125;if(opt$type == &quot;jpeg&quot;) &#123;jpeg(file=out_file) &#125; #, 400*length(file_tab[1,]) , 400*length(file_tab[,1])) &#125;if(opt$type == &quot;pdf&quot;) &#123; pdf(file=out_file) &#125; #, 20*length(file_tab[1,]) , 20*length(file_tab[,1])) &#125;data=read.table(opt$infile ,header=T)data2=ddply(data,&quot;Cluster&quot;,summarise,Median=round(median(Value),3))ggplot(data,aes(x=reorder(Cluster,Value),y=Value,fill=Cluster)) +geom_boxplot() +theme(panel.grid.major =element_blank(), panel.grid.minor = element_blank(), panel.background = element_blank(), axis.line = element_line(colour = &quot;black&quot;),axis.title.x=element_text(size=25), axis.title.y =element_text(size=25), title=element_text(size=25), axis.text.x=element_text(angle=30,hjust=1,size=15))+ #设置x轴，数据标签的样式labs(x=opt$x.lab ,y=opt$y.lab) + # 设置x轴和y轴现实的标注geom_text(data=data2,aes(x=Cluster,y=2.5,colour=Cluster,label=Median,vjust=-0.2)) + # 在y=2.5的位置添加标签批注coord_cartesian(ylim=c(0,3)) # 对绘制的图片 根据x轴和y轴进行截取#####ggplot(data,aes(x=reorder(Cluster,Value),y=Value,fill=Cluster)) +### 绘图类型 ####geom_boxplot() + # 绘制箱线图### 样式 ####theme(panel.grid.major =element_blank(), # 去除主网格线#panel.grid.minor = element_blank(), #去除次网格线#panel.background = element_blank(), #去除背景色（默认为灰色）#axis.line = element_line(colour = &quot;black&quot;)，#将x轴和y轴的框线设置为黑色#axis.title.x=element_text(size=25), #设置x轴的标题样式#axis.title.y =element_text(size=25), #设置y轴的标题样式#title=element_text(size=25), #设置主标题样式#axis.text.x=element_text(angle=30,hjust=1,size=15)) + #设置x轴，数据标签的样式### 设置坐标轴标注 ####labs(x=opt$x.lab ,y=opt$y.lab) + # 设置x轴和y轴现实的标注### 添加标签 ####geom_text(data=data2,aes(x=Cluster,y=2.5,colour=Cluster,label=Median,vjust=-0.2)) + # 在y=2.5的位置添加标签批注### 对图片进行截取 ####coord_cartesian(ylim=c(0,3)) # 对绘制的图片 根据x轴和y轴进行截取dev.off()]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux配置文件~/.bashrc设置]]></title>
    <url>%2F2018%2F04%2F13%2FLinux-%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6-bashrc%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[常见配置https://blog.csdn.net/bangemantou/article/details/7682272 ## 相关问题~/.bashrc不能自动source最近更换了一个集群，更改了配置文件，却发现每次登陆都需要手动source，~/.bashrc不能自动执行，表示手动用了几次，发现每次这样简直不能忍～。查了一些资料来解决这个问题。 缺少~/.bash_profile创建 ~/.bash_profile 文件，并在文件开始位置添加如下内容：。 12345# .bash_profile# Get the aliases and functionsif [ -f ~/.bashrc ]; then . ~/.bashrcfi]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Bash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BASH的基本语法]]></title>
    <url>%2F2018%2F04%2F13%2FLinux-BASH%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[参考资料 之前更多的是直接使用Linux命令组合，对shell命令的使用比较少，都是有需求临时百度，没有系统的了解过，趁此机会，系统了解一下bash。 目录 最简单的例子 —— Hello World! 关于输入、输出和错误输出 BASH 中对变量的规定（与 C 语言的异同） BASH 中的基本流程控制语法 函数的使用 1.最简单的例子 —— Hello World!几乎所有的讲解编程的书给读者的第一个例子都是 Hello World 程序，那么我们今天也就从这个例子出发，来逐步了解 BASH。 用 vi 编辑器编辑一个 hello 文件如下： 123#!/bin/bash #第一行说明文件的类型，Linux系统根据 &quot;#!&quot; 及该字串后面的信息确定该文件的类型# This is a very simple example #在 BASH 程序中从“#”号（注意：后面紧接着是“!”号的除外）开始到行尾的多有部分均被看作是程序的注释。echo Hello World #bash的执行命令 如何执行该程序呢？有两种方法：一种是显式制定 BASH 去执行： bash hello或sh hello （这里 sh 是指向 bash 的一个链接，“lrwxrwxrwx 1 root root 4 Aug 20 05:41 /bin/sh -&gt; bash”） 或者可以先将 hello 文件改为可以执行的文件，然后直接运行它，此时由于 hello 文件第一行的 “#! /bin/bash” 的作用，系统会自动用/bin/bash 程序去解释执行 hello 文件的： 123#! bashchmod +x hello./hello 此处没有直接 “$ hello”是因为当前目录不是当前用户可执行文件的默认目录，而将当前目录“.”设为默认目录是一个不安全的设置。 需要注意的是，BASH 程序被执行后，实际上 Linux 系统是另外开设了一个进程来运行的。 2. 关于输入、输出和错误输出在 Linux 系统中：标准输入(stdin)默认为键盘输入；标准输出(stdout)默认为屏幕输出；标准错误输出(stderr)默认也是输出到屏幕（上面的 std 表示 standard）。在 BASH 中使用这些概念时一般将标准输出表示为 1，将标准错误输出表示为 2。 12345# 不常用的方法n&lt;&amp;- #表示将 n 号输入关闭 &lt;&amp;- #表示关闭标准输入（键盘）n&gt;&amp;- #表示将 n 号输出关闭&gt;&amp;- #表示将标准输出关闭 33. BASH 中对变量的规定BASH 中的变量都是不能含有保留字，不能含有 “-“ 等保留字符，也不能含有空格。 简单变量在 BASH 中变量定义是不需要的，没有 “int i” 这样的定义过程。如果想用一个变量，只要他没有在前面被定义过，就直接可以用，当然你使用该变量的第一条语句应该是对他赋初值了，如果你不赋初值也没关 系，只不过该变量是空（ 注意：是 NULL，不是 0 ）。不给变量赋初值虽然语法上不反对，但不是一个好的编程习惯。好了我们看看下面的例子：]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Bash</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[samtools-安装]]></title>
    <url>%2F2018%2F04%2F09%2FSoftware-samtools-%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[环境配置 12345#报错缺少时 curses.h: No such file or directoryyum install ncurses-devel ncurses#报错缺少时 bzlib.h: No such file or directoryyum install bzip2-devel.x86_64 软件安装1234567wget -c https://github.com/samtools/samtools/releases/download/1.9/samtools-1.9.tar.bz2tar xvf samtools-1.9.tar.bz2cd samtools-1.9/./configure --prefix=~/biosoft/samtools-1.9makemake install]]></content>
      <categories>
        <category>NGS</category>
        <category>software</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>软件安装</tag>
        <tag>环境配置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R安装]]></title>
    <url>%2F2018%2F04%2F09%2FR-%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[R，作为数据计算和统计的经典工具，很多行业的数据分析和挖掘都跟它息息相关。熟悉R，对传统行业的数据的体量和分析会有一个初步的认识。了解R，我们先从安装它开始。Windows和Mac下有专门的安装程序，可以从https://www.r-project.org/， 可以直接安装。Linux下也可以通过相应的yum或者apt-get进行安装。然而，有些情况下，如Linux软件中心带的R程序如果太old，无法与其它的程序比如Scala或者Java兼容，则需要手工编译源码进行安装。这种繁琐的环节最好不要遇上，否则会比较��，此文用来纪念这个过程。R程序本身有很多依赖，建议参考本文先把依赖都装上去，然后再build R源程序。或者也可以直接编译R源代码，需要什么依赖安装什么依赖。 yum install -y readline-devel gcc*yum install libXt-devel -y 1.zlibwget http://ncu.dl.sourceforge.net/project/libpng/zlib/1.2.8/zlib-1.2.8.tar.gztar -zxvf zlib-1.2.8.tar.gzcd zlib-1.2.8./configure –prefix=/opt/zlib-1.2.8make &amp;&amp; make install 2.bzipwget http://www.bzip.org/1.0.6/bzip2-1.0.6.tar.gztar -zxvf bzip2-1.0.6.tar.gzcd bzip2-1.0.6make -f Makefile-libbz2_somake cleanmakemake install PREFIX=/opt/bzip2-1.0.6cd /opt/ 3. xzwget http://tukaani.org/xz/xz-5.2.2.tar.gztar xzvf xz-5.2.2.tar.gzcd xz-5.2.2./configure –prefix=/opt/xz-5.2.2make -j3 &amp; make install 4. pcrewget http://fossies.org/linux/misc/pcre-8.39.tar.gztar -zxvf pcre-8.39.tar.gzcd pcre-8.39./configure –prefix=/opt/pcre-8.39 –enable-utf8make &amp; make install 5. openssl(不是必须的，如果机子上已经安装则可以跳过)yum install openssl* 6. CURLwget http://www.execve.net/curl/curl-7.50.1.tar.gztar zxvf curl-7.50.1.tar.gzcd curl-7.50.1./configure —prefix=/opt/curl-7.50.1make &amp;&amp; make install 7.更新链接lib库和PATH路径echo /opt/xz-5.2.2/lib &gt;&gt; /etc/ld.so.confecho /opt/pcre-8.39/lib &gt;&gt; /etc/ld.so.confecho ‘export PATH=/opt/R-3.3.1/bin:${PATH}:/opt/curl-7.50.1/bin’ &gt;&gt; /root/.bashrcsource /root/.bashrc 8. 安装R程序wget http://mirrors.xmu.edu.cn/CRAN/src/base/R-3/R-3.3.1.tar.gztar -zxvf R-3.3.1.tar.gzcd R-3.3.1./configure –prefix=/opt/R-3.3.1 –enable-R-shlib LDFLAGS=”-L/opt/zlib-1.2.8/lib -L/opt/bzip2-1.0.6/lib -L/opt/xz-5.2.2/lib -L/opt/pcre-8.39/lib -L/opt/curl-7.50.1/lib” CPPFLAGS=”-I/opt/zlib-1.2.8/include -I/opt/bzip2-1.0.6/include -I/opt/xz-5.2.2/include -I/opt/pcre-8.39/include -I/opt/curl-7.50.1/include”ldconfigmaketouch doc/NEWS.pdf（Install R的过程中，遇到了一个NEWS.pdf找不到，用这个办法绕过的）make install 安装成功后，可以通过以下办法进行测试。root@cu01 R-3.3.1]# lsbin include lib lib64 share[root@cu01 R-3.3.1]# R R version 3.3.1 (2016-06-21) – “Bug in Your Hair”Copyright (C) 2016 The R Foundation for Statistical ComputingPlatform: x86_64-pc-linux-gnu (64-bit) R是自由软件，不带任何担保。在某些条件下你可以将其自由散布。用’license()’或’licence()’来看散布的详细条件。 R是个合作计划，有许多人为之做出了贡献.用’contributors()’来看合作者的详细情况用’citation()’会告诉你如何在出版物中正确地引用R或R程序包。 用’demo()’来看一些示范程序，用’help()’来阅读在线帮助文件，或用’help.start()’通过HTML浏览器来看帮助文件。用’q()’退出R.]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>R</category>
        <category>环境配置</category>
      </categories>
      <tags>
        <tag>R</tag>
        <tag>软件安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GATK4初探 - 1]]></title>
    <url>%2F2018%2F04%2F09%2FSoftware-GATK4%E5%88%9D%E6%8E%A2-1%2F</url>
    <content type="text"><![CDATA[germline somatic detail GATK4 简介；参考地址WorkflowWDL语法Best Practices GATK4.0的改动 Re-engineered for speed、 scalability and versatillity Expanded scope of analysis to more variant types Reproducible best practices worlflowsGATK4。0 协议Under BSD3.0 streamlined arhciecture（overall efficlency）Intel Genomics Kernel Library （speed）Intel GenomicsDB （scalability）Apache Spark support（robust parallelism）Google Dataproc and GCS support（cloud execution）Versatility of data traversal （analysis scpe） 变异检出Geretic changes in individuals relative to a reference genome Germline（inherited） Somatic（cancer） Reference genome= a standardized genomic sequenceHuman genome reference sequence Previous standard hg19/b37 New sandard ： hg38 变异检出造成干扰的原因： 噪音、污染、纯度、 GATK4 对应不同变异检出的程序： Germline SOMATIC SNPs&amp;Indel HaplotypeCaller GVCF MuTect2 CNV GATK gCNV（beta） GATK CNV +aCNV Structure GATK SVDiscovery（beta） Planned GATK bestPractices 单样本变异检出算法 Mutect 支持但样本的SNV检出（假阳性多） GATK workflowsGithub流程Script使用WDL编写 变异检测过程；Step1 Identify ActiveRegions]]></content>
      <categories>
        <category>NGS</category>
        <category>software</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>变异检测</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Software-MANTIS调研]]></title>
    <url>%2F2018%2F04%2F09%2FSoftware-MANTIS%E8%B0%83%E7%A0%94%2F</url>
    <content type="text"><![CDATA[简介MANTIS (Microsatellite Analysis for Normal-Tumor InStability) 是一个从成对的BAM文件中检测微卫星不稳定性的程序。 为了进行分析，程序需要一个肿瘤BAM和一个匹配的正常BAM文件(使用相同的管道生成)来确定两个样本之间的不稳定性得分。 推荐使用较长的读数(理想情况下，100bp或更长)，因为较短的读数不太可能完全覆盖微卫星位点，并且在质量控制过滤器失败后将被丢弃。MANTIS 于2017年发表在Oncotarget ( Performance evaluation for rapid detection of pan-cancer microsatellite instability with MANTIS) 如果需要使用该软件，可以通过Github 进行获取。 软件使用软件的安装安装软件的依赖包该软件是基于Python开发的，软件的运行需要安装下列Python库 NumPy(v1.6.2) Pysam(v0.8.3) 使用方法天津集群安装，conda环境调试成功使用环境Manti （先执行命令 source activate Manti）在模拟环境中进行分析，测试命令：1234python /share/udata/liubo/Software/MANTIS-master/mantis.py -b loci.bed --genome hg19.fa -n normal.bam -t cancer.bam -o MANTIS.txt --threads 8 # threads设置软件运行的线程数。 参考基因组和bed文件，可以使用配置未见的方式存储到配置文件中。引用配置文件使用 -cfg 参数。123#配置文件格式genome = /path/to/reference/genome.fastabedfile = /path/to/my/loci.bed 软件原理 阅读bed文件，获得目标区域，然后根据基因组信息，把这些靶标位点比对到参考基因组上，建立索引（通过0和1）； 每次针对一个靶标区域，工具首先从normal和cancer样本比对后的bam文件中抽提覆盖这个区域的reads，然后对这些reads进行一个初步的质控过滤，其中过滤标准如下： 1.确保这些reads都达到了合格满意的序列长度,默认：35（参数：mrl） 2.每个base的平均质量值得分达到要求的最小值，默认：25（参数：mrq） 3.覆盖的整个的靶标区域。 对通过初步过滤的reads单独进行分析，检测微卫星结构的起始位点，以及总的重复次数（通过起始位点开始，匹配微卫星结构的匹配次数） 一旦确定了微卫星的repeat次数以后，对数据进行第二次的质控， 1.确定在reads序列末端前loci没有被打断。 2.确定微卫星区域中的每个base的平均质量值都比较高，且达到标准，默认：30（mlq） 针对tumor和normal文件，分别统计不同的repeat counts的reads支持数，获得每个靶标区域的结构重复的reads支持数,reads支持数过低的repeat count 会被移除，默认：3（mrr） 确定repeat counts数以后，对每个靶标区域进行质控。将重复序列长度中偏离标准值过大的repeat count数移除，默认3倍标准差（参数sd ） ，会进行移除。 然后针对normal和cancer，检查每个靶标的总reads数目，确保reads的数目足够获得一个统计学显著的分布，达不到标准的loci会被丢弃。默认：30（mlc） 利用最终剩下的repeat count数据，进行得分计算，获得每个样本的一个不稳定得分。计算方法每个loci单独计算，分别对normal和cancer进行标准化（利用样本在loci的总reads数，将每个repeat的reads支持数，标准化为一个分数，从而量化在两个样本在深度和覆盖度上的差异），根据标准化的reads count计算stepwise： 一旦每个区域的得分计算出来以后，所有区域的不稳定性得分的平局值就可以计算得到，从而用一个数值来反映样本的不稳定程度。（得分范围是,值越大，越不稳定，值越小越稳定）]]></content>
      <categories>
        <category>NGS</category>
        <category>software</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>MSI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蜜蜂群图绘制]]></title>
    <url>%2F2018%2F04%2F08%2FR-%E8%9C%9C%E8%9C%82%E7%BE%A4%E5%9B%BE%E7%BB%98%E5%88%B6%2F</url>
    <content type="text"><![CDATA[输出结果 绘图命令1bee_plot_with_color(&quot;../../Desktop/seqencing depth.csv&quot;,&quot;xlab&quot;,&quot;ylab&quot;) 函数代码函数代码 12345678910111213141516171819202122bee_plot_with_color=function(In_file,xlab_text,ylab_text)&#123;library(beeswarm)read.csv(In_file,header=F)-&gt;a#biocLite(c(&quot;beeswarm&quot;,&quot;ggplot2&quot;))label_tag=a[1,]label_tag=as.matrix(label_tag)a=a[-1,]ncol(a)-&gt;num1mat=c()for(i in 1:num1)&#123;as.numeric(as.matrix(a[,i]))-&gt;temptemp[!is.na(temp)]-&gt;templength(temp)-&gt;numrep(i,num)-&gt;label_temprbind(mat,cbind(temp,label_temp))-&gt;mat&#125;beeswarm(mat[,1]~mat[,2], pch = 1,col = rainbow(10),labels=label_tag ,xlab=xlab_text , ylab=ylab_text)#pch对应的不同数值可以调整散点图中点的样式；boxplot(mat[,1]~mat[,2],add=T,names=label_tag)-&gt;S&#125; 输入文件：每列对应一类数据，head行，对应类的名称，下面每行是该类的具体数据，最终针对每类数据绘制对应的散点图和4分位图。demo数据]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件格式说明 - SAM/BAM]]></title>
    <url>%2F2018%2F04%2F06%2F2018-04-06.%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E-SAM.BAM%2F</url>
    <content type="text"><![CDATA[Sam 格式文献Sam 格式博客Sam 格式说明 Bam 头文件头文件是一行行以 @ 开头的注释文件，文件记录了比对是所用的参考序列信息，序列的名称和序列的长度（@SQ），同时也记录了比对、Markdup、重比对等过程所使用的软件以及对应的软件版本（@PG），同时还会有记录的样本信息（@RG）；如果有需要更改样本的头文件，可以通过Samtools rehead# 定义一个新的头文件，来替代原来的头文件. Bam头文件示例 Bam 头文件：123456789101112@HD VN:1.0 GO:none SO:coordinate@SQ SN:chr1 LN:249250621@SQ SN:chr2 LN:243199373@SQ SN:chr3 LN:198022430@SQ SN:chr4 LN:191154276@SQ SN:chr5 LN:180915260@SQ SN:chr6 LN:171115067@SQ SN:chr7 LN:159138663@RG ID:cancer PL:illumina PU:FCHF3HCBCX2 LB:17D0846999-98 SM:cancer CN:BGI@PG ID:MarkDuplicates PN:MarkDuplicates VN:1.98(1547) CL:net.sf.picard.sam.MarkDuplicates INPUT=[/THL4/home/bgi_thcancer/liubo/Project/BRAC_CY/2018-05-29/17D0846999-98/cancer/3_markdup_bam/17D0846999-98_sort.bam] OUTPUT=/THL4/home/bgi_thcancer/liubo/Project/BRAC_CY/2018-05-29/17D0846999-98/cancer/3_markdup_bam/17D0846999-98_sort_markdup.bam METRICS_FILE=/THL4/home/bgi_thcancer/liubo/Project/BRAC_CY/2018-05-29/17D0846999-98/cancer/3_markdup_bam/17D0846999-98_sort_markdup.bam.metrics REMOVE_DUPLICATES=false ASSUME_SORTED=true VALIDATION_STRINGENCY=LENIENT PROGRAM_RECORD_ID=MarkDuplicates PROGRAM_GROUP_NAME=MarkDuplicates MAX_SEQUENCES_FOR_DISK_READ_ENDS_MAP=50000 MAX_FILE_HANDLES_FOR_READ_ENDS_MAP=8000 SORTING_COLLECTION_SIZE_RATIO=0.25 READ_NAME_REGEX=[a-zA-Z0-9]+:[0-9]:([0-9]+):([0-9]+):([0-9]+).* OPTICAL_DUPLICATE_PIXEL_DISTANCE=100 VERBOSITY=INFO QUIET=false COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false@PG ID:bwa PN:bwa VN:0.6.2-r126@PG ID:GATK IndelRealigner VN:2.3-9-ge5ebf34 CL:knownAlleles=[(RodBinding name=knownAlleles source=/THL4/home/bgi_thcancer/pipeline/chip_1.7M/db/aln/dbsnp/dbSNP132_1000GIndel_merge_for_realgn.txt)] targetIntervals=/THL4/home/bgi_thcancer/liubo/Project/BRAC_CY/2018-05-29/17D0846999-98/cancer/4_realign_bam/17D0846999-98_cancer.intervals LODThresholdForCleaning=5.0 consensusDeterminationModel=USE_READS entropyThreshold=0.15 maxReadsInMemory=150000 maxIsizeForMovement=3000 maxPositionalMoveAllowed=200 maxConsensuses=30 maxReadsForConsensuses=120 maxReadsForRealignment=20000 noOriginalAlignmentTags=false nWayOut=null generate_nWayOut_md5s=false check_early=false noPGTag=false keepPGTags=false indelsFileForDebugging=null statisticsFileForDebugging=null SNPsFileForDebugging=null Bam 内容部分Bam 的内容部分，包含了所有序列的比对信息，包括比对位置，比对质量值查看方式 samtools view ;在Bam/Sam输出的结果中每一行都包括十二项通过Tab分隔，从左到右分别是： 序列的名称 概括出一个合适的标记，各个数字分别代表 1 read是pair中的一条（read表示本条read，mate表示pair中的另一条read） 2 pair一正一负完美的比对上 4 这条read没有比对上 8mate没有比对上 16 这条read反向比对 32mate反向比对 64这条read是read1 128这条read是read2 256第二次比对 512比对质量不合格 1024read是PCR或光学副本产生 2048辅助比对结果 假如说标记为以上列举出的数目，就可以直接推断出匹配的情况。假如说标记不是以上列举出的数字，比如说 83=（64+16+2+1），就是这几种情况值和。 参考序列的名字 在参考序列上的位置 mapping qulity?? 越高则位点越独特bowtie2有时并不能完全确定一个短的序列来自与参考序列的那个位置，特别是对于那些比较简单的序列。但是bowtie2会给出一个值来显示出 这个段序列来自某个位点的概率值，这个值就是mapping qulity。Mapping qulity的计算方法是：Q=-10log10p，Q是一个非负值，p是这个序列不来自这个位点的估计值。假如说一条序列在某个参考序列上找到了两个位点，但是其中一个位点的Q明显大于另一个位点的Q值，这条序列来源于前一个位点的可能性就比较大。Q值的差距越大，这独特性越高。Q值的计算方法来自与SAM标准格式，请查看SAM总结。 代表比对结果的CIGAR字符串，如37M1D2M1I，这段字符的意思是37个匹配，1个参考序列上的删除，2个匹配，1个参考序列上的插入。M代表的是alignment match(可以是错配) “M”表示 match或 mismatch； “I”表示 insert； “D”表示 deletion； “N”表示 skipped（跳过这段区域）； “S”表示 soft clipping（被剪切的序列存在于序列中）； “H”表示 hard clipping（被剪切的序列不存在于序列中）； “P”表示 padding； “=”表示 match； “X”表示 mismatch（错配，位置是一一对应的）； mate 序列所在参考序列的名称 mate 序列在参考序列上的位置 估计出的片段的长度，当mate 序列位于本序列上游时该值为负值。 read的序列 ASCII码格式的序列质量 可选的区域 AS:i? 匹配的得分 XS:i? 第二好的匹配的得分 YS:i? mate 序列匹配的得分 XN:i? 在参考序列上模糊碱基的个数 XM:i? 错配的个数 XO:i? gap open的个数 XG:i? gap 延伸的个数 NM:i? 经过编辑的序列 YF:i? 说明为什么这个序列被过滤的字符串 YT:Z MD:Z? 代表序列和参考序列错配的字符串]]></content>
      <categories>
        <category>知识沉淀</category>
        <category>文件格式</category>
      </categories>
      <tags>
        <tag>Bam</tag>
        <tag>Sam</tag>
        <tag>文件格式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件格式说明 - Vcf]]></title>
    <url>%2F2018%2F04%2F06%2F2018-04-16.%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E-vcf%2F</url>
    <content type="text"><![CDATA[简介VCF (Variant Call Format) version 4.1The VCF specification is no longer maintained by the 1000 Genomes Project. The group leading the management and expansion of the format is the Global Alliance for Genomics and Health Data Working group file format team, http://ga4gh.org/#/fileformats-teamThe main version of the specification can be found on https://github.com/samtools/hts-specsThis is under continued development, please check the hts-specs page for the most recent specification A PDF of the v4.1 spec is http://samtools.github.io/hts-specs/VCFv4.1.pdfA PDF of the v4.2 spec is http://samtools.github.io/hts-specs/VCFv4.2.pdfVCFTools host a discussion list about the specification called vcf-spec http://sourceforge.net/p/vcftools/mailman/ REF:http://blog.sina.com.cn/s/blog_12d5e3d3c0101qv1u.htmlhttp://samtools.github.io/hts-specs/VCFv4.2.pdfhttp://samtools.github.io/bcftools/bcftools.html VCF（Variant Call Format）文件示例（VCFv4.2）123456789101112131415161718192021222324##fileformat=VCFv4.2##fileDate=20090805##source=myImputationProgramV3.1##reference=file:///seq/references/1000GenomesPilot-NCBI36.fasta##contig=&lt;ID=20,length=62435964,assembly=B36,md5=f126cdf8a6e0c7f379d618ff66beb2da,species=&quot;Homo sapiens&quot;,taxonomy=x&gt;##phasing=partial##INFO=&lt;ID=NS,Number=1,Type=Integer,Description=&quot;Number of Samples With Data&quot;&gt;##INFO=&lt;ID=DP,Number=1,Type=Integer,Description=&quot;Total Depth&quot;&gt;##INFO=&lt;ID=AF,Number=A,Type=Float,Description=&quot;Allele Frequency&quot;&gt;##INFO=&lt;ID=AA,Number=1,Type=String,Description=&quot;Ancestral Allele&quot;&gt;##INFO=&lt;ID=DB,Number=0,Type=Flag,Description=&quot;dbSNP membership, build 129&quot;&gt;##INFO=&lt;ID=H2,Number=0,Type=Flag,Description=&quot;HapMap2 membership&quot;&gt;##FILTER=&lt;ID=q10,Description=&quot;Quality below 10&quot;&gt;##FILTER=&lt;ID=s50,Description=&quot;Less than 50% of samples have data&quot;&gt;##FORMAT=&lt;ID=GT,Number=1,Type=String,Description=&quot;Genotype&quot;&gt;##FORMAT=&lt;ID=GQ,Number=1,Type=Integer,Description=&quot;Genotype Quality&quot;&gt;##FORMAT=&lt;ID=DP,Number=1,Type=Integer,Description=&quot;Read Depth&quot;&gt;##FORMAT=&lt;ID=HQ,Number=2,Type=Integer,Description=&quot;Haplotype Quality&quot;&gt;#CHROM POS ID REF ALT QUAL FILTER INFO FORMAT NA00001 NA00002 NA0000320 14370 rs6054257 G A 29 PASS NS=3;DP=14;AF=0.5;DB;H2 GT:GQ:DP:HQ 0|0:48:1:51,51 1|0:48:8:51,51 1/1:43:5:.,.20 17330 . T A 3 q10 NS=3;DP=11;AF=0.017 GT:GQ:DP:HQ 0|0:49:3:58,50 0|1:3:5:65,3 0/0:41:320 1110696 rs6040355 A G,T 67 PASS NS=2;DP=10;AF=0.333,0.667;AA=T;DB GT:GQ:DP:HQ 1|2:21:6:23,27 2|1:2:0:18,2 2/2:35:420 1230237 . T . 47 PASS NS=3;DP=13;AA=T GT:GQ:DP:HQ 0|0:54:7:56,60 0|0:48:4:51,51 0/0:61:220 1234567 microsat1 GTC G,GTCT 50 PASS NS=3;DP=9;AA=G GT:GQ:DP 0/1:35:4 0/2:17:2 1/1:40:3 其中每列对应的含义 title 含义 CHROM： 表示变异位点是在哪个contig 里call出来的，如果是人类全基因组的话那就是chr1…chr22，chrX,Y,M。 POS： 参考基因组位置，第一个碱基的位置是1。按数字升序排列，允许有多条记录有相同的位置。变异位点相对于参考基因组所在的位置，如果是indel，就是第一个碱基所在的位置。 ID： 如果call出来的SNP存在于dbSNP数据库里，就会显示相应的dbSNP里的rs编号。 REF和REF： 在这个变异位点处，参考基因组中所对应的碱基和研究对象基因组中所对应的碱基。 QUAL： 可以理解为所call出来的变异位点的质量值。Q=-10lgP，Q表示质量值；P表示这个位点发生错误的概率。因此，如果想把错误率从控制在90%以上，P的阈值就是1/10，那lg（1/10）=-1，Q=（-10）*（-1）=10。同理，当Q=20时，错误率就控制在了0.01。 FILTER： 理想情况下，QUAL这个值应该是用所有的错误模型算出来的，这个值就可以代表正确的变异位点了，但是事实是做不到的。因此，还需要对原始变异位点做进一步的过滤。无论你用什么方法对变异位点进行过滤，过滤完了之后，在FILTER一栏都会留下过滤记录，如果是通过了过滤标准，那么这些通过标准的好的变异位点的FILTER一栏就会注释一个PASS，如果没有通过过滤，就会在FILTER这一栏提示除了PASS的其他信息。如果这一栏是一个“.”的话，就说明没有进行过任何过滤。 到现在，我们就可以解释上面的例子：chr1：873762 是一个新发现的T/G变异，并且有很高的可信度（qual=5231.78）。chr1：877664 是一个已知的变异为A/G 的SNP位点，名字rs3828047，并且具有很高的可信度（qual=3931.66）。chr1：899282 是一个已知的变异为C/T的SNP位点，名字rs28548431，但可信度较低（qual=71.77）。chr1：974165 是一个已知的变异为T/C的SNP位点，名字rs9442391，但是这个位点的质量值很低，被标 成了“LowQual”，在后续分析中可以被过滤掉。 其中最后面两列是相对应的，每一个tag对应一个或者一组值，如：chr1：873762，GT对应0/1；AD对应173,141；DP对应282；GQ对应99；PL对应255,0,255。 GT： 表示这个样本的基因型，对于一个二倍体生物，GT值表示的是这个样本在这个位点所携带的两个等位基因。0表示跟REF一样；1表示表示跟ALT一样；2表示第二个ALT。当只有一个ALT 等位基因的时候，0/0表示纯和且跟REF一致；0/1表示杂合，两个allele一个是ALT一个是REF；1/1表示纯和且都为ALT； The most common format subfield is GT (genotype) data. If the GT subfield is present, it must be the first subfield. In the sample data, genotype alleles are numeric: the REF allele is 0, the first ALT allele is 1, and so on. The allele separator is ‘/‘ for unphased genotypes and ‘|’ for phased genotypes.0 - reference call1 - alternative call 12 - alternative call 2AD： 对应两个以逗号隔开的值，这两个值分别表示覆盖到REF和ALT碱基的reads数，相当于支持REF和支持ALT的测序深度。DP： 覆盖到这个位点的总的reads数量，相当于这个位点的深度（并不是多有的reads数量，而是大概一定质量值要求的reads数）。PL: 对应3个以逗号隔开的值，这三个值分别表示该位点基因型是0/0，0/1，1/1的没经过先验的标准化Phred-scaled似然值（L）。如果转换成支持该基因型概率（P）的话，由于L=-10lgP，那么P=10^（-L/10），因此，当L值为0时，P=10^0=1。因此，这个值越小，支持概率就越大，也就是说是这个基因型的可能性越大。GQ： 表示最可能的基因型的质量值。表示的意义同QUAL。 举个例子说明一下：chr1 899282 rs28548431 C T [CLIPPED] GT:AD:DP:GQ:PL 0/1:1,3:4:25.92:103,0,26在这个位点，GT=0/1，也就是说这个位点的基因型是C/T；GQ=25.92，质量值并不算太高，可能是因为cover到这个位点的reads数太少，DP=4，也就是说只有4条reads支持这个地方的变异；AD=1,3，也就是说支持REF的read有一条，支持ALT的有3条；在PL里，这个位点基因型的不确定性就表现的更突出了，0/1的PL值为0，虽然支持0/1的概率很高；但是1/1的PL值只有26，也就是说还有10^(-2.6)=0.25%的可能性是1/1；但几乎不可能是0/0，因为支持0/0的概率只有10^(-10.3)=5*10-11。 各个版本的vcf之间的差异v4.1 -&gt; v4.2 的变动特征]]></content>
      <categories>
        <category>知识沉淀</category>
        <category>文件格式</category>
      </categories>
      <tags>
        <tag>文件格式</tag>
        <tag>Vcf</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[文件格式说明 - Bed]]></title>
    <url>%2F2018%2F04%2F06%2F2022-01-26.%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%E8%AF%B4%E6%98%8E-bed%2F</url>
    <content type="text"><![CDATA[定义Browser Extensible Data (BED) is a whitespace-delimited file format, where each file consists of one or more lines Each line describes discrete genomic features by physical start and end position on a linear chromosome. The file extension for the BED format is .bed. 官方文档 格式说明格式概览一个完整的bed文件包含如下的12列信息(可以通过标注bedn只使用其中的前n列信息) Col Field Type Regex or range Brief description 1 chrom String [[:alnum:]_]{1,255} Chromosome name 2 chromStart Int [0, 264 − 1] Feature start position 3 chromEnd Int [0, 264 − 1] Feature end position 4 name String [^\t]{0,255} Feature description 5 score Int [0, 1000] A numerical value 6 strand String [-+.] Feature strand 7 thickStart Int [0, 264 − 1] Thick start position 8 thickEnd Int [0, 264 − 1] Thick end position 9 itemRgb Int,Int,Int ([0, 255], [0, 255], [0, 255]) \ 0 Display color 10 blockCount Int [0, chromEnd − chromStart]5 Number of blocks 11 blockSizes List[Int] ([[:digit:]]+,){blockCount−1}[[:digit:]]+,?6 Block sizes 12 blockStarts List[Int] ([[:digit:]]+,){blockCount−1}[[:digit:]]+,? Block start positions 各列内容的详细介绍如下： 坐标(Coordinates) chrom: The name of the chromosome or scaffold where the feature is present. Limitingonly to word characters only, instead of all non-whitespace characters, makes BED filesmore portable to varying environments which may make different assumptions about allowedcharacters. The name must be between 1 and 255 characters long, inclusive. chromStart: Start position of the feature on the chromosome or scaffold. chromStart must bean integer greater than or equal to 0 and less than the total number of bases of the chromo-some to which it belongs. If the size of the chromoschromosomeome is unknown, then chromStart mustbe less than or equal to $2^{64}$ − 1, which is the maximum size of an unsigned 64-bit integer. chromEnd: End position of the feature on the chromosome or scaffold. chromEnd must bean integer greater than or equal to the value of chromStart and less than or equal to the totalnumber of bases in the chromosome to which it belongs. If the size of the chromosomeis unknown, then chromEnd must be less than or equal to $2^{64}$ − 1, the maximum size of anunsigned 64-bit integer. 简单属性(Simple attributes) name: String that describes the feature. The name must be 0 to 255 non-tab characters. Thename must not be empty or contain whitespace, unless all fields in file are delimited exclusivelyusing single tab characters. A visual representation of the BED format may display the namenext to the feature. score: Integer between 0 and 1000, inclusive. If the feature has no score information, then 0should be used as a default value. A visual representation of the BED format may shadefeatures differently depending on their score. strand: Strand that the feature appears on. The strand may either refer to the + (sense orcoding) strand or the - (antisense or complementary) strand. If the feature has no strandinformation or unknown strand, then a dot (.) must be used. Display attributes thickStart: Start position at which the feature is visualized with a thicker or accented display.This value must be an integer between chromStart and chromEnd, inclusive. There is nospecified default value for thickStart. thickEnd: End position at which the feature is visualized with a thicker or accented display.This value must be an integer greater than or equal to thickStart and less than or equalto chromEnd, inclusive. In BED files with fewer than 7 fields, the whole feature has thickdisplay. In BED7+ files, to achieve the same effect, set thickStart equal to chromStartand thickEnd equal to chromEnd. If this field is not specified but thickStart is, then theentire feature has thick display. There is no specified default value for thickEnd. itemRgb: A triple of integers that determines the color of this feature when visualized. Thetriple is three integers separated by commas. Each integer is between 0 and 255, inclusive. Tomake a feature black, itemRgb may be a single 0, which is visualized identically to a featurewith itemRgb of 0,0,0. Blocks blockCount: Number of blocks in the feature. blockCount must be an integer greater than 0.blockCount is mandatory in BED12+ files. Null or empty blockCount are not allowed,because blockSizes and blockStarts rely on blockCount. A visual representation of the BEDformat may have blocks appear thicker than the rest of the feature. blockSizes: Comma-separated list of length blockCount containing the size of each block. Theremust be no spaces before or after commas. There may be a trailing comma after the lastelement of the list. blockSizes is mandatory in BED12+ files. Null or empty blockSizes is notallowed, because blockStarts cannot be verified without blockSizes. blockStarts: Comma-separated list of length blockCount containing each block’s start position,relative to chromStart. There must not be spaces before or after the commas. There maybe a trailing comma after the last element of the list. Each element in blockStarts is pairedwith the corresponding element in blockSizes. Each blockStarts element must be an integerbetween 0 and chromEnd−chromStart, inclusive. For each couple i of (blockStartsi, blockSizesi),the quantity chromStart + blockStartsi + blockSizesi must be less or equal to chromEnd. Theseconditions enforce that each block is contained within the feature. The first block muststart at chromStart and the last block must end at chromEnd. Moreover, the blocks must notoverlap. The list must be sorted in ascending order. blockStarts is mandatory in BED12+files. Null or empty blockStarts is not allowed. 术语和概念 （Terminology and concepts）0-start, half-open coordinate system: bed区间的位置描述为0起始，区间为左闭右开区间。A coordinate system where the first base starts at position 0, and the start of the interval is included but the end is not. For example, for a sequence of bases ACTGCG, the bases given by the interval [2, 4) are TG. BEDn: 表示文件包含bed的前n个字段（总计12个字段）A file with the first n fields of the BED format. For example, BED3 means a file with only the first 3 fields; BED12 means a file with all 12 fields. BEDn+: 表示包含前n个bed的定义字段，后续跟随一些自定义字段。A file that has n fields of the BED format, followed by any number of fields of custom data defined by a user. BEDn+m: 表示包含前n个bed的定义字段，后续跟随m个自定义字段。A file that has a custom tab-delimited format starting with the first n fields of the BED format, followed by m fields of custom data defined by a user. For example, BED6+4 means a file with the first 6 fields of the BED format, followed by 4 user-defined fields block: Linear subfeatures within a feature. Usually used to designate exons chromosome: 染色体编号 A sequence of nucleobases with a name. In this specification, “chromosome” may also describe a named scaffold that does not fit the biological definition of a chromosome. Often, chromosomes are numbered starting from 1. There are also often sex chromosomes such as W, X, Y, and Z, mitochondrial chromosomes such as M, and possibly scaffolds from an unknown chromosome, often labeled Un. The name of each chromosome is often prefixed with chr. Examples of chromosome names include chr1, 21, chrX, chrM, chrUn, chr19_KI270914v1_alt, and chrUn_KI270435v1. feature: A linear region of a chromosome with specified properties. For example, a file’s features might all be peaks called from ChIP-seq data, or transcript. field: Data stored as non-tab text. All fields are 7-bit US ASCII. file: Sequence of one or more lines. line: String terminated by a line separator, in one of the following classes. Either a data line, a comment line, or a blank line. Discussed more fully in subsection 1.3 line separator: Either carriage return, line feed, or carriage return followed by line feed. The same line separator must be used throughout the file. 示意12 [Bedwen]]]></content>
      <categories>
        <category>知识沉淀</category>
        <category>文件格式</category>
      </categories>
      <tags>
        <tag>文件格式</tag>
        <tag>Bed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Perl脚本的调试]]></title>
    <url>%2F2018%2F04%2F05%2FPerl-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86-%E8%84%9A%E6%9C%AC%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[编程中错误不可避免，调试能够帮助我们发现有问题的代码段。在网上看了一下Perl脚本调试，发现其实很多东西并不需要，而且那么多也没人看。 下面简单整理一下。 1.进入debug。 使用-d，进入debug状态。例：perl -d Perl程序名称。 2.设置断点 b:设置断点。例：b 行号； c:程序执行到下一个断点处，或执行到指定行。例：c ；c 行号； d:删除一个断点。例：d 断点所在行号； D:删除所有断点。例：D； L:列出所有断点。例：L。 3.程序调试 n：执行下一行，跳过方法； s：执行下一行，如果是方法则进入方法体。# 所有引用的第三方包也会逐语句进行执行 T：程序的调用栈回退一级。 a：给程序的某一行加一个附加操作。在执行该行语句前先执行附加的操作。 例：a 行号 命令 。 R：重新启动正在调试的程序。 w：显示某行周围一窗（一屏）文件内容。 例: w 行号。 4.查看变量值 p：查看变量值。例：p 变量名； x：查看变量值并结构化显示。例：x 变量名。 W：监视变量值。被监视的变量在发生改变时，会打印输出。 例： W 变量名 （无变量则删除所有监控）。 V： 包名 变量名列表：显示指定包内的所有（或部分）变量的值。 **注：V、X命令中的变量名列表以空格分隔且变量名前应去掉$、@或% ** 使用工具进行调试 类似浏览器的F12功能，Perl也提供了调试工具ptkdb。使用该工具需要两个模型包：Tk和ptkdb。 使用如下命令可以安装着两个包 perl -MCPAN -e&apos;install Tk&apos; perl -MCPAN -e&apos;install Devel::ptkdb&apos;]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>Perl</category>
      </categories>
      <tags>
        <tag>Perl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Perl包：Statistics_Descriptive 数据统计]]></title>
    <url>%2F2018%2F04%2F02%2FPerl-%E5%8C%85-Statistics_Descriptive%E6%95%B0%E6%8D%AE%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[模块名： Statistics::Descriptive 使用方法简介构建对象12use Statistics::Descriptivemy $stat = Statistics::Descriptive::Full-&gt;new(); 导入数据12$stat-&gt;add_data(@a); # 导入数组$stat-&gt;add_data($a); # 导入数值 数据处理1$stat-&gt;sort_data(); 数据过滤1$stat-&gt;set_outlier_filter($code_ref); # 设置一个过滤函数，对数据进行过滤 计算统计指标12345678910111213141516171819202122my $mean = $stat-&gt;mean();#平均值my $variance = $stat-&gt;variance();#方差my $num = $stat-&gt;count();#data的数目my $standard_deviation=$stat-&gt;standard_deviation();#标准差my $sum=$stat-&gt;sum();#求和my $min=$stat-&gt;min();#最小值my $mindex=$stat-&gt;mindex();#最小值的indexmy $max=$stat-&gt;max();#最大值my $maxdex=$stat-&gt;maxdex();#最大值的indexmy $range=$stat-&gt;sample_range();#最小值到最大值print &quot;Number of Values = $num\n&quot;, &quot;Mean = $mean\n&quot;, &quot;Variance = $variance\n&quot;, &quot;standard_deviation = $standard_deviation\n&quot;, &quot;sum =$sum\n&quot;, &quot;min =$min\n&quot;, &quot;mindex=$mindex\n&quot;, &quot;max=$max\n&quot;, &quot;maxdex=$maxdex\n&quot;, &quot;range=$range\n&quot;;]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>Perl</category>
      </categories>
      <tags>
        <tag>Perl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[测序数据库-SRA]]></title>
    <url>%2F2017%2F01%2F22%2F2017-01-22.%E6%B5%8B%E5%BA%8F%E6%95%B0%E6%8D%AE%E5%BA%93-SRA%2F</url>
    <content type="text"><![CDATA[目前三个高通量数据合并针对动物，植物，微生物的划分进行去除；将目前的动物，植物．微生物三个高通量测序数据库进行整合；合并为一个数据库 高通量测序数据库 :合并原因： 有些项目有可能是存在跨物种的情况，进行分类的时候会产生问题（数据冗余或数据的缺失）； 物种的分类进行无法直接获取，如果区分需要人工整理，后期自动更新受影响； 提供物种检索后，数据库的合并不会收到影响； 高通量测序数据库 类别 NCBI DDBJ EBI 项目 PRJNAxxx / SRPxxx PRJDxxxxx 样品 SAMN03085625 / SRSxxx SAMDxxxxxx 实验 SRXxxxx DRAxxxxxx http://trace.ddbj.nig.ac.jp/bioproject/index_e.htmlhttp://trace.ddbj.nig.ac.jp/biosample/index_e.htmlhttp://trace.ddbj.nig.ac.jp/dra/index_e.html 数据获取 项目获取页面 NCBI项目项目ID 拼出xml文件下载路径：http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=bioproject&amp;retmode=xml&amp;id=301661 样品获取页面 NCBI样品进入样品页面，获得样品的uid，拼出xml文件下载路径:http://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=biosample&amp;retmode=xml&amp;id=1047767 特殊案例 一个样品对应多个项目 一个样品对应多个实验 样品没有对应项目信息 一个实验对应多套测序数据]]></content>
      <categories>
        <category>知识沉淀</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生信相关公共数据库]]></title>
    <url>%2F2017%2F01%2F19%2F0000-00-00.%E7%94%9F%E4%BF%A1%E7%9B%B8%E5%85%B3%E5%85%AC%E5%85%B1%E6%95%B0%E6%8D%AE%E5%BA%93%2F</url>
    <content type="text"><![CDATA[规范化数据库 HGVS(Human Genome Variation Society) 人类基因组突变描述格式规范 主要的可变剪切注释 HGMD(The Human Gene Mutation Database,HGMD® ) 肿瘤相关数据库TCGA肿瘤基因组图谱（TCGA）计划是由美国National Cancer Institute（NCI）和National Human Genome ResearchInstitute（NHGRI）于2006年联合启动的项目，作为目前最大的癌症基因信息数据库，收录33个癌种其中10个罕见癌种，及29种癌症器官，1万多个肿瘤样本，27万多份文件，含有多模式基因组学、表观基因组学和蛋白质组学数据。数据包括全基因组不同遗传特征的测量，如同一基因的DNA拷贝数、DNA甲基化、mRNA表达、SNP等。参考文献：The Cancer Genome Atlas (TCGA): an immeasurable source of knowledge 数据库名 网址 介绍 TCGA-GDC https://portal.gdc.cancer.gov/ TCGA官网 GEPIA http://gepia.cancer-pku.cn/ 包含TCGA和GTEx 的9736个肿瘤和8687个正常对照样本的RNA-seq数据。可提供在线分析。 cBioPortal http://www.cbioportal.org/ 数据包括MUT（Mutation突变），CNA(Copy Number Alterations,拷贝数变化），EXP（mRNA Expression，mRNA表达）和PORT/RPPA（Protein/ phosphoprotein level，蛋白表达或磷酸化变化），部分数据含有临床信息。 MethHC http://methhc.mbc.nctu.edu.tw/php/index.php 目前包含由Illumina HumanMethylation450K BeadChip产生的6548个DNA甲基化数据和由18个人癌症中的RNA-seq / miRNA-seq产生的12 567个mRNA / microRNA表达数据。 WebMEV http://mev.tm4.org/#/welcome 可上传数据或下载TCGA或GEO数据 DriverDBv2 http://driverdb.tms.cmu.edu.tw/driverdbv2/index.php 肿瘤驱动基因查询 UCSCGEOGEO数据库全称GENE EXPRESSION OMNIBUS，是由美国国立生物技术信息中心NCBI创建并维护的基因表达数据库，用于从任何物种或人造的来源检索基因表达数据。它创建于2000年，收录了世界各国研究机构提交的来自microarray，高密度寡核苷酸array（HAD），杂交膜（filter）和SAGE的许多类型的基因表达数据，目前已经发表的论文，论文中涉及到的基因表达检测的数据可以通过此数据库中找到。作为一个公共数据集合含有一系列预先计算的数据的定义和描述，以及用于交互检索和分析表达数据的在线工具。 ICGCICGC（International Cancer Genome Consortium，国际肿瘤基因组协作组），主要目标是全面阐明导致全球人类疾病负担的多种癌症中存在的基因组变化。收集了50种不同癌症类型（或亚型）的肿瘤数据，其中包括基因异常表达，体细胞突变，表观遗传修饰，临床数据等。ICGC包括亚洲、澳大利亚、欧洲、北美和南美17个行政区的89项目，包括25000个癌症基因组 cBioportalcBioPortal数据库整合了126个肿瘤基因组研究的数据，包括TCGA和ICGC等大型的肿瘤研究项目，涵盖了两万八千例标本的数据，此外部分样品还包括了临床预后等表型的信息。cBioPortal用于探索，可视化和分析多维癌症基因组学数据。将癌症组织和细胞系的分子谱分析数据简化为易于理解的遗传，表观遗传，基因表达和蛋白质组学事件。查询界面与定制数据存储相结合，使研究人员能够以交互方式探索样本，基因和途径的基因改变，并在基础数据中提供时将这些与临床结果联系起来。提供来自多个平台的基因水平数据的图形摘要，网络可视化和分析，生存分析，以患者为中心的查询和软件程序化访问。 MethHCMethHC专注于人类疾病的异常甲基化。MethHC整合了来自TCGA的DNA甲基化数据，基因表达数据和microRNA表达数据。MethHC目前包含由Illumina HumanMethylation450K BeadChip产生的6548个DNA甲基化数据和由18个人癌症中的RNA-seq / miRNA-seq产生的12 567个mRNA / microRNA表达数据。 HPA人类蛋白质表达图集（The human protein atlas）涵盖了17000个不同蛋白及26009种不同抗体的蛋白质水平分析。现在人类蛋白质图谱共包括三大亚图谱：组织图谱、细胞图谱和病理图谱。组织图谱包含了人类基因在RNA和蛋白质水平的表达信息。其中，蛋白质表达信息是来自免疫组化分析结果，依赖于无数商业化或者自制的抗体。细胞图谱包含人类细胞内蛋白质的空间信息。病理图谱涵盖了17种主要癌症类型、大约8000名病人的信息。病理图谱的一个创新是交互式生存散点图，可以以交互形式展示病人的生存数据。参考文献文档及文献：http://www.proteinatlas.org/about/publications OncoKBOncoKB是由Memorial Sloan Kettering癌症中心（MSK）维护的全面的精准肿瘤学知识库，包含来自FDA，NCCN或ASCO，ClinicalTrials.gov和科学文献的专业指导方针和建议，治疗策略，肿瘤专家或肿瘤协会共识，参考文献等信息。OncoKB目前包含有关554种癌症基因特定改变的详细信息，还有1级（FDA批准）、2级（标准护理）的治疗信息，3级临床证据和生物学证据。 StringString(search tool for the retrival of interacting genes/proteins)基因、蛋白质相互作用关系检索工具可以获取独特的，覆盖范围广的实验以及预测的相互作用关系信息。string提供的相互作用关系主要基于confidence score（可靠指数），以及其他附属信息，比如提供蛋白质域和3D结构。目前包括1100+个物种的5200+万蛋白质。构建蛋白质蛋白质相互作用网络可以用于过滤和评估功能性基因组学的数据，以及为注释蛋白质的结构、功能和进化性。 其他数据库 数据库 地址 简介 NCBI-gene https://www.ncbi.nlm.nih.gov/gene 是分子生物学，生物化学，和遗传学知识的存储和分析的自动系统。 GeneCards https://www.genecards.org/ 收录关于人的蛋白质编码基因、假基因、RNA基因、遗传基因座、基因簇和未分类的基因等详细信息。 ICGC https://icgc.org/ 收集了50种不同癌症类型（或亚型）的肿瘤数据，其中包括基因异常表达，体细胞突变，表观遗传修饰，临床数据等。ICGC包括亚洲、澳大利亚、欧洲、北美和南美17个行政区的89项目，包括25000个癌症基因组。 HPA https://www.proteinatlas.org/ 包括三大亚图谱：组织图谱、细胞图谱和病理图谱。可交互式展示数据。 UCSC http://genome.ucsc.edu/ 包含多个重要物种基因组草图，与ENCODE同步更新。可在线分析。 OncoKB https://oncokb.org/ 包含有关554种癌症基因特定改变的详细信息，还有1级（FDA批准）、2级（标准护理）的治疗信息，3级临床证据和生物学证据。 MalaCards https://www.malacards.org/ 疾病相关基因查询 GEO https://www.ncbi.nlm.nih.gov/gds 芯片数据库 SRA https://www.ncbi.nlm.nih.gov/sra/ 测序数据库 ArrayExpress https://www.ebi.ac.uk/arrayexpress/ 欧洲版GEO DAVID http://david.abcc.ncifcrf.gov/tools.jsp 功能富集分析 String http://string-db.org/ 蛋白互作查询+功能富集分析 GSEA http://software.broadinstitute.org/gsea/index.jsp 功能富集分析 Cosmic(Catalogue Of Somatic Mutations In Cancer)是目前世界上最大和最综合性的数据库，可以帮助我们探索癌症患者体细胞突变的功能及影响。癌症相关的体细胞位点，是整个网站的核心，收录了来自不同研究机构和数据库的体细胞突变数据，并提供了方便的浏览，检索，下载功能。 Cell Lines Projec对癌症研究中常用的细胞系样本进行深入研究，分析其突变信息。相比COSMIC, 整个项目中涵盖的变异数据会少一点。该项目网址如下： COSMIC-3D 通过交互式的网页，展现了基因突变导致的蛋白结构域的变化。在搜索框中输入一个具体的基因名称或者蛋白名称，可以查看具体的记录。 Cancer Gene Census在癌症研究中，找到相关的突变基因是最核心的目的之一。通过对各种癌症进行调研，整理了一份癌症相关的突变基因列表，这份列表就是Cancer Gene Census,简称CGC。 在CGC种，将所有的癌症相关基因分成两类: Tier1 : 对于这部分基因，有充分的证据表明，正是由于这些基因的突变，导致癌症的进一步发生。 Tier2 : 对于这部分基因，只能说在癌症中检测到了大量该基因的突变，但是并没有充分证据表明该基因突变对癌症发生的影响。 GeneCards基本覆盖了几大数据库对于基因的分析数据，是人类基因的综合数据库。该数据库整合了125个网站的基因数据中心的数据（包括HUGO(Human Gene Nomenclature Committee)、GDB(Genome Database)、MGD(Mouse Genome Database)等）。由以色列魏茨曼科学研究所维护的关于基因及其产物以及生物医学应用的文献库。GeneCards提供简明的基因组，蛋白质组，转录，遗传和功能上所有已知和预测的人类基因。GeneCards中的信息功能信息包括指向疾病的关系，突变和多态性，基因表达，基因功能，途径，蛋白质与蛋白质相互作用，相关的药物及化合物和切割等先进的研究抗体的试剂和工具等，重组蛋白，克隆，表达分析和RNAi试剂等。（还有各种数据库ID相互转换） GeneCards以卡片的形式给出结果，列出所查询基因的 1、官方名称，GDB同义列表、小鼠中的同源物、细胞遗传学定位、基因产物名称、产物功能，如在细胞中的作用、表达方式、定位、与其他蛋白质的同源性及其在疾病中的作用等； 2、相关基因家族； 3、相关疾病列表； 4、有关的研究论文； 5、医学应用，如根据该基因的有关知识而建立的新的治疗与诊断方法等。]]></content>
      <categories>
        <category>index</category>
        <category>知识沉淀</category>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生信相关软件索引]]></title>
    <url>%2F2017%2F01%2F19%2F0000-00-00.%E7%94%9F%E4%BF%A1%E7%9B%B8%E5%85%B3%E8%BD%AF%E4%BB%B6%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[常见文件格式 文件格式说明 - Vcf 文件格式说明 - SAM/BAM 终端软件 Software-终端工具-MobaxTerm 下机数据质控 SOAPNuke 变异检测 GATK4初探 - 1 功能软件 samtools-安装 Software-transvar_变异坐标转换 Jbrowse部署安装 安装 bcftools 1.2, htslib-1.2.1, tabix12345678wget https://github.com/samtools/bcftools/releases/download/1.2/bcftools-1.2.tar.bz2tar xvf bcftools-1.2.tar.bz2cd bcftools-1.2makemake installcd htslib-1.2.1makemake install]]></content>
      <categories>
        <category>index</category>
        <category>NGS</category>
        <category>software</category>
      </categories>
      <tags>
        <tag>Software</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python常用函数包索引]]></title>
    <url>%2F2017%2F01%2F19%2F0000-00-01.Python%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%8C%85%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[编码规范 Python 编码规范 python基础知识 Python 基础知识 Python 基础知识 Python 基础知识 - 序列的方法 Python 基础知识 - 文件读写 Python 基础知识 - 文件读写 Python 基础知识 - 序列的方法 python常用包数据处理 Python-包-包管理器Conda Python包-OpenCV_图像处理 Python包-pandas Python包-pyechart画web版图片 Python包-python-docx撰写word Python包-python-docx撰写word Python包-Scipy_科学计算库 Python包-Numpy记录 Python包-Scipy_科学计算库 NGS相关 Python包-Numpy记录 Python包-Numpy记录]]></content>
      <categories>
        <category>index</category>
        <category>编程拾慧</category>
        <category>python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[R常用函数包]]></title>
    <url>%2F2017%2F01%2F19%2F0000-00-03.R%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%8C%85%2F</url>
    <content type="text"><![CDATA[绘图相关函数]]></content>
      <categories>
        <category>index</category>
        <category>编程拾慧</category>
        <category>R</category>
      </categories>
      <tags>
        <tag>R</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Perl常用函数包]]></title>
    <url>%2F2017%2F01%2F19%2F0000-00-02.Perl%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0%E5%8C%85%2F</url>
    <content type="text"><![CDATA[基础知识Perl脚本的调试 包/库Perl包：Statistics_Descriptive 数据统计]]></content>
      <categories>
        <category>index</category>
        <category>编程拾慧</category>
        <category>Perl</category>
      </categories>
      <tags>
        <tag>Perl</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BGI工作索引]]></title>
    <url>%2F2017%2F01%2F15%2F0000-01-00.BGI%E5%B7%A5%E4%BD%9C%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[培训材料 NGS检测原理-实验 snakemake介绍 知识点 TMB简介及华大相关进展 DNA-Damage 本地构建control集合进行过滤 NGS检测中的数据模拟 指南参考 肿瘤NGS检测开发过程中的方法学 Standards and Guidelines for the Interpretation and Reporting of Sequence Variants in Cancer Standards and guidelines for the interpretation of sequence variants]]></content>
      <categories>
        <category>index</category>
      </categories>
      <tags>
        <tag>BGI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim常用命令]]></title>
    <url>%2F2017%2F01%2F15%2FLinux-Vim-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[在Vim中，光标的移动控制 命令 说明 H 左移动 J 下移动 K 上移动 L 右移动 w 移动到下一个单词 b 移动到上一个单词 行内跳转 命令 说明 w 到下一个单词的开头 e 到下一个单词的结尾 b 到前一个单词的开头 ge 到前一个单词的结尾 0或^ 到行头 $ 到行尾 f&lt;字母&gt; 向后搜索&lt;字母&gt;并跳转到第一个匹配的位置(非常实用) F&lt;字母&gt; 向前搜索&lt;字母&gt;并跳转到第一个匹配的位置 t&lt;字母&gt; 向后搜索&lt;字母&gt;并跳转到第一个匹配位置之前的一个字母(不常用) T&lt;字母&gt; 向前搜索&lt;字母&gt;并跳转到第一个匹配位置之后的一个字母(不常用) 切换为编辑状态的命令 命令 说明 i 在当前光标处进行编辑 I 在行首插入 A 在行末插入 a 在光标后插入编辑 o 在当前行后插入一个新行 O 在当前行前插入一个新行 cw 从光标所在位置开始插入编辑，同时删除该行中光标后面的文本 命令行模式下，退出Vim 命令 说明 :q! 强制退出，不保存编辑内容 :q 直接退出（仅在未更改文本内容时可用） :wq 或 :x 保存并退出 :wq! 强制保存并退出 :w （文件路径）将文档另存为文件路径，如果没有文件路径则保存原文件 :saveas 文件路径将文件另存为（文件路径） shift + zz 在普通模式下直接退出Vim，（对文件进行的更改会被保存） 其他快捷操作 命令 说明 .（小数点） 重复上一次的操作]]></content>
      <categories>
        <category>编程拾慧</category>
        <category>Vim</category>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Vim</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[鸡尾酒配方]]></title>
    <url>%2F2017%2F01%2F15%2F2015-04-23.%E9%B8%A1%E5%B0%BE%E9%85%92%E9%85%8D%E6%96%B9%2F</url>
    <content type="text"><![CDATA[轰炸机【英文名称】：B52【材 料】：, 咖啡酒 1A 百利甜1A ，伏特加 1A【制 法】：将咖啡酒，百利甜，伏特加依次加入子弹杯，点燃 泥石流【英文名称】：xxxx【材 料】：, 咖啡酒 1A 百利甜1A ，伏特加 1A【制 法】：将咖啡酒，百利甜，伏特加依次加入子弹杯混匀。 水母【材 料】：, 伏特加30ml、蓝橙力娇酒10ml、百利甜1滴。【制 法】：将蓝橙加入有伏特加的杯子中，然后滴加一滴百利甜。 蓝色珊瑚礁Blue Lagoon【材料】：伏特加60毫升、蓝色橙皮酒30毫升、凤梨汁60毫升、柑橘酒3-5毫升、凤梨带皮切片【制法】：除了凤梨片之外，将所有材料与碎冰放入雪克壶中充分摇匀后，过滤倒入冷却的鸡尾酒杯。最后放上凤梨片做装饰即可 红粉佳人【英文名称】：Pink Lady Cocktail【材 料】：辛辣金酒1盎司，蛋清1个，石榴糖浆1/4盎司，君度1/4盎司，柠檬汁1/2盎司【制 法】：(1)将所有材料倒入雪克壶中剧烈摇和；(2)将摇和好的酒倒入鸡尾酒杯中。]]></content>
      <categories>
        <category>鸡尾酒</category>
      </categories>
      <tags>
        <tag>鸡尾酒</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云计算技术及性能优化]]></title>
    <url>%2F2017%2F01%2F15%2F0001-00-01.%E4%BA%91%E8%AE%A1%E7%AE%97%E6%8A%80%E6%9C%AF%E5%8F%8A%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[云计算-基础概念-私有云公有云混合云 云计算技术及性能优化]]></content>
      <categories>
        <category>云计算</category>
      </categories>
      <tags>
        <tag>流程开发</tag>
      </tags>
  </entry>
</search>
